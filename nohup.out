[32m[2019-03-14 21:01:17 @__init__.py:79][0m Set root logger. Unset logger with neuralgym.unset_logger().
[32m[2019-03-14 21:01:17 @__init__.py:80][0m Saving logging to file: neuralgym_logs/20190314210117112192.
[32m[2019-03-14 21:01:25 @config.py:92][0m ---------------------------------- APP CONFIG ----------------------------------
[32m[2019-03-14 21:01:25 @config.py:119][0m TV_LOSS: False
[32m[2019-03-14 21:01:25 @config.py:119][0m MAX_DELTA_WIDTH: 32
[32m[2019-03-14 21:01:25 @config.py:119][0m VIZ_MAX_OUT: 10
[32m[2019-03-14 21:01:25 @config.py:119][0m VAL_PSTEPS: 1000
[32m[2019-03-14 21:01:25 @config.py:119][0m L1_LOSS: True
[32m[2019-03-14 21:01:25 @config.py:119][0m BATCH_SIZE: 16
[32m[2019-03-14 21:01:25 @config.py:119][0m GPU_ID: -1
[32m[2019-03-14 21:01:25 @config.py:119][0m MAX_DELTA_HEIGHT: 32
[32m[2019-03-14 21:01:25 @config.py:119][0m IMG_SHAPES: [256, 256, 3]
[32m[2019-03-14 21:01:25 @config.py:119][0m COARSE_L1_ALPHA: 1.2
[32m[2019-03-14 21:01:25 @config.py:119][0m RANDOM_CROP: False
[32m[2019-03-14 21:01:25 @config.py:119][0m VAL: False
[32m[2019-03-14 21:01:25 @config.py:119][0m VERTICAL_MARGIN: 0
[32m[2019-03-14 21:01:25 @config.py:119][0m GAN_LOSS_ALPHA: 0.001
[32m[2019-03-14 21:01:25 @config.py:119][0m MODEL_RESTORE: release_imagenet_256
[32m[2019-03-14 21:01:25 @config.py:119][0m GLOBAL_DCGAN_LOSS_ALPHA: 1.0
[32m[2019-03-14 21:01:25 @config.py:119][0m AE_LOSS_ALPHA: 1.2
[32m[2019-03-14 21:01:25 @config.py:119][0m STATIC_VIEW_SIZE: 30
[32m[2019-03-14 21:01:25 @config.py:119][0m WGAN_GP_LAMBDA: 10
[32m[2019-03-14 21:01:25 @config.py:119][0m GRADS_SUMMARY: False
[32m[2019-03-14 21:01:25 @config.py:119][0m TRAIN_SPE: 1000
[32m[2019-03-14 21:01:25 @config.py:119][0m GRADIENT_CLIP_VALUE: 0.1Â Â 
[32m[2019-03-14 21:01:25 @config.py:119][0m HORIZONTAL_MARGIN: 0
[32m[2019-03-14 21:01:25 @config.py:111][0m DATA_FLIST: 
[32m[2019-03-14 21:01:25 @config.py:119][0m   celebahq: ['data/celeba_hq/train_shuffled.flist', 'data/celeba_hq/validation_static_view.flist']
[32m[2019-03-14 21:01:25 @config.py:119][0m   places2: ['data/places2/train_shuffled.flist', 'data/places2/validation_static_view.flist']
[32m[2019-03-14 21:01:25 @config.py:119][0m   imagenet: ['data/imagenet/train_shuffled.flist', 'data/imagenet/validation_static_view.flist']
[32m[2019-03-14 21:01:25 @config.py:119][0m   celeba: ['data/celeba/train_shuffled.flist', 'data/celeba/validation_static_view.flist']
[32m[2019-03-14 21:01:25 @config.py:119][0m   mine: ['data_flist/train_shuffled.flist', 'data_flist/validation_shuffled.flist']
[32m[2019-03-14 21:01:25 @config.py:119][0m PADDING: SAME
[32m[2019-03-14 21:01:25 @config.py:119][0m HEIGHT: 128
[32m[2019-03-14 21:01:25 @config.py:119][0m GAN: wgan_gp
[32m[2019-03-14 21:01:25 @config.py:119][0m TV_LOSS_ALPHA: 0.0
[32m[2019-03-14 21:01:25 @config.py:119][0m DISCOUNTED_MASK: True
[32m[2019-03-14 21:01:25 @config.py:119][0m LOG_DIR: full_model_celeba_hq_256
[32m[2019-03-14 21:01:25 @config.py:119][0m FEATURE_LOSS: False
[32m[2019-03-14 21:01:25 @config.py:119][0m GRAMS_LOSS: False
[32m[2019-03-14 21:01:25 @config.py:119][0m GRADIENT_CLIP: False
[32m[2019-03-14 21:01:25 @config.py:119][0m NUM_GPUS: 1
[32m[2019-03-14 21:01:25 @config.py:119][0m DATASET: mine
[32m[2019-03-14 21:01:25 @config.py:119][0m VGG_MODEL_FILE: data/model_zoo/vgg16.npz
[32m[2019-03-14 21:01:25 @config.py:119][0m RANDOM_SEED: False
[32m[2019-03-14 21:01:25 @config.py:119][0m FEATURE_LOSS_ALPHA: 0.01
[32m[2019-03-14 21:01:25 @config.py:119][0m GLOBAL_WGAN_LOSS_ALPHA: 1.0
[32m[2019-03-14 21:01:25 @config.py:119][0m SPATIAL_DISCOUNTING_GAMMA: 0.9
[32m[2019-03-14 21:01:25 @config.py:119][0m WIDTH: 128
[32m[2019-03-14 21:01:25 @config.py:119][0m LOAD_VGG_MODEL: False
[32m[2019-03-14 21:01:25 @config.py:119][0m PRETRAIN_COARSE_NETWORK: False
[32m[2019-03-14 21:01:25 @config.py:119][0m GAN_WITH_MASK: False
[32m[2019-03-14 21:01:25 @config.py:119][0m GRAMS_LOSS_ALPHA: 50
[32m[2019-03-14 21:01:25 @config.py:119][0m AE_LOSS: True
[32m[2019-03-14 21:01:25 @config.py:119][0m MAX_ITERS: 10000
[32m[2019-03-14 21:01:25 @config.py:119][0m L1_LOSS_ALPHA: 1.2
[32m[2019-03-14 21:01:25 @config.py:94][0m --------------------------------------------------------------------------------
[32m[2019-03-14 21:01:26 @gpus.py:20][0m Set env: CUDA_VISIBLE_DEVICES=[0].
[32m[2019-03-14 21:01:26 @dataset.py:26][0m --------------------------------- Dataset Info ---------------------------------
[32m[2019-03-14 21:01:26 @dataset.py:36][0m queue_size: 256
[32m[2019-03-14 21:01:26 @dataset.py:36][0m nthreads: 16
[32m[2019-03-14 21:01:26 @dataset.py:36][0m dtypes: [tf.float32]
[32m[2019-03-14 21:01:26 @dataset.py:36][0m index: 0
[32m[2019-03-14 21:01:26 @dataset.py:36][0m batch_phs: [<tf.Tensor 'Placeholder:0' shape=(?, 256, 256, 3) dtype=float32>]
[32m[2019-03-14 21:01:26 @dataset.py:36][0m random_crop: False
[32m[2019-03-14 21:01:26 @dataset.py:36][0m shapes: [[256, 256, 3]]
[32m[2019-03-14 21:01:26 @dataset.py:36][0m file_length: 1065
[32m[2019-03-14 21:01:26 @dataset.py:36][0m filetype: image
[32m[2019-03-14 21:01:26 @dataset.py:36][0m fn_preprocess: None
[32m[2019-03-14 21:01:26 @dataset.py:36][0m enqueue_size: 32
[32m[2019-03-14 21:01:26 @dataset.py:36][0m return_fnames: False
[32m[2019-03-14 21:01:26 @dataset.py:36][0m random: False
[32m[2019-03-14 21:01:26 @dataset.py:37][0m --------------------------------------------------------------------------------
[32m[2019-03-14 21:01:28 @inpaint_model.py:159][0m Set batch_predicted to x2.
[32m[2019-03-14 21:01:28 @inpaint_ops.py:201][0m Use spatial discounting l1 loss.
[32m[2019-03-14 21:01:28 @inpaint_ops.py:201][0m Use spatial discounting l1 loss.
[32m[2019-03-14 21:01:29 @inpaint_model.py:241][0m Set L1_LOSS_ALPHA to 1.200000
[32m[2019-03-14 21:01:29 @inpaint_model.py:242][0m Set GAN_LOSS_ALPHA to 0.001000
[32m[2019-03-14 21:01:29 @inpaint_model.py:245][0m Set AE_LOSS_ALPHA to 1.200000
[32m[2019-03-14 21:01:30 @inpaint_model.py:159][0m Set batch_predicted to x2.
[32m[2019-03-14 21:01:30 @inpaint_ops.py:201][0m Use spatial discounting l1 loss.
[32m[2019-03-14 21:01:30 @inpaint_ops.py:201][0m Use spatial discounting l1 loss.
[32m[2019-03-14 21:01:31 @inpaint_model.py:241][0m Set L1_LOSS_ALPHA to 1.200000
[32m[2019-03-14 21:01:31 @inpaint_model.py:242][0m Set GAN_LOSS_ALPHA to 0.001000
[32m[2019-03-14 21:01:31 @inpaint_model.py:245][0m Set AE_LOSS_ALPHA to 1.200000
[32m[2019-03-14 21:01:32 @trainer.py:61][0m ------------------------- Context Of Secondary Trainer -------------------------
[32m[2019-03-14 21:01:32 @trainer.py:63][0m graph_def: <function multigpu_graph_def at 0x7f7dd3340f28>
[32m[2019-03-14 21:01:32 @trainer.py:63][0m optimizer: <tensorflow.python.training.adam.AdamOptimizer object at 0x7f7d9d321f98>
[32m[2019-03-14 21:01:32 @trainer.py:63][0m log_progress: False
[32m[2019-03-14 21:01:32 @trainer.py:63][0m grads_summary: True
[32m[2019-03-14 21:01:32 @trainer.py:63][0m spe: 1
[32m[2019-03-14 21:01:32 @trainer.py:63][0m feed_dict: {}
[32m[2019-03-14 21:01:32 @trainer.py:63][0m graph_def_kwargs: {'loss_type': 'd', 'model': <inpaint_model.InpaintCAModel object at 0x7f7d9e16af60>, 'data': <neuralgym.data.data_from_fnames.DataFromFNames object at 0x7f7d9e1b1320>, 'config': {}}
[32m[2019-03-14 21:01:32 @trainer.py:63][0m max_iters: 5
[32m[2019-03-14 21:01:32 @trainer.py:63][0m var_list: [<tf.Variable 'discriminator/discriminator_local/conv1/kernel:0' shape=(5, 5, 3, 64) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_local/conv1/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_local/conv2/kernel:0' shape=(5, 5, 64, 128) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_local/conv2/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_local/conv3/kernel:0' shape=(5, 5, 128, 256) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_local/conv3/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_local/conv4/kernel:0' shape=(5, 5, 256, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_local/conv4/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_global/conv1/kernel:0' shape=(5, 5, 3, 64) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_global/conv1/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_global/conv2/kernel:0' shape=(5, 5, 64, 128) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_global/conv2/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_global/conv3/kernel:0' shape=(5, 5, 128, 256) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_global/conv3/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_global/conv4/kernel:0' shape=(5, 5, 256, 256) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_global/conv4/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'discriminator/dout_local_fc/kernel:0' shape=(32768, 1) dtype=float32_ref>, <tf.Variable 'discriminator/dout_local_fc/bias:0' shape=(1,) dtype=float32_ref>, <tf.Variable 'discriminator/dout_global_fc/kernel:0' shape=(65536, 1) dtype=float32_ref>, <tf.Variable 'discriminator/dout_global_fc/bias:0' shape=(1,) dtype=float32_ref>]
[32m[2019-03-14 21:01:32 @trainer.py:63][0m log_dir: /tmp/neuralgym
[32m[2019-03-14 21:01:32 @trainer.py:64][0m --------------------------------------------------------------------------------
[32m[2019-03-14 21:01:34 @inpaint_model.py:159][0m Set batch_predicted to x2.
[32m[2019-03-14 21:01:34 @inpaint_ops.py:201][0m Use spatial discounting l1 loss.
[32m[2019-03-14 21:01:34 @inpaint_ops.py:201][0m Use spatial discounting l1 loss.
[32m[2019-03-14 21:01:40 @inpaint_model.py:241][0m Set L1_LOSS_ALPHA to 1.200000
[32m[2019-03-14 21:01:40 @inpaint_model.py:242][0m Set GAN_LOSS_ALPHA to 0.001000
[32m[2019-03-14 21:01:40 @inpaint_model.py:245][0m Set AE_LOSS_ALPHA to 1.200000
2019-03-14 21:01:44.002212: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[32m[2019-03-14 21:01:48 @data_from_fnames.py:153][0m image is None, sleep this thread for 0.1s.
[32m[2019-03-14 21:01:48 @data_from_fnames.py:153][0m image is None, sleep this thread for 0.1s.
Exception in thread Thread-17:
Traceback (most recent call last):
  File "/usr/lib/python3.5/threading.py", line 914, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.5/threading.py", line 862, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.5/dist-packages/neuralgym/data/feeding_queue_runner.py", line 194, in _run
    data = func()
  File "/usr/local/lib/python3.5/dist-packages/neuralgym/data/data_from_fnames.py", line 143, in <lambda>
    feed_dict_op=[lambda: self.next_batch()],
  File "/usr/local/lib/python3.5/dist-packages/neuralgym/data/data_from_fnames.py", line 182, in next_batch
    img = cv2.resize(img, tuple(self.shapes[i][:-1][::-1]))
cv2.error: OpenCV(4.0.0) /io/opencv/modules/imgproc/src/resize.cpp:3784: error: (-215:Assertion failed) !ssize.empty() in function 'resize'


Exception in thread Thread-14:
Traceback (most recent call last):
  File "/usr/lib/python3.5/threading.py", line 914, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.5/threading.py", line 862, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.5/dist-packages/neuralgym/data/feeding_queue_runner.py", line 194, in _run
    data = func()
  File "/usr/local/lib/python3.5/dist-packages/neuralgym/data/data_from_fnames.py", line 143, in <lambda>
    feed_dict_op=[lambda: self.next_batch()],
  File "/usr/local/lib/python3.5/dist-packages/neuralgym/data/data_from_fnames.py", line 182, in next_batch
    img = cv2.resize(img, tuple(self.shapes[i][:-1][::-1]))
cv2.error: OpenCV(4.0.0) /io/opencv/modules/imgproc/src/resize.cpp:3784: error: (-215:Assertion failed) !ssize.empty() in function 'resize'


[32m[2019-03-14 21:01:49 @trainer.py:59][0m -------------------------- Context Of Primary Trainer --------------------------
[32m[2019-03-14 21:01:49 @trainer.py:63][0m sess: <tensorflow.python.client.session.Session object at 0x7f7d98eab6a0>
[32m[2019-03-14 21:01:49 @trainer.py:63][0m start_queue_runners: True
[32m[2019-03-14 21:01:49 @trainer.py:63][0m optimizer: <tensorflow.python.training.adam.AdamOptimizer object at 0x7f7d9d321f98>
[32m[2019-03-14 21:01:49 @trainer.py:63][0m saver: <tensorflow.python.training.saver.Saver object at 0x7f7d99a02828>
[32m[2019-03-14 21:01:49 @trainer.py:63][0m gradient_processor: None
[32m[2019-03-14 21:01:49 @trainer.py:63][0m summary_writer: <tensorflow.python.summary.writer.writer.FileWriter object at 0x7f7d99a026d8>
[32m[2019-03-14 21:01:49 @trainer.py:63][0m spe: 1000
[32m[2019-03-14 21:01:49 @trainer.py:63][0m global_step: <tf.Variable 'global_step:0' shape=() dtype=int32_ref>
[32m[2019-03-14 21:01:49 @trainer.py:63][0m sess_config: gpu_options {
  allow_growth: true
}
allow_soft_placement: true

[32m[2019-03-14 21:01:49 @trainer.py:63][0m max_iters: 10000
[32m[2019-03-14 21:01:49 @trainer.py:63][0m graph_def: <function multigpu_graph_def at 0x7f7dd3340f28>
[32m[2019-03-14 21:01:49 @trainer.py:63][0m feed_dict: {}
[32m[2019-03-14 21:01:49 @trainer.py:63][0m log_progress: True
[32m[2019-03-14 21:01:49 @trainer.py:63][0m grads_summary: False
[32m[2019-03-14 21:01:49 @trainer.py:63][0m global_variables_initializer: True
[32m[2019-03-14 21:01:49 @trainer.py:63][0m graph_def_kwargs: {'loss_type': 'g', 'model': <inpaint_model.InpaintCAModel object at 0x7f7d9e16af60>, 'data': <neuralgym.data.data_from_fnames.DataFromFNames object at 0x7f7d9e1b1320>, 'config': {}}
[32m[2019-03-14 21:01:49 @trainer.py:63][0m var_list: [<tf.Variable 'inpaint_net/conv1/kernel:0' shape=(5, 5, 5, 32) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv1/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv2_downsample/kernel:0' shape=(3, 3, 32, 64) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv2_downsample/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv3/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv3/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv4_downsample/kernel:0' shape=(3, 3, 64, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv4_downsample/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv5/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv5/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv6/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv6/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv7_atrous/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv7_atrous/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv8_atrous/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv8_atrous/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv9_atrous/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv9_atrous/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv10_atrous/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv10_atrous/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv11/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv11/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv12/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv12/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv13_upsample/conv13_upsample_conv/kernel:0' shape=(3, 3, 128, 64) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv13_upsample/conv13_upsample_conv/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv14/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv14/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv15_upsample/conv15_upsample_conv/kernel:0' shape=(3, 3, 64, 32) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv15_upsample/conv15_upsample_conv/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv16/kernel:0' shape=(3, 3, 32, 16) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv16/bias:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv17/kernel:0' shape=(3, 3, 16, 3) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv17/bias:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv1/kernel:0' shape=(5, 5, 5, 32) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv1/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv2_downsample/kernel:0' shape=(3, 3, 32, 32) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv2_downsample/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv3/kernel:0' shape=(3, 3, 32, 64) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv3/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv4_downsample/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv4_downsample/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv5/kernel:0' shape=(3, 3, 64, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv5/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv6/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv6/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv7_atrous/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv7_atrous/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv8_atrous/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv8_atrous/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv9_atrous/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv9_atrous/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv10_atrous/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv10_atrous/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv1/kernel:0' shape=(5, 5, 5, 32) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv1/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv2_downsample/kernel:0' shape=(3, 3, 32, 32) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv2_downsample/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv3/kernel:0' shape=(3, 3, 32, 64) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv3/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv4_downsample/kernel:0' shape=(3, 3, 64, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv4_downsample/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv5/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv5/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv6/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv6/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv9/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv9/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv10/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv10/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv11/kernel:0' shape=(3, 3, 256, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv11/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv12/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv12/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv13_upsample/allconv13_upsample_conv/kernel:0' shape=(3, 3, 128, 64) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv13_upsample/allconv13_upsample_conv/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv14/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv14/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv15_upsample/allconv15_upsample_conv/kernel:0' shape=(3, 3, 64, 32) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv15_upsample/allconv15_upsample_conv/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv16/kernel:0' shape=(3, 3, 32, 16) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv16/bias:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv17/kernel:0' shape=(3, 3, 16, 3) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv17/bias:0' shape=(3,) dtype=float32_ref>]
[32m[2019-03-14 21:01:49 @trainer.py:63][0m log_dir: model_logs/20190314210129062103_10-255-0-254_mine_NORMAL_wgan_gp_full_model_celeba_hq_256
[32m[2019-03-14 21:01:49 @trainer.py:63][0m global_step_add_one: Tensor("add_one_to_global_step:0", shape=(), dtype=int32_ref)
[32m[2019-03-14 21:01:49 @trainer.py:64][0m --------------------------------------------------------------------------------
[32m[2019-03-14 21:01:50 @data_from_fnames.py:153][0m image is None, sleep this thread for 0.1s.
[32m[2019-03-14 21:01:50 @data_from_fnames.py:153][0m image is None, sleep this thread for 0.1s.
[32m[2019-03-14 21:01:50 @data_from_fnames.py:153][0m image is None, sleep this thread for 0.1s.
Exception in thread Thread-13:
Traceback (most recent call last):
  File "/usr/lib/python3.5/threading.py", line 914, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.5/threading.py", line 862, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.5/dist-packages/neuralgym/data/feeding_queue_runner.py", line 194, in _run
    data = func()
  File "/usr/local/lib/python3.5/dist-packages/neuralgym/data/data_from_fnames.py", line 143, in <lambda>
    feed_dict_op=[lambda: self.next_batch()],
  File "/usr/local/lib/python3.5/dist-packages/neuralgym/data/data_from_fnames.py", line 182, in next_batch
    img = cv2.resize(img, tuple(self.shapes[i][:-1][::-1]))
cv2.error: OpenCV(4.0.0) /io/opencv/modules/imgproc/src/resize.cpp:3784: error: (-215:Assertion failed) !ssize.empty() in function 'resize'


Exception in thread Thread-7:
Traceback (most recent call last):
  File "/usr/lib/python3.5/threading.py", line 914, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.5/threading.py", line 862, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.5/dist-packages/neuralgym/data/feeding_queue_runner.py", line 194, in _run
    data = func()
  File "/usr/local/lib/python3.5/dist-packages/neuralgym/data/data_from_fnames.py", line 143, in <lambda>
    feed_dict_op=[lambda: self.next_batch()],
  File "/usr/local/lib/python3.5/dist-packages/neuralgym/data/data_from_fnames.py", line 182, in next_batch
    img = cv2.resize(img, tuple(self.shapes[i][:-1][::-1]))
cv2.error: OpenCV(4.0.0) /io/opencv/modules/imgproc/src/resize.cpp:3784: error: (-215:Assertion failed) !ssize.empty() in function 'resize'


Exception in thread Thread-12:
Traceback (most recent call last):
  File "/usr/lib/python3.5/threading.py", line 914, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.5/threading.py", line 862, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.5/dist-packages/neuralgym/data/feeding_queue_runner.py", line 194, in _run
    data = func()
  File "/usr/local/lib/python3.5/dist-packages/neuralgym/data/data_from_fnames.py", line 143, in <lambda>
    feed_dict_op=[lambda: self.next_batch()],
  File "/usr/local/lib/python3.5/dist-packages/neuralgym/data/data_from_fnames.py", line 182, in next_batch
    img = cv2.resize(img, tuple(self.shapes[i][:-1][::-1]))
cv2.error: OpenCV(4.0.0) /io/opencv/modules/imgproc/src/resize.cpp:3784: error: (-215:Assertion failed) !ssize.empty() in function 'resize'


[32m[2019-03-14 21:01:51 @logger.py:43][0m [32;1mTrigger callback: [0mTrigger WeightsViewer: logging model weights...
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv1/kernel:0, shape: [5, 5, 5, 32], size: 4000
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv1/bias:0, shape: [32], size: 32
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv2_downsample/kernel:0, shape: [3, 3, 32, 64], size: 18432
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv2_downsample/bias:0, shape: [64], size: 64
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv3/kernel:0, shape: [3, 3, 64, 64], size: 36864
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv3/bias:0, shape: [64], size: 64
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv4_downsample/kernel:0, shape: [3, 3, 64, 128], size: 73728
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv4_downsample/bias:0, shape: [128], size: 128
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv5/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv5/bias:0, shape: [128], size: 128
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv6/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv6/bias:0, shape: [128], size: 128
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv7_atrous/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv7_atrous/bias:0, shape: [128], size: 128
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv8_atrous/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv8_atrous/bias:0, shape: [128], size: 128
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv9_atrous/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv9_atrous/bias:0, shape: [128], size: 128
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv10_atrous/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv10_atrous/bias:0, shape: [128], size: 128
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv11/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv11/bias:0, shape: [128], size: 128
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv12/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv12/bias:0, shape: [128], size: 128
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv13_upsample/conv13_upsample_conv/kernel:0, shape: [3, 3, 128, 64], size: 73728
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv13_upsample/conv13_upsample_conv/bias:0, shape: [64], size: 64
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv14/kernel:0, shape: [3, 3, 64, 64], size: 36864
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv14/bias:0, shape: [64], size: 64
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv15_upsample/conv15_upsample_conv/kernel:0, shape: [3, 3, 64, 32], size: 18432
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv15_upsample/conv15_upsample_conv/bias:0, shape: [32], size: 32
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv16/kernel:0, shape: [3, 3, 32, 16], size: 4608
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv16/bias:0, shape: [16], size: 16
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv17/kernel:0, shape: [3, 3, 16, 3], size: 432
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/conv17/bias:0, shape: [3], size: 3
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv1/kernel:0, shape: [5, 5, 5, 32], size: 4000
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv1/bias:0, shape: [32], size: 32
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv2_downsample/kernel:0, shape: [3, 3, 32, 32], size: 9216
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv2_downsample/bias:0, shape: [32], size: 32
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv3/kernel:0, shape: [3, 3, 32, 64], size: 18432
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv3/bias:0, shape: [64], size: 64
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv4_downsample/kernel:0, shape: [3, 3, 64, 64], size: 36864
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv4_downsample/bias:0, shape: [64], size: 64
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv5/kernel:0, shape: [3, 3, 64, 128], size: 73728
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv5/bias:0, shape: [128], size: 128
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv6/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv6/bias:0, shape: [128], size: 128
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv7_atrous/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv7_atrous/bias:0, shape: [128], size: 128
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv8_atrous/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv8_atrous/bias:0, shape: [128], size: 128
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv9_atrous/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv9_atrous/bias:0, shape: [128], size: 128
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv10_atrous/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv10_atrous/bias:0, shape: [128], size: 128
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv1/kernel:0, shape: [5, 5, 5, 32], size: 4000
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv1/bias:0, shape: [32], size: 32
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv2_downsample/kernel:0, shape: [3, 3, 32, 32], size: 9216
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv2_downsample/bias:0, shape: [32], size: 32
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv3/kernel:0, shape: [3, 3, 32, 64], size: 18432
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv3/bias:0, shape: [64], size: 64
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv4_downsample/kernel:0, shape: [3, 3, 64, 128], size: 73728
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv4_downsample/bias:0, shape: [128], size: 128
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv5/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv5/bias:0, shape: [128], size: 128
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv6/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv6/bias:0, shape: [128], size: 128
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv9/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv9/bias:0, shape: [128], size: 128
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv10/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv10/bias:0, shape: [128], size: 128
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv11/kernel:0, shape: [3, 3, 256, 128], size: 294912
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv11/bias:0, shape: [128], size: 128
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv12/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv12/bias:0, shape: [128], size: 128
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv13_upsample/allconv13_upsample_conv/kernel:0, shape: [3, 3, 128, 64], size: 73728
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv13_upsample/allconv13_upsample_conv/bias:0, shape: [64], size: 64
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv14/kernel:0, shape: [3, 3, 64, 64], size: 36864
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv14/bias:0, shape: [64], size: 64
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv15_upsample/allconv15_upsample_conv/kernel:0, shape: [3, 3, 64, 32], size: 18432
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv15_upsample/allconv15_upsample_conv/bias:0, shape: [32], size: 32
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv16/kernel:0, shape: [3, 3, 32, 16], size: 4608
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv16/bias:0, shape: [16], size: 16
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv17/kernel:0, shape: [3, 3, 16, 3], size: 432
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv17/bias:0, shape: [3], size: 3
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_local/conv1/kernel:0, shape: [5, 5, 3, 64], size: 4800
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_local/conv1/bias:0, shape: [64], size: 64
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_local/conv2/kernel:0, shape: [5, 5, 64, 128], size: 204800
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_local/conv2/bias:0, shape: [128], size: 128
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_local/conv3/kernel:0, shape: [5, 5, 128, 256], size: 819200
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_local/conv3/bias:0, shape: [256], size: 256
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_local/conv4/kernel:0, shape: [5, 5, 256, 512], size: 3276800
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_local/conv4/bias:0, shape: [512], size: 512
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_global/conv1/kernel:0, shape: [5, 5, 3, 64], size: 4800
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_global/conv1/bias:0, shape: [64], size: 64
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_global/conv2/kernel:0, shape: [5, 5, 64, 128], size: 204800
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_global/conv2/bias:0, shape: [128], size: 128
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_global/conv3/kernel:0, shape: [5, 5, 128, 256], size: 819200
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_global/conv3/bias:0, shape: [256], size: 256
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_global/conv4/kernel:0, shape: [5, 5, 256, 256], size: 1638400
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_global/conv4/bias:0, shape: [256], size: 256
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: discriminator/dout_local_fc/kernel:0, shape: [32768, 1], size: 32768
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: discriminator/dout_local_fc/bias:0, shape: [1], size: 1
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: discriminator/dout_global_fc/kernel:0, shape: [65536, 1], size: 65536
[32m[2019-03-14 21:01:51 @weights_viewer.py:43][0m - weight name: discriminator/dout_global_fc/bias:0, shape: [1], size: 1
[32m[2019-03-14 21:01:51 @logger.py:43][0m [32;1mTrigger callback: [0mTotal counts of trainable weights: 10674312.
[32m[2019-03-14 21:01:51 @weights_viewer.py:60][0m Total size of trainable weights: 0G 10M 184K 136B (Assuming32-bit data type.)
[32m[2019-03-14 21:03:05 @data_from_fnames.py:153][0m image is None, sleep this thread for 0.1s.
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/usr/lib/python3.5/threading.py", line 914, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.5/threading.py", line 862, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.5/dist-packages/neuralgym/data/feeding_queue_runner.py", line 194, in _run
    data = func()
  File "/usr/local/lib/python3.5/dist-packages/neuralgym/data/data_from_fnames.py", line 143, in <lambda>
    feed_dict_op=[lambda: self.next_batch()],
  File "/usr/local/lib/python3.5/dist-packages/neuralgym/data/data_from_fnames.py", line 182, in next_batch
    img = cv2.resize(img, tuple(self.shapes[i][:-1][::-1]))
cv2.error: OpenCV(4.0.0) /io/opencv/modules/imgproc/src/resize.cpp:3784: error: (-215:Assertion failed) !ssize.empty() in function 'resize'


[32m[2019-03-14 21:05:48 @data_from_fnames.py:153][0m image is None, sleep this thread for 0.1s.
  File "train.py", line 39
    else:
        ^
IndentationError: unindent does not match any outer indentation level
Traceback (most recent call last):
  File "train.py", line 6, in <module>
    import tensorflow as tf
ImportError: No module named tensorflow
[32m[2019-03-17 10:59:19 @__init__.py:79][0m Set root logger. Unset logger with neuralgym.unset_logger().
[32m[2019-03-17 10:59:19 @__init__.py:80][0m Saving logging to file: neuralgym_logs/20190317105919676416.
[32m[2019-03-17 10:59:29 @config.py:92][0m ---------------------------------- APP CONFIG ----------------------------------
[32m[2019-03-17 10:59:29 @config.py:119][0m MAX_ITERS: 100000
[32m[2019-03-17 10:59:29 @config.py:119][0m RANDOM_CROP: False
[32m[2019-03-17 10:59:29 @config.py:119][0m IMG_SHAPES: [256, 256, 3]
[32m[2019-03-17 10:59:29 @config.py:119][0m STATIC_VIEW_SIZE: 30
[32m[2019-03-17 10:59:29 @config.py:119][0m FEATURE_LOSS: True
[32m[2019-03-17 10:59:29 @config.py:119][0m VIZ_MAX_OUT: 10
[32m[2019-03-17 10:59:29 @config.py:119][0m MAX_DELTA_HEIGHT: 32
[32m[2019-03-17 10:59:29 @config.py:119][0m GRADS_SUMMARY: False
[32m[2019-03-17 10:59:29 @config.py:119][0m AE_LOSS: True
[32m[2019-03-17 10:59:29 @config.py:119][0m COARSE_L1_ALPHA: 1.2
[32m[2019-03-17 10:59:29 @config.py:119][0m L1_LOSS: True
[32m[2019-03-17 10:59:29 @config.py:119][0m GAN_WITH_MASK: False
[32m[2019-03-17 10:59:29 @config.py:119][0m GRAMS_LOSS_ALPHA: 50
[32m[2019-03-17 10:59:29 @config.py:119][0m LOAD_VGG_MODEL: True
[32m[2019-03-17 10:59:29 @config.py:119][0m TRAIN_SPE: 1000
[32m[2019-03-17 10:59:29 @config.py:119][0m MAX_DELTA_WIDTH: 32
[32m[2019-03-17 10:59:29 @config.py:119][0m HORIZONTAL_MARGIN: 0
[32m[2019-03-17 10:59:29 @config.py:119][0m MODEL_RESTORE: release_imagenet_256
[32m[2019-03-17 10:59:29 @config.py:119][0m LOG_DIR: full_model_celeba_hq_256
[32m[2019-03-17 10:59:29 @config.py:119][0m PADDING: SAME
[32m[2019-03-17 10:59:29 @config.py:111][0m DATA_FLIST: 
[32m[2019-03-17 10:59:29 @config.py:119][0m   celeba: ['data/celeba/train_shuffled.flist', 'data/celeba/validation_static_view.flist']
[32m[2019-03-17 10:59:29 @config.py:119][0m   places2: ['data/places2/train_shuffled.flist', 'data/places2/validation_static_view.flist']
[32m[2019-03-17 10:59:29 @config.py:119][0m   imagenet: ['data/imagenet/train_shuffled.flist', 'data/imagenet/validation_static_view.flist']
[32m[2019-03-17 10:59:29 @config.py:119][0m   celebahq: ['data/celeba_hq/train_shuffled.flist', 'data/celeba_hq/validation_static_view.flist']
[32m[2019-03-17 10:59:29 @config.py:119][0m   mine: ['data_flist/train_shuffled.flist', 'data_flist/validation_shuffled.flist']
[32m[2019-03-17 10:59:29 @config.py:119][0m VAL_PSTEPS: 1000
[32m[2019-03-17 10:59:29 @config.py:119][0m HEIGHT: 128
[32m[2019-03-17 10:59:29 @config.py:119][0m VERTICAL_MARGIN: 0
[32m[2019-03-17 10:59:29 @config.py:119][0m VGG_MODEL_FILE: vgg/vgg16_weights.npz
[32m[2019-03-17 10:59:29 @config.py:119][0m GAN_LOSS_ALPHA: 0.001
[32m[2019-03-17 10:59:29 @config.py:119][0m GPU_ID: 0
[32m[2019-03-17 10:59:29 @config.py:119][0m DISCOUNTED_MASK: True
[32m[2019-03-17 10:59:29 @config.py:119][0m TV_LOSS: False
[32m[2019-03-17 10:59:29 @config.py:119][0m GRADIENT_CLIP_VALUE: 0.1Â Â 
[32m[2019-03-17 10:59:29 @config.py:119][0m GRADIENT_CLIP: False
[32m[2019-03-17 10:59:29 @config.py:119][0m GAN: wgan_gp
[32m[2019-03-17 10:59:29 @config.py:119][0m GLOBAL_DCGAN_LOSS_ALPHA: 1.0
[32m[2019-03-17 10:59:29 @config.py:119][0m z: 0.9
[32m[2019-03-17 10:59:29 @config.py:119][0m BATCH_SIZE: 16
[32m[2019-03-17 10:59:29 @config.py:119][0m TV_LOSS_ALPHA: 0.0
[32m[2019-03-17 10:59:29 @config.py:119][0m DATASET: mine
[32m[2019-03-17 10:59:29 @config.py:119][0m VAL: False
[32m[2019-03-17 10:59:29 @config.py:119][0m WIDTH: 128
[32m[2019-03-17 10:59:29 @config.py:119][0m GRAMS_LOSS: True
[32m[2019-03-17 10:59:29 @config.py:119][0m NUM_GPUS: 1
[32m[2019-03-17 10:59:29 @config.py:119][0m AE_LOSS_ALPHA: 1.2
[32m[2019-03-17 10:59:29 @config.py:119][0m FEATURE_LOSS_ALPHA: 0.01
[32m[2019-03-17 10:59:29 @config.py:119][0m L1_LOSS_ALPHA: 1.2
[32m[2019-03-17 10:59:29 @config.py:119][0m GLOBAL_WGAN_LOSS_ALPHA: 1.0
[32m[2019-03-17 10:59:29 @config.py:119][0m RANDOM_SEED: False
[32m[2019-03-17 10:59:29 @config.py:119][0m PRETRAIN_COARSE_NETWORK: False
[32m[2019-03-17 10:59:29 @config.py:119][0m WGAN_GP_LAMBDA: 10
[32m[2019-03-17 10:59:29 @config.py:94][0m --------------------------------------------------------------------------------
[32m[2019-03-17 10:59:29 @gpus.py:20][0m Set env: CUDA_VISIBLE_DEVICES=[0].
[32m[2019-03-17 10:59:29 @dataset.py:26][0m --------------------------------- Dataset Info ---------------------------------
[32m[2019-03-17 10:59:29 @dataset.py:36][0m random_crop: False
[32m[2019-03-17 10:59:29 @dataset.py:36][0m random: False
[32m[2019-03-17 10:59:29 @dataset.py:36][0m enqueue_size: 32
[32m[2019-03-17 10:59:29 @dataset.py:36][0m fn_preprocess: None
[32m[2019-03-17 10:59:29 @dataset.py:36][0m filetype: image
[32m[2019-03-17 10:59:29 @dataset.py:36][0m queue_size: 256
[32m[2019-03-17 10:59:29 @dataset.py:36][0m shapes: [[256, 256, 3]]
[32m[2019-03-17 10:59:29 @dataset.py:36][0m nthreads: 16
[32m[2019-03-17 10:59:29 @dataset.py:36][0m return_fnames: False
[32m[2019-03-17 10:59:29 @dataset.py:36][0m file_length: 4420
[32m[2019-03-17 10:59:29 @dataset.py:36][0m dtypes: [tf.float32]
[32m[2019-03-17 10:59:29 @dataset.py:36][0m index: 0
[32m[2019-03-17 10:59:29 @dataset.py:36][0m batch_phs: [<tf.Tensor 'Placeholder:0' shape=(?, 256, 256, 3) dtype=float32>]
[32m[2019-03-17 10:59:29 @dataset.py:37][0m --------------------------------------------------------------------------------
[32m[2019-03-17 10:59:32 @inpaint_model.py:159][0m Set batch_predicted to x2.
Traceback (most recent call last):
  File "train.py", line 52, in <module>
    images, config=config)
  File "/home/dc2-user/siuDong/ganCode/generative_inpainting/inpaint_model.py", line 171, in build_graph_with_losses
    losses['l1_loss'] = l1_alpha * tf.reduce_mean(tf.abs(local_patch_batch_pos - local_patch_x1)*spatial_discounting_mask(config))
  File "/home/dc2-user/siuDong/ganCode/generative_inpainting/inpaint_ops.py", line 198, in spatial_discounting_mask
    gamma = config.SPATIAL_DISCOUNTING_GAMMA
  File "/usr/local/lib/python3.5/dist-packages/neuralgym/utils/config.py", line 97, in __getattr__
    value = self._cfg_dict[name]
KeyError: 'SPATIAL_DISCOUNTING_GAMMA'
[32m[2019-03-17 11:02:10 @__init__.py:79][0m Set root logger. Unset logger with neuralgym.unset_logger().
[32m[2019-03-17 11:02:10 @__init__.py:80][0m Saving logging to file: neuralgym_logs/20190317110210071000.
[32m[2019-03-17 11:02:12 @config.py:92][0m ---------------------------------- APP CONFIG ----------------------------------
[32m[2019-03-17 11:02:12 @config.py:119][0m HEIGHT: 128
[32m[2019-03-17 11:02:12 @config.py:119][0m MAX_DELTA_HEIGHT: 32
[32m[2019-03-17 11:02:12 @config.py:119][0m STATIC_VIEW_SIZE: 30
[32m[2019-03-17 11:02:12 @config.py:111][0m DATA_FLIST: 
[32m[2019-03-17 11:02:12 @config.py:119][0m   mine: ['data_flist/train_shuffled.flist', 'data_flist/validation_shuffled.flist']
[32m[2019-03-17 11:02:12 @config.py:119][0m   imagenet: ['data/imagenet/train_shuffled.flist', 'data/imagenet/validation_static_view.flist']
[32m[2019-03-17 11:02:12 @config.py:119][0m   celeba: ['data/celeba/train_shuffled.flist', 'data/celeba/validation_static_view.flist']
[32m[2019-03-17 11:02:12 @config.py:119][0m   celebahq: ['data/celeba_hq/train_shuffled.flist', 'data/celeba_hq/validation_static_view.flist']
[32m[2019-03-17 11:02:12 @config.py:119][0m   places2: ['data/places2/train_shuffled.flist', 'data/places2/validation_static_view.flist']
[32m[2019-03-17 11:02:12 @config.py:119][0m GAN_WITH_MASK: False
[32m[2019-03-17 11:02:12 @config.py:119][0m GRAMS_LOSS_ALPHA: 50
[32m[2019-03-17 11:02:12 @config.py:119][0m IMG_SHAPES: [256, 256, 3]
[32m[2019-03-17 11:02:12 @config.py:119][0m DATASET: mine
[32m[2019-03-17 11:02:12 @config.py:119][0m L1_LOSS_ALPHA: 1.2
[32m[2019-03-17 11:02:12 @config.py:119][0m MAX_ITERS: 100000
[32m[2019-03-17 11:02:12 @config.py:119][0m FEATURE_LOSS: True
[32m[2019-03-17 11:02:12 @config.py:119][0m VIZ_MAX_OUT: 10
[32m[2019-03-17 11:02:12 @config.py:119][0m AE_LOSS_ALPHA: 1.2
[32m[2019-03-17 11:02:12 @config.py:119][0m TV_LOSS: False
[32m[2019-03-17 11:02:12 @config.py:119][0m GAN_LOSS_ALPHA: 0.001
[32m[2019-03-17 11:02:12 @config.py:119][0m LOG_DIR: full_model_celeba_hq_256
[32m[2019-03-17 11:02:12 @config.py:119][0m COARSE_L1_ALPHA: 1.2
[32m[2019-03-17 11:02:12 @config.py:119][0m GRAMS_LOSS: True
[32m[2019-03-17 11:02:12 @config.py:119][0m DISCOUNTED_MASK: True
[32m[2019-03-17 11:02:12 @config.py:119][0m MODEL_RESTORE: release_imagenet_256
[32m[2019-03-17 11:02:12 @config.py:119][0m VGG_MODEL_FILE: vgg/vgg16_weights.npz
[32m[2019-03-17 11:02:12 @config.py:119][0m HORIZONTAL_MARGIN: 0
[32m[2019-03-17 11:02:12 @config.py:119][0m VAL: False
[32m[2019-03-17 11:02:12 @config.py:119][0m MAX_DELTA_WIDTH: 32
[32m[2019-03-17 11:02:12 @config.py:119][0m AE_LOSS: True
[32m[2019-03-17 11:02:12 @config.py:119][0m VERTICAL_MARGIN: 0
[32m[2019-03-17 11:02:12 @config.py:119][0m BATCH_SIZE: 16
[32m[2019-03-17 11:02:12 @config.py:119][0m GPU_ID: 0
[32m[2019-03-17 11:02:12 @config.py:119][0m GAN: wgan_gp
[32m[2019-03-17 11:02:12 @config.py:119][0m VAL_PSTEPS: 1000
[32m[2019-03-17 11:02:12 @config.py:119][0m NUM_GPUS: 1
[32m[2019-03-17 11:02:12 @config.py:119][0m z: 0.9
[32m[2019-03-17 11:02:12 @config.py:119][0m GLOBAL_WGAN_LOSS_ALPHA: 1.0
[32m[2019-03-17 11:02:12 @config.py:119][0m PRETRAIN_COARSE_NETWORK: False
[32m[2019-03-17 11:02:12 @config.py:119][0m RANDOM_SEED: False
[32m[2019-03-17 11:02:12 @config.py:119][0m GLOBAL_DCGAN_LOSS_ALPHA: 1.0
[32m[2019-03-17 11:02:12 @config.py:119][0m WIDTH: 128
[32m[2019-03-17 11:02:12 @config.py:119][0m RANDOM_CROP: False
[32m[2019-03-17 11:02:12 @config.py:119][0m LOAD_VGG_MODEL: True
[32m[2019-03-17 11:02:12 @config.py:119][0m TRAIN_SPE: 1000
[32m[2019-03-17 11:02:12 @config.py:119][0m L1_LOSS: True
[32m[2019-03-17 11:02:12 @config.py:119][0m WGAN_GP_LAMBDA: 10
[32m[2019-03-17 11:02:12 @config.py:119][0m GRADIENT_CLIP: False
[32m[2019-03-17 11:02:12 @config.py:119][0m FEATURE_LOSS_ALPHA: 0.01
[32m[2019-03-17 11:02:12 @config.py:119][0m TV_LOSS_ALPHA: 0.0
[32m[2019-03-17 11:02:12 @config.py:119][0m PADDING: SAME
[32m[2019-03-17 11:02:12 @config.py:119][0m GRADS_SUMMARY: False
[32m[2019-03-17 11:02:12 @config.py:119][0m GRADIENT_CLIP_VALUE: 0.1Â Â 
[32m[2019-03-17 11:02:12 @config.py:94][0m --------------------------------------------------------------------------------
[32m[2019-03-17 11:02:12 @gpus.py:20][0m Set env: CUDA_VISIBLE_DEVICES=[0].
[32m[2019-03-17 11:02:12 @dataset.py:26][0m --------------------------------- Dataset Info ---------------------------------
[32m[2019-03-17 11:02:12 @dataset.py:36][0m file_length: 4420
[32m[2019-03-17 11:02:12 @dataset.py:36][0m index: 0
[32m[2019-03-17 11:02:12 @dataset.py:36][0m return_fnames: False
[32m[2019-03-17 11:02:12 @dataset.py:36][0m dtypes: [tf.float32]
[32m[2019-03-17 11:02:12 @dataset.py:36][0m filetype: image
[32m[2019-03-17 11:02:12 @dataset.py:36][0m random: False
[32m[2019-03-17 11:02:12 @dataset.py:36][0m fn_preprocess: None
[32m[2019-03-17 11:02:12 @dataset.py:36][0m nthreads: 16
[32m[2019-03-17 11:02:12 @dataset.py:36][0m shapes: [[256, 256, 3]]
[32m[2019-03-17 11:02:12 @dataset.py:36][0m batch_phs: [<tf.Tensor 'Placeholder:0' shape=(?, 256, 256, 3) dtype=float32>]
[32m[2019-03-17 11:02:12 @dataset.py:36][0m random_crop: False
[32m[2019-03-17 11:02:12 @dataset.py:36][0m enqueue_size: 32
[32m[2019-03-17 11:02:12 @dataset.py:36][0m queue_size: 256
[32m[2019-03-17 11:02:12 @dataset.py:37][0m --------------------------------------------------------------------------------
[32m[2019-03-17 11:02:14 @inpaint_model.py:159][0m Set batch_predicted to x2.
Traceback (most recent call last):
  File "train.py", line 52, in <module>
    images, config=config)
  File "/home/dc2-user/siuDong/ganCode/generative_inpainting/inpaint_model.py", line 171, in build_graph_with_losses
    losses['l1_loss'] = l1_alpha * tf.reduce_mean(tf.abs(local_patch_batch_pos - local_patch_x1)*spatial_discounting_mask(config))
  File "/home/dc2-user/siuDong/ganCode/generative_inpainting/inpaint_ops.py", line 198, in spatial_discounting_mask
    gamma = config.SPATIAL_DISCOUNTING_GAMMA
  File "/usr/local/lib/python3.5/dist-packages/neuralgym/utils/config.py", line 97, in __getattr__
    value = self._cfg_dict[name]
KeyError: 'SPATIAL_DISCOUNTING_GAMMA'
[32m[2019-03-17 11:03:03 @__init__.py:79][0m Set root logger. Unset logger with neuralgym.unset_logger().
[32m[2019-03-17 11:03:03 @__init__.py:80][0m Saving logging to file: neuralgym_logs/20190317110303883359.
[32m[2019-03-17 11:03:06 @config.py:92][0m ---------------------------------- APP CONFIG ----------------------------------
[32m[2019-03-17 11:03:06 @config.py:119][0m MAX_DELTA_WIDTH: 32
[32m[2019-03-17 11:03:06 @config.py:119][0m GLOBAL_WGAN_LOSS_ALPHA: 1.0
[32m[2019-03-17 11:03:06 @config.py:119][0m VERTICAL_MARGIN: 0
[32m[2019-03-17 11:03:06 @config.py:119][0m VGG_MODEL_FILE: vgg/vgg16_weights.npz
[32m[2019-03-17 11:03:06 @config.py:119][0m GRADIENT_CLIP: False
[32m[2019-03-17 11:03:06 @config.py:119][0m DATASET: mine
[32m[2019-03-17 11:03:06 @config.py:119][0m WIDTH: 128
[32m[2019-03-17 11:03:06 @config.py:119][0m PADDING: SAME
[32m[2019-03-17 11:03:06 @config.py:119][0m GAN: wgan_gp
[32m[2019-03-17 11:03:06 @config.py:119][0m AE_LOSS: True
[32m[2019-03-17 11:03:06 @config.py:119][0m VIZ_MAX_OUT: 10
[32m[2019-03-17 11:03:06 @config.py:119][0m GRAMS_LOSS_ALPHA: 50
[32m[2019-03-17 11:03:06 @config.py:119][0m HEIGHT: 128
[32m[2019-03-17 11:03:06 @config.py:119][0m AE_LOSS_ALPHA: 1.2
[32m[2019-03-17 11:03:06 @config.py:119][0m MAX_DELTA_HEIGHT: 32
[32m[2019-03-17 11:03:06 @config.py:119][0m TV_LOSS_ALPHA: 0.0
[32m[2019-03-17 11:03:06 @config.py:119][0m MAX_ITERS: 100000
[32m[2019-03-17 11:03:06 @config.py:119][0m RANDOM_CROP: False
[32m[2019-03-17 11:03:06 @config.py:119][0m GRAMS_LOSS: True
[32m[2019-03-17 11:03:06 @config.py:119][0m GRADS_SUMMARY: False
[32m[2019-03-17 11:03:06 @config.py:119][0m FEATURE_LOSS: True
[32m[2019-03-17 11:03:06 @config.py:119][0m NUM_GPUS: 1
[32m[2019-03-17 11:03:06 @config.py:119][0m MODEL_RESTORE: release_imagenet_256
[32m[2019-03-17 11:03:06 @config.py:119][0m VAL_PSTEPS: 1000
[32m[2019-03-17 11:03:06 @config.py:119][0m COARSE_L1_ALPHA: 1.2
[32m[2019-03-17 11:03:06 @config.py:119][0m RANDOM_SEED: False
[32m[2019-03-17 11:03:06 @config.py:119][0m WGAN_GP_LAMBDA: 10
[32m[2019-03-17 11:03:06 @config.py:119][0m DISCOUNTED_MASK: True
[32m[2019-03-17 11:03:06 @config.py:119][0m VAL: False
[32m[2019-03-17 11:03:06 @config.py:119][0m GAN_WITH_MASK: False
[32m[2019-03-17 11:03:06 @config.py:119][0m TV_LOSS: False
[32m[2019-03-17 11:03:06 @config.py:119][0m L1_LOSS_ALPHA: 1.2
[32m[2019-03-17 11:03:06 @config.py:119][0m GAN_LOSS_ALPHA: 0.001
[32m[2019-03-17 11:03:06 @config.py:119][0m IMG_SHAPES: [256, 256, 3]
[32m[2019-03-17 11:03:06 @config.py:119][0m PRETRAIN_COARSE_NETWORK: False
[32m[2019-03-17 11:03:06 @config.py:119][0m z: 0.9
[32m[2019-03-17 11:03:06 @config.py:119][0m TRAIN_SPE: 1000
[32m[2019-03-17 11:03:06 @config.py:119][0m HORIZONTAL_MARGIN: 0
[32m[2019-03-17 11:03:06 @config.py:119][0m FEATURE_LOSS_ALPHA: 0.01
[32m[2019-03-17 11:03:06 @config.py:119][0m L1_LOSS: True
[32m[2019-03-17 11:03:06 @config.py:119][0m GRADIENT_CLIP_VALUE: 0.1Â Â 
[32m[2019-03-17 11:03:06 @config.py:119][0m LOG_DIR: full_model_celeba_hq_256
[32m[2019-03-17 11:03:06 @config.py:119][0m BATCH_SIZE: 16
[32m[2019-03-17 11:03:06 @config.py:119][0m GLOBAL_DCGAN_LOSS_ALPHA: 1.0
[32m[2019-03-17 11:03:06 @config.py:111][0m DATA_FLIST: 
[32m[2019-03-17 11:03:06 @config.py:119][0m   celeba: ['data/celeba/train_shuffled.flist', 'data/celeba/validation_static_view.flist']
[32m[2019-03-17 11:03:06 @config.py:119][0m   places2: ['data/places2/train_shuffled.flist', 'data/places2/validation_static_view.flist']
[32m[2019-03-17 11:03:06 @config.py:119][0m   mine: ['data_flist/train_shuffled.flist', 'data_flist/validation_shuffled.flist']
[32m[2019-03-17 11:03:06 @config.py:119][0m   imagenet: ['data/imagenet/train_shuffled.flist', 'data/imagenet/validation_static_view.flist']
[32m[2019-03-17 11:03:06 @config.py:119][0m   celebahq: ['data/celeba_hq/train_shuffled.flist', 'data/celeba_hq/validation_static_view.flist']
[32m[2019-03-17 11:03:06 @config.py:119][0m GPU_ID: 0
[32m[2019-03-17 11:03:06 @config.py:119][0m STATIC_VIEW_SIZE: 30
[32m[2019-03-17 11:03:06 @config.py:119][0m LOAD_VGG_MODEL: True
[32m[2019-03-17 11:03:06 @config.py:94][0m --------------------------------------------------------------------------------
[32m[2019-03-17 11:03:06 @gpus.py:20][0m Set env: CUDA_VISIBLE_DEVICES=[0].
[32m[2019-03-17 11:03:06 @dataset.py:26][0m --------------------------------- Dataset Info ---------------------------------
[32m[2019-03-17 11:03:06 @dataset.py:36][0m dtypes: [tf.float32]
[32m[2019-03-17 11:03:06 @dataset.py:36][0m fn_preprocess: None
[32m[2019-03-17 11:03:06 @dataset.py:36][0m batch_phs: [<tf.Tensor 'Placeholder:0' shape=(?, 256, 256, 3) dtype=float32>]
[32m[2019-03-17 11:03:06 @dataset.py:36][0m queue_size: 256
[32m[2019-03-17 11:03:06 @dataset.py:36][0m filetype: image
[32m[2019-03-17 11:03:06 @dataset.py:36][0m index: 0
[32m[2019-03-17 11:03:06 @dataset.py:36][0m shapes: [[256, 256, 3]]
[32m[2019-03-17 11:03:06 @dataset.py:36][0m return_fnames: False
[32m[2019-03-17 11:03:06 @dataset.py:36][0m random: False
[32m[2019-03-17 11:03:06 @dataset.py:36][0m nthreads: 16
[32m[2019-03-17 11:03:06 @dataset.py:36][0m random_crop: False
[32m[2019-03-17 11:03:06 @dataset.py:36][0m file_length: 4420
[32m[2019-03-17 11:03:06 @dataset.py:36][0m enqueue_size: 32
[32m[2019-03-17 11:03:06 @dataset.py:37][0m --------------------------------------------------------------------------------
[32m[2019-03-17 11:03:08 @inpaint_model.py:159][0m Set batch_predicted to x2.
Traceback (most recent call last):
  File "train.py", line 52, in <module>
    images, config=config)
  File "/home/dc2-user/siuDong/ganCode/generative_inpainting/inpaint_model.py", line 171, in build_graph_with_losses
    losses['l1_loss'] = l1_alpha * tf.reduce_mean(tf.abs(local_patch_batch_pos - local_patch_x1)*spatial_discounting_mask(config))
  File "/home/dc2-user/siuDong/ganCode/generative_inpainting/inpaint_ops.py", line 198, in spatial_discounting_mask
    gamma = config.SPATIAL_DISCOUNTING_GAMMA
  File "/usr/local/lib/python3.5/dist-packages/neuralgym/utils/config.py", line 97, in __getattr__
    value = self._cfg_dict[name]
KeyError: 'SPATIAL_DISCOUNTING_GAMMA'
[32m[2019-03-17 11:04:50 @__init__.py:79][0m Set root logger. Unset logger with neuralgym.unset_logger().
[32m[2019-03-17 11:04:50 @__init__.py:80][0m Saving logging to file: neuralgym_logs/20190317110450561673.
[32m[2019-03-17 11:04:53 @config.py:92][0m ---------------------------------- APP CONFIG ----------------------------------
[32m[2019-03-17 11:04:53 @config.py:119][0m GRADS_SUMMARY: False
[32m[2019-03-17 11:04:53 @config.py:119][0m L1_LOSS_ALPHA: 1.2
[32m[2019-03-17 11:04:53 @config.py:119][0m HEIGHT: 128
[32m[2019-03-17 11:04:53 @config.py:119][0m z: 0.9
[32m[2019-03-17 11:04:53 @config.py:119][0m NUM_GPUS: 1
[32m[2019-03-17 11:04:53 @config.py:111][0m DATA_FLIST: 
[32m[2019-03-17 11:04:53 @config.py:119][0m   celebahq: ['data/celeba_hq/train_shuffled.flist', 'data/celeba_hq/validation_static_view.flist']
[32m[2019-03-17 11:04:53 @config.py:119][0m   celeba: ['data/celeba/train_shuffled.flist', 'data/celeba/validation_static_view.flist']
[32m[2019-03-17 11:04:53 @config.py:119][0m   imagenet: ['data/imagenet/train_shuffled.flist', 'data/imagenet/validation_static_view.flist']
[32m[2019-03-17 11:04:53 @config.py:119][0m   mine: ['data_flist/train_shuffled.flist', 'data_flist/validation_shuffled.flist']
[32m[2019-03-17 11:04:53 @config.py:119][0m   places2: ['data/places2/train_shuffled.flist', 'data/places2/validation_static_view.flist']
[32m[2019-03-17 11:04:53 @config.py:119][0m VAL: False
[32m[2019-03-17 11:04:53 @config.py:119][0m MAX_DELTA_HEIGHT: 32
[32m[2019-03-17 11:04:53 @config.py:119][0m RANDOM_CROP: False
[32m[2019-03-17 11:04:53 @config.py:119][0m VGG_MODEL_FILE: vgg/vgg16_weights.npz
[32m[2019-03-17 11:04:53 @config.py:119][0m COARSE_L1_ALPHA: 1.2
[32m[2019-03-17 11:04:53 @config.py:119][0m IMG_SHAPES: [256, 256, 3]
[32m[2019-03-17 11:04:53 @config.py:119][0m VERTICAL_MARGIN: 0
[32m[2019-03-17 11:04:53 @config.py:119][0m WGAN_GP_LAMBDA: 10
[32m[2019-03-17 11:04:53 @config.py:119][0m MAX_DELTA_WIDTH: 32
[32m[2019-03-17 11:04:53 @config.py:119][0m GAN_WITH_MASK: False
[32m[2019-03-17 11:04:53 @config.py:119][0m MODEL_RESTORE: release_imagenet_256
[32m[2019-03-17 11:04:53 @config.py:119][0m GLOBAL_WGAN_LOSS_ALPHA: 1.0
[32m[2019-03-17 11:04:53 @config.py:119][0m VIZ_MAX_OUT: 10
[32m[2019-03-17 11:04:53 @config.py:119][0m LOG_DIR: full_model_celeba_hq_256
[32m[2019-03-17 11:04:53 @config.py:119][0m WIDTH: 128
[32m[2019-03-17 11:04:53 @config.py:119][0m GAN_LOSS_ALPHA: 0.001
[32m[2019-03-17 11:04:53 @config.py:119][0m AE_LOSS_ALPHA: 1.2
[32m[2019-03-17 11:04:53 @config.py:119][0m GRADIENT_CLIP_VALUE: 0.1Â Â 
[32m[2019-03-17 11:04:53 @config.py:119][0m GRAMS_LOSS_ALPHA: 50
[32m[2019-03-17 11:04:53 @config.py:119][0m GPU_ID: 0
[32m[2019-03-17 11:04:53 @config.py:119][0m LOAD_VGG_MODEL: True
[32m[2019-03-17 11:04:53 @config.py:119][0m GAN: wgan_gp
[32m[2019-03-17 11:04:53 @config.py:119][0m L1_LOSS: True
[32m[2019-03-17 11:04:53 @config.py:119][0m GRAMS_LOSS: True
[32m[2019-03-17 11:04:53 @config.py:119][0m RANDOM_SEED: False
[32m[2019-03-17 11:04:53 @config.py:119][0m AE_LOSS: True
[32m[2019-03-17 11:04:53 @config.py:119][0m FEATURE_LOSS_ALPHA: 0.01
[32m[2019-03-17 11:04:53 @config.py:119][0m TV_LOSS_ALPHA: 0.0
[32m[2019-03-17 11:04:53 @config.py:119][0m DATASET: mine
[32m[2019-03-17 11:04:53 @config.py:119][0m DISCOUNTED_MASK: True
[32m[2019-03-17 11:04:53 @config.py:119][0m FEATURE_LOSS: True
[32m[2019-03-17 11:04:53 @config.py:119][0m MAX_ITERS: 100000
[32m[2019-03-17 11:04:53 @config.py:119][0m TV_LOSS: False
[32m[2019-03-17 11:04:53 @config.py:119][0m TRAIN_SPE: 1000
[32m[2019-03-17 11:04:53 @config.py:119][0m PRETRAIN_COARSE_NETWORK: False
[32m[2019-03-17 11:04:53 @config.py:119][0m VAL_PSTEPS: 1000
[32m[2019-03-17 11:04:53 @config.py:119][0m GLOBAL_DCGAN_LOSS_ALPHA: 1.0
[32m[2019-03-17 11:04:53 @config.py:119][0m BATCH_SIZE: 16
[32m[2019-03-17 11:04:53 @config.py:119][0m STATIC_VIEW_SIZE: 30
[32m[2019-03-17 11:04:53 @config.py:119][0m HORIZONTAL_MARGIN: 0
[32m[2019-03-17 11:04:53 @config.py:119][0m GRADIENT_CLIP: False
[32m[2019-03-17 11:04:53 @config.py:119][0m PADDING: SAME
[32m[2019-03-17 11:04:53 @config.py:94][0m --------------------------------------------------------------------------------
[32m[2019-03-17 11:04:53 @gpus.py:20][0m Set env: CUDA_VISIBLE_DEVICES=[0].
[32m[2019-03-17 11:04:53 @dataset.py:26][0m --------------------------------- Dataset Info ---------------------------------
[32m[2019-03-17 11:04:53 @dataset.py:36][0m filetype: image
[32m[2019-03-17 11:04:53 @dataset.py:36][0m random: False
[32m[2019-03-17 11:04:53 @dataset.py:36][0m file_length: 4420
[32m[2019-03-17 11:04:53 @dataset.py:36][0m fn_preprocess: None
[32m[2019-03-17 11:04:53 @dataset.py:36][0m batch_phs: [<tf.Tensor 'Placeholder:0' shape=(?, 256, 256, 3) dtype=float32>]
[32m[2019-03-17 11:04:53 @dataset.py:36][0m random_crop: False
[32m[2019-03-17 11:04:53 @dataset.py:36][0m queue_size: 256
[32m[2019-03-17 11:04:53 @dataset.py:36][0m nthreads: 16
[32m[2019-03-17 11:04:53 @dataset.py:36][0m enqueue_size: 32
[32m[2019-03-17 11:04:53 @dataset.py:36][0m return_fnames: False
[32m[2019-03-17 11:04:53 @dataset.py:36][0m index: 0
[32m[2019-03-17 11:04:53 @dataset.py:36][0m dtypes: [tf.float32]
[32m[2019-03-17 11:04:53 @dataset.py:36][0m shapes: [[256, 256, 3]]
[32m[2019-03-17 11:04:53 @dataset.py:37][0m --------------------------------------------------------------------------------
[32m[2019-03-17 11:04:55 @inpaint_model.py:159][0m Set batch_predicted to x2.
Traceback (most recent call last):
  File "train.py", line 52, in <module>
    images, config=config)
  File "/home/dc2-user/siuDong/ganCode/generative_inpainting/inpaint_model.py", line 171, in build_graph_with_losses
    losses['l1_loss'] = l1_alpha * tf.reduce_mean(tf.abs(local_patch_batch_pos - local_patch_x1)*spatial_discounting_mask(config))
  File "/home/dc2-user/siuDong/ganCode/generative_inpainting/inpaint_ops.py", line 198, in spatial_discounting_mask
    gamma = config.SPATIAL_DISCOUNTING_GAMMA
  File "/usr/local/lib/python3.5/dist-packages/neuralgym/utils/config.py", line 97, in __getattr__
    value = self._cfg_dict[name]
KeyError: 'SPATIAL_DISCOUNTING_GAMMA'
[32m[2019-03-17 11:13:43 @__init__.py:79][0m Set root logger. Unset logger with neuralgym.unset_logger().
[32m[2019-03-17 11:13:43 @__init__.py:80][0m Saving logging to file: neuralgym_logs/20190317111343269066.
[32m[2019-03-17 11:13:46 @config.py:92][0m ---------------------------------- APP CONFIG ----------------------------------
[32m[2019-03-17 11:13:46 @config.py:119][0m GRAMS_LOSS: True
[32m[2019-03-17 11:13:46 @config.py:119][0m VIZ_MAX_OUT: 10
[32m[2019-03-17 11:13:46 @config.py:119][0m MAX_DELTA_WIDTH: 32
[32m[2019-03-17 11:13:46 @config.py:119][0m GRAMS_LOSS_ALPHA: 50
[32m[2019-03-17 11:13:46 @config.py:119][0m TRAIN_SPE: 1000
[32m[2019-03-17 11:13:46 @config.py:119][0m STATIC_VIEW_SIZE: 30
[32m[2019-03-17 11:13:46 @config.py:119][0m HORIZONTAL_MARGIN: 0
[32m[2019-03-17 11:13:46 @config.py:119][0m COARSE_L1_ALPHA: 1.2
[32m[2019-03-17 11:13:46 @config.py:119][0m RANDOM_SEED: False
[32m[2019-03-17 11:13:46 @config.py:119][0m GAN_WITH_MASK: False
[32m[2019-03-17 11:13:46 @config.py:119][0m GAN: wgan_gp
[32m[2019-03-17 11:13:46 @config.py:119][0m DATASET: mine
[32m[2019-03-17 11:13:46 @config.py:119][0m TV_LOSS: False
[32m[2019-03-17 11:13:46 @config.py:119][0m LOG_DIR: full_model_celeba_hq_256
[32m[2019-03-17 11:13:46 @config.py:119][0m MAX_DELTA_HEIGHT: 32
[32m[2019-03-17 11:13:46 @config.py:119][0m GLOBAL_DCGAN_LOSS_ALPHA: 1.0
[32m[2019-03-17 11:13:46 @config.py:111][0m DATA_FLIST: 
[32m[2019-03-17 11:13:46 @config.py:119][0m   places2: ['data/places2/train_shuffled.flist', 'data/places2/validation_static_view.flist']
[32m[2019-03-17 11:13:46 @config.py:119][0m   celeba: ['data/celeba/train_shuffled.flist', 'data/celeba/validation_static_view.flist']
[32m[2019-03-17 11:13:46 @config.py:119][0m   celebahq: ['data/celeba_hq/train_shuffled.flist', 'data/celeba_hq/validation_static_view.flist']
[32m[2019-03-17 11:13:46 @config.py:119][0m   mine: ['data_flist/train_shuffled.flist', 'data_flist/validation_shuffled.flist']
[32m[2019-03-17 11:13:46 @config.py:119][0m   imagenet: ['data/imagenet/train_shuffled.flist', 'data/imagenet/validation_static_view.flist']
[32m[2019-03-17 11:13:46 @config.py:119][0m VAL_PSTEPS: 1000
[32m[2019-03-17 11:13:46 @config.py:119][0m DISCOUNTED_MASK: True
[32m[2019-03-17 11:13:46 @config.py:119][0m GAN_LOSS_ALPHA: 0.001
[32m[2019-03-17 11:13:46 @config.py:119][0m TV_LOSS_ALPHA: 0.0
[32m[2019-03-17 11:13:46 @config.py:119][0m L1_LOSS_ALPHA: 1.2
[32m[2019-03-17 11:13:46 @config.py:119][0m PADDING: SAME
[32m[2019-03-17 11:13:46 @config.py:119][0m GRADS_SUMMARY: False
[32m[2019-03-17 11:13:46 @config.py:119][0m PRETRAIN_COARSE_NETWORK: False
[32m[2019-03-17 11:13:46 @config.py:119][0m BATCH_SIZE: 16
[32m[2019-03-17 11:13:46 @config.py:119][0m SPATIAL_DISCOUNTING_GAMMA: 0.9
[32m[2019-03-17 11:13:46 @config.py:119][0m L1_LOSS: True
[32m[2019-03-17 11:13:46 @config.py:119][0m VERTICAL_MARGIN: 0
[32m[2019-03-17 11:13:46 @config.py:119][0m GRADIENT_CLIP: False
[32m[2019-03-17 11:13:46 @config.py:119][0m MAX_ITERS: 100000
[32m[2019-03-17 11:13:46 @config.py:119][0m MODEL_RESTORE: release_imagenet_256
[32m[2019-03-17 11:13:46 @config.py:119][0m VGG_MODEL_FILE: vgg/vgg16_weights.npz
[32m[2019-03-17 11:13:46 @config.py:119][0m LOAD_VGG_MODEL: True
[32m[2019-03-17 11:13:46 @config.py:119][0m IMG_SHAPES: [256, 256, 3]
[32m[2019-03-17 11:13:46 @config.py:119][0m WGAN_GP_LAMBDA: 10
[32m[2019-03-17 11:13:46 @config.py:119][0m AE_LOSS: True
[32m[2019-03-17 11:13:46 @config.py:119][0m NUM_GPUS: 1
[32m[2019-03-17 11:13:46 @config.py:119][0m FEATURE_LOSS: True
[32m[2019-03-17 11:13:46 @config.py:119][0m GRADIENT_CLIP_VALUE: 0.1Â Â 
[32m[2019-03-17 11:13:46 @config.py:119][0m GPU_ID: 0
[32m[2019-03-17 11:13:46 @config.py:119][0m FEATURE_LOSS_ALPHA: 0.01
[32m[2019-03-17 11:13:46 @config.py:119][0m AE_LOSS_ALPHA: 1.2
[32m[2019-03-17 11:13:46 @config.py:119][0m HEIGHT: 128
[32m[2019-03-17 11:13:46 @config.py:119][0m WIDTH: 128
[32m[2019-03-17 11:13:46 @config.py:119][0m RANDOM_CROP: False
[32m[2019-03-17 11:13:46 @config.py:119][0m GLOBAL_WGAN_LOSS_ALPHA: 1.0
[32m[2019-03-17 11:13:46 @config.py:119][0m VAL: False
[32m[2019-03-17 11:13:46 @config.py:94][0m --------------------------------------------------------------------------------
[32m[2019-03-17 11:13:46 @gpus.py:20][0m Set env: CUDA_VISIBLE_DEVICES=[0].
[32m[2019-03-17 11:13:46 @dataset.py:26][0m --------------------------------- Dataset Info ---------------------------------
[32m[2019-03-17 11:13:46 @dataset.py:36][0m file_length: 4420
[32m[2019-03-17 11:13:46 @dataset.py:36][0m index: 0
[32m[2019-03-17 11:13:46 @dataset.py:36][0m dtypes: [tf.float32]
[32m[2019-03-17 11:13:46 @dataset.py:36][0m filetype: image
[32m[2019-03-17 11:13:46 @dataset.py:36][0m random_crop: False
[32m[2019-03-17 11:13:46 @dataset.py:36][0m shapes: [[256, 256, 3]]
[32m[2019-03-17 11:13:46 @dataset.py:36][0m return_fnames: False
[32m[2019-03-17 11:13:46 @dataset.py:36][0m nthreads: 16
[32m[2019-03-17 11:13:46 @dataset.py:36][0m random: False
[32m[2019-03-17 11:13:46 @dataset.py:36][0m fn_preprocess: None
[32m[2019-03-17 11:13:46 @dataset.py:36][0m queue_size: 256
[32m[2019-03-17 11:13:46 @dataset.py:36][0m batch_phs: [<tf.Tensor 'Placeholder:0' shape=(?, 256, 256, 3) dtype=float32>]
[32m[2019-03-17 11:13:46 @dataset.py:36][0m enqueue_size: 32
[32m[2019-03-17 11:13:46 @dataset.py:37][0m --------------------------------------------------------------------------------
[32m[2019-03-17 11:13:48 @inpaint_model.py:159][0m Set batch_predicted to x2.
[32m[2019-03-17 11:13:48 @inpaint_ops.py:201][0m Use spatial discounting l1 loss.
[32m[2019-03-17 11:13:48 @inpaint_ops.py:201][0m Use spatial discounting l1 loss.
[32m[2019-03-17 11:13:49 @inpaint_model.py:241][0m Set L1_LOSS_ALPHA to 1.200000
[32m[2019-03-17 11:13:49 @inpaint_model.py:242][0m Set GAN_LOSS_ALPHA to 0.001000
[32m[2019-03-17 11:13:49 @inpaint_model.py:245][0m Set AE_LOSS_ALPHA to 1.200000
[32m[2019-03-17 11:13:50 @inpaint_model.py:159][0m Set batch_predicted to x2.
[32m[2019-03-17 11:13:51 @inpaint_ops.py:201][0m Use spatial discounting l1 loss.
[32m[2019-03-17 11:13:51 @inpaint_ops.py:201][0m Use spatial discounting l1 loss.
[32m[2019-03-17 11:13:51 @inpaint_model.py:241][0m Set L1_LOSS_ALPHA to 1.200000
[32m[2019-03-17 11:13:51 @inpaint_model.py:242][0m Set GAN_LOSS_ALPHA to 0.001000
[32m[2019-03-17 11:13:51 @inpaint_model.py:245][0m Set AE_LOSS_ALPHA to 1.200000
[32m[2019-03-17 11:13:52 @trainer.py:61][0m ------------------------- Context Of Secondary Trainer -------------------------
[32m[2019-03-17 11:13:52 @trainer.py:63][0m var_list: [<tf.Variable 'discriminator/discriminator_local/conv1/kernel:0' shape=(5, 5, 3, 64) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_local/conv1/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_local/conv2/kernel:0' shape=(5, 5, 64, 128) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_local/conv2/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_local/conv3/kernel:0' shape=(5, 5, 128, 256) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_local/conv3/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_local/conv4/kernel:0' shape=(5, 5, 256, 512) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_local/conv4/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_global/conv1/kernel:0' shape=(5, 5, 3, 64) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_global/conv1/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_global/conv2/kernel:0' shape=(5, 5, 64, 128) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_global/conv2/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_global/conv3/kernel:0' shape=(5, 5, 128, 256) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_global/conv3/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_global/conv4/kernel:0' shape=(5, 5, 256, 256) dtype=float32_ref>, <tf.Variable 'discriminator/discriminator_global/conv4/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'discriminator/dout_local_fc/kernel:0' shape=(32768, 1) dtype=float32_ref>, <tf.Variable 'discriminator/dout_local_fc/bias:0' shape=(1,) dtype=float32_ref>, <tf.Variable 'discriminator/dout_global_fc/kernel:0' shape=(65536, 1) dtype=float32_ref>, <tf.Variable 'discriminator/dout_global_fc/bias:0' shape=(1,) dtype=float32_ref>]
[32m[2019-03-17 11:13:52 @trainer.py:63][0m log_progress: False
[32m[2019-03-17 11:13:52 @trainer.py:63][0m optimizer: <tensorflow.python.training.adam.AdamOptimizer object at 0x7f38655568d0>
[32m[2019-03-17 11:13:52 @trainer.py:63][0m grads_summary: True
[32m[2019-03-17 11:13:52 @trainer.py:63][0m graph_def_kwargs: {'config': {}, 'loss_type': 'd', 'data': <neuralgym.data.data_from_fnames.DataFromFNames object at 0x7f38664cf898>, 'model': <inpaint_model.InpaintCAModel object at 0x7f3866419ba8>}
[32m[2019-03-17 11:13:52 @trainer.py:63][0m graph_def: <function multigpu_graph_def at 0x7f38ee33cf28>
[32m[2019-03-17 11:13:52 @trainer.py:63][0m max_iters: 5
[32m[2019-03-17 11:13:52 @trainer.py:63][0m feed_dict: {}
[32m[2019-03-17 11:13:52 @trainer.py:63][0m log_dir: /tmp/neuralgym
[32m[2019-03-17 11:13:52 @trainer.py:63][0m spe: 1
[32m[2019-03-17 11:13:52 @trainer.py:64][0m --------------------------------------------------------------------------------
[32m[2019-03-17 11:13:54 @inpaint_model.py:159][0m Set batch_predicted to x2.
[32m[2019-03-17 11:13:54 @inpaint_ops.py:201][0m Use spatial discounting l1 loss.
[32m[2019-03-17 11:13:54 @inpaint_ops.py:201][0m Use spatial discounting l1 loss.
[32m[2019-03-17 11:14:00 @inpaint_model.py:241][0m Set L1_LOSS_ALPHA to 1.200000
[32m[2019-03-17 11:14:00 @inpaint_model.py:242][0m Set GAN_LOSS_ALPHA to 0.001000
[32m[2019-03-17 11:14:00 @inpaint_model.py:245][0m Set AE_LOSS_ALPHA to 1.200000
2019-03-17 11:14:03.985743: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-03-17 11:14:04.737583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-03-17 11:14:04.737822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135
pciBusID: 0000:00:07.0
totalMemory: 7.43GiB freeMemory: 7.31GiB
2019-03-17 11:14:04.737840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-17 11:14:05.042461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-17 11:14:05.042531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-17 11:14:05.042558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-17 11:14:05.057128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7048 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:07.0, compute capability: 6.1)
[32m[2019-03-17 11:14:10 @trainer.py:59][0m -------------------------- Context Of Primary Trainer --------------------------
[32m[2019-03-17 11:14:10 @trainer.py:63][0m log_progress: True
[32m[2019-03-17 11:14:10 @trainer.py:63][0m gradient_processor: None
[32m[2019-03-17 11:14:10 @trainer.py:63][0m optimizer: <tensorflow.python.training.adam.AdamOptimizer object at 0x7f38655568d0>
[32m[2019-03-17 11:14:10 @trainer.py:63][0m start_queue_runners: True
[32m[2019-03-17 11:14:10 @trainer.py:63][0m sess: <tensorflow.python.client.session.Session object at 0x7f3861ca8978>
[32m[2019-03-17 11:14:10 @trainer.py:63][0m saver: <tensorflow.python.training.saver.Saver object at 0x7f37dcafeef0>
[32m[2019-03-17 11:14:10 @trainer.py:63][0m spe: 1000
[32m[2019-03-17 11:14:10 @trainer.py:63][0m grads_summary: False
[32m[2019-03-17 11:14:10 @trainer.py:63][0m global_variables_initializer: True
[32m[2019-03-17 11:14:10 @trainer.py:63][0m var_list: [<tf.Variable 'inpaint_net/conv1/kernel:0' shape=(5, 5, 5, 32) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv1/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv2_downsample/kernel:0' shape=(3, 3, 32, 64) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv2_downsample/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv3/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv3/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv4_downsample/kernel:0' shape=(3, 3, 64, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv4_downsample/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv5/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv5/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv6/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv6/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv7_atrous/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv7_atrous/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv8_atrous/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv8_atrous/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv9_atrous/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv9_atrous/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv10_atrous/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv10_atrous/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv11/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv11/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv12/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv12/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv13_upsample/conv13_upsample_conv/kernel:0' shape=(3, 3, 128, 64) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv13_upsample/conv13_upsample_conv/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv14/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv14/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv15_upsample/conv15_upsample_conv/kernel:0' shape=(3, 3, 64, 32) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv15_upsample/conv15_upsample_conv/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv16/kernel:0' shape=(3, 3, 32, 16) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv16/bias:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv17/kernel:0' shape=(3, 3, 16, 3) dtype=float32_ref>, <tf.Variable 'inpaint_net/conv17/bias:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv1/kernel:0' shape=(5, 5, 5, 32) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv1/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv2_downsample/kernel:0' shape=(3, 3, 32, 32) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv2_downsample/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv3/kernel:0' shape=(3, 3, 32, 64) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv3/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv4_downsample/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv4_downsample/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv5/kernel:0' shape=(3, 3, 64, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv5/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv6/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv6/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv7_atrous/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv7_atrous/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv8_atrous/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv8_atrous/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv9_atrous/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv9_atrous/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv10_atrous/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/xconv10_atrous/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv1/kernel:0' shape=(5, 5, 5, 32) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv1/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv2_downsample/kernel:0' shape=(3, 3, 32, 32) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv2_downsample/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv3/kernel:0' shape=(3, 3, 32, 64) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv3/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv4_downsample/kernel:0' shape=(3, 3, 64, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv4_downsample/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv5/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv5/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv6/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv6/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv9/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv9/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv10/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/pmconv10/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv11/kernel:0' shape=(3, 3, 256, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv11/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv12/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv12/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv13_upsample/allconv13_upsample_conv/kernel:0' shape=(3, 3, 128, 64) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv13_upsample/allconv13_upsample_conv/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv14/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv14/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv15_upsample/allconv15_upsample_conv/kernel:0' shape=(3, 3, 64, 32) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv15_upsample/allconv15_upsample_conv/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv16/kernel:0' shape=(3, 3, 32, 16) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv16/bias:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv17/kernel:0' shape=(3, 3, 16, 3) dtype=float32_ref>, <tf.Variable 'inpaint_net/allconv17/bias:0' shape=(3,) dtype=float32_ref>]
[32m[2019-03-17 11:14:10 @trainer.py:63][0m sess_config: gpu_options {
  allow_growth: true
}
allow_soft_placement: true

[32m[2019-03-17 11:14:10 @trainer.py:63][0m log_dir: model_logs/20190317111349169013_10-255-0-254_mine_NORMAL_wgan_gp_full_model_celeba_hq_256
[32m[2019-03-17 11:14:10 @trainer.py:63][0m global_step_add_one: Tensor("add_one_to_global_step:0", shape=(), dtype=int32_ref)
[32m[2019-03-17 11:14:10 @trainer.py:63][0m summary_writer: <tensorflow.python.summary.writer.writer.FileWriter object at 0x7f3861ca8ef0>
[32m[2019-03-17 11:14:10 @trainer.py:63][0m feed_dict: {}
[32m[2019-03-17 11:14:10 @trainer.py:63][0m max_iters: 100000
[32m[2019-03-17 11:14:10 @trainer.py:63][0m graph_def: <function multigpu_graph_def at 0x7f38ee33cf28>
[32m[2019-03-17 11:14:10 @trainer.py:63][0m global_step: <tf.Variable 'global_step:0' shape=() dtype=int32_ref>
[32m[2019-03-17 11:14:10 @trainer.py:63][0m graph_def_kwargs: {'config': {}, 'loss_type': 'g', 'data': <neuralgym.data.data_from_fnames.DataFromFNames object at 0x7f38664cf898>, 'model': <inpaint_model.InpaintCAModel object at 0x7f3866419ba8>}
[32m[2019-03-17 11:14:10 @trainer.py:64][0m --------------------------------------------------------------------------------
[32m[2019-03-17 11:14:12 @logger.py:43][0m [32;1mTrigger callback: [0mTrigger WeightsViewer: logging model weights...
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv1/kernel:0, shape: [5, 5, 5, 32], size: 4000
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv1/bias:0, shape: [32], size: 32
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv2_downsample/kernel:0, shape: [3, 3, 32, 64], size: 18432
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv2_downsample/bias:0, shape: [64], size: 64
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv3/kernel:0, shape: [3, 3, 64, 64], size: 36864
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv3/bias:0, shape: [64], size: 64
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv4_downsample/kernel:0, shape: [3, 3, 64, 128], size: 73728
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv4_downsample/bias:0, shape: [128], size: 128
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv5/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv5/bias:0, shape: [128], size: 128
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv6/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv6/bias:0, shape: [128], size: 128
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv7_atrous/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv7_atrous/bias:0, shape: [128], size: 128
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv8_atrous/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv8_atrous/bias:0, shape: [128], size: 128
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv9_atrous/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv9_atrous/bias:0, shape: [128], size: 128
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv10_atrous/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv10_atrous/bias:0, shape: [128], size: 128
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv11/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv11/bias:0, shape: [128], size: 128
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv12/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv12/bias:0, shape: [128], size: 128
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv13_upsample/conv13_upsample_conv/kernel:0, shape: [3, 3, 128, 64], size: 73728
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv13_upsample/conv13_upsample_conv/bias:0, shape: [64], size: 64
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv14/kernel:0, shape: [3, 3, 64, 64], size: 36864
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv14/bias:0, shape: [64], size: 64
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv15_upsample/conv15_upsample_conv/kernel:0, shape: [3, 3, 64, 32], size: 18432
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv15_upsample/conv15_upsample_conv/bias:0, shape: [32], size: 32
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv16/kernel:0, shape: [3, 3, 32, 16], size: 4608
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv16/bias:0, shape: [16], size: 16
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv17/kernel:0, shape: [3, 3, 16, 3], size: 432
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/conv17/bias:0, shape: [3], size: 3
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv1/kernel:0, shape: [5, 5, 5, 32], size: 4000
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv1/bias:0, shape: [32], size: 32
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv2_downsample/kernel:0, shape: [3, 3, 32, 32], size: 9216
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv2_downsample/bias:0, shape: [32], size: 32
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv3/kernel:0, shape: [3, 3, 32, 64], size: 18432
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv3/bias:0, shape: [64], size: 64
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv4_downsample/kernel:0, shape: [3, 3, 64, 64], size: 36864
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv4_downsample/bias:0, shape: [64], size: 64
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv5/kernel:0, shape: [3, 3, 64, 128], size: 73728
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv5/bias:0, shape: [128], size: 128
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv6/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv6/bias:0, shape: [128], size: 128
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv7_atrous/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv7_atrous/bias:0, shape: [128], size: 128
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv8_atrous/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv8_atrous/bias:0, shape: [128], size: 128
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv9_atrous/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv9_atrous/bias:0, shape: [128], size: 128
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv10_atrous/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/xconv10_atrous/bias:0, shape: [128], size: 128
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv1/kernel:0, shape: [5, 5, 5, 32], size: 4000
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv1/bias:0, shape: [32], size: 32
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv2_downsample/kernel:0, shape: [3, 3, 32, 32], size: 9216
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv2_downsample/bias:0, shape: [32], size: 32
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv3/kernel:0, shape: [3, 3, 32, 64], size: 18432
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv3/bias:0, shape: [64], size: 64
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv4_downsample/kernel:0, shape: [3, 3, 64, 128], size: 73728
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv4_downsample/bias:0, shape: [128], size: 128
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv5/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv5/bias:0, shape: [128], size: 128
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv6/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv6/bias:0, shape: [128], size: 128
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv9/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv9/bias:0, shape: [128], size: 128
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv10/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/pmconv10/bias:0, shape: [128], size: 128
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv11/kernel:0, shape: [3, 3, 256, 128], size: 294912
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv11/bias:0, shape: [128], size: 128
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv12/kernel:0, shape: [3, 3, 128, 128], size: 147456
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv12/bias:0, shape: [128], size: 128
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv13_upsample/allconv13_upsample_conv/kernel:0, shape: [3, 3, 128, 64], size: 73728
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv13_upsample/allconv13_upsample_conv/bias:0, shape: [64], size: 64
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv14/kernel:0, shape: [3, 3, 64, 64], size: 36864
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv14/bias:0, shape: [64], size: 64
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv15_upsample/allconv15_upsample_conv/kernel:0, shape: [3, 3, 64, 32], size: 18432
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv15_upsample/allconv15_upsample_conv/bias:0, shape: [32], size: 32
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv16/kernel:0, shape: [3, 3, 32, 16], size: 4608
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv16/bias:0, shape: [16], size: 16
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv17/kernel:0, shape: [3, 3, 16, 3], size: 432
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: inpaint_net/allconv17/bias:0, shape: [3], size: 3
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_local/conv1/kernel:0, shape: [5, 5, 3, 64], size: 4800
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_local/conv1/bias:0, shape: [64], size: 64
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_local/conv2/kernel:0, shape: [5, 5, 64, 128], size: 204800
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_local/conv2/bias:0, shape: [128], size: 128
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_local/conv3/kernel:0, shape: [5, 5, 128, 256], size: 819200
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_local/conv3/bias:0, shape: [256], size: 256
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_local/conv4/kernel:0, shape: [5, 5, 256, 512], size: 3276800
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_local/conv4/bias:0, shape: [512], size: 512
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_global/conv1/kernel:0, shape: [5, 5, 3, 64], size: 4800
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_global/conv1/bias:0, shape: [64], size: 64
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_global/conv2/kernel:0, shape: [5, 5, 64, 128], size: 204800
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_global/conv2/bias:0, shape: [128], size: 128
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_global/conv3/kernel:0, shape: [5, 5, 128, 256], size: 819200
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_global/conv3/bias:0, shape: [256], size: 256
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_global/conv4/kernel:0, shape: [5, 5, 256, 256], size: 1638400
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: discriminator/discriminator_global/conv4/bias:0, shape: [256], size: 256
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: discriminator/dout_local_fc/kernel:0, shape: [32768, 1], size: 32768
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: discriminator/dout_local_fc/bias:0, shape: [1], size: 1
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: discriminator/dout_global_fc/kernel:0, shape: [65536, 1], size: 65536
[32m[2019-03-17 11:14:12 @weights_viewer.py:43][0m - weight name: discriminator/dout_global_fc/bias:0, shape: [1], size: 1
[32m[2019-03-17 11:14:12 @logger.py:43][0m [32;1mTrigger callback: [0mTotal counts of trainable weights: 10674312.
[32m[2019-03-17 11:14:12 @weights_viewer.py:60][0m Total size of trainable weights: 0G 10M 184K 136B (Assuming32-bit data type.)
[32m[2019-03-17 11:14:12 @logger.py:43][0m [32;1mTrigger callback: [0mTrigger ModelRestorer: Load model from models/release_imagenet_256/snap-0.
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/allconv11/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/allconv11/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/allconv12/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/allconv12/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/allconv13_upsample/allconv13_upsample_conv/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/allconv13_upsample/allconv13_upsample_conv/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/allconv14/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/allconv14/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/allconv15_upsample/allconv15_upsample_conv/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/allconv15_upsample/allconv15_upsample_conv/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/allconv16/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/allconv16/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/allconv17/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/allconv17/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv1/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv1/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv10_atrous/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv10_atrous/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv11/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv11/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv12/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv12/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv13_upsample/conv13_upsample_conv/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv13_upsample/conv13_upsample_conv/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv14/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv14/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv15_upsample/conv15_upsample_conv/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv15_upsample/conv15_upsample_conv/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv16/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv16/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv17/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv17/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv2_downsample/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv2_downsample/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv3/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv3/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv4_downsample/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv4_downsample/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv5/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv5/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv6/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv6/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv7_atrous/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv7_atrous/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv8_atrous/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv8_atrous/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv9_atrous/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/conv9_atrous/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/pmconv1/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/pmconv1/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/pmconv10/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/pmconv10/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/pmconv2_downsample/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/pmconv2_downsample/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/pmconv3/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/pmconv3/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/pmconv4_downsample/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/pmconv4_downsample/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/pmconv5/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/pmconv5/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/pmconv6/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/pmconv6/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/pmconv9/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/pmconv9/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/xconv1/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/xconv1/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/xconv10_atrous/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/xconv10_atrous/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/xconv2_downsample/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/xconv2_downsample/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/xconv3/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/xconv3/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/xconv4_downsample/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/xconv4_downsample/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/xconv5/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/xconv5/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/xconv6/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/xconv6/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/xconv7_atrous/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/xconv7_atrous/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/xconv8_atrous/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/xconv8_atrous/kernel:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/xconv9_atrous/bias:0
[32m[2019-03-17 11:14:12 @model_restorer.py:60][0m - restoring variable: inpaint_net/xconv9_atrous/kernel:0
2019-03-17 11:14:45.178226: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.52GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-03-17 11:14:45.216249: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.08GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-03-17 11:14:45.390686: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.29GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-03-17 11:14:45.419263: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.06GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-03-17 11:14:45.564984: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.16GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-03-17 11:14:45.638340: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.28GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
[2K|--------------------| 1.00%, 83/8217 sec. train epoch 1, iter 10/1000, loss 0.135270, 0.25 batches/sec.[2K|--------------------| 2.00%, 133/4883 sec. train epoch 1, iter 20/1000, loss 0.137184, 0.22 batches/sec.[2K|#-------------------| 3.00%, 183/4860 sec. train epoch 1, iter 30/1000, loss 0.121050, 0.21 batches/sec.[2K|#-------------------| 4.00%, 233/4822 sec. train epoch 1, iter 40/1000, loss 0.128104, 0.21 batches/sec.[2K|#-------------------| 5.00%, 284/4788 sec. train epoch 1, iter 50/1000, loss 0.138129, 0.21 batches/sec.[2K|#-------------------| 6.00%, 334/4754 sec. train epoch 1, iter 60/1000, loss 0.131283, 0.21 batches/sec.[2K|#-------------------| 7.00%, 385/4708 sec. train epoch 1, iter 70/1000, loss 0.125191, 0.20 batches/sec.[2K|##------------------| 8.00%, 435/4663 sec. train epoch 1, iter 80/1000, loss 0.119369, 0.20 batches/sec.[2K|##------------------| 9.00%, 486/4610 sec. train epoch 1, iter 90/1000, loss 0.114679, 0.20 batches/sec.[2K|##------------------| 10.00%, 537/4569 sec. train epoch 1, iter 100/1000, loss 0.107651, 0.20 batches/sec.[2K|##------------------| 11.00%, 588/4529 sec. train epoch 1, iter 110/1000, loss 0.102448, 0.20 batches/sec.[2K|##------------------| 12.00%, 639/4484 sec. train epoch 1, iter 120/1000, loss 0.104614, 0.20 batches/sec.[2K|###-----------------| 13.00%, 690/4429 sec. train epoch 1, iter 130/1000, loss 0.106775, 0.20 batches/sec.[2K|###-----------------| 14.00%, 741/4383 sec. train epoch 1, iter 140/1000, loss 0.116113, 0.20 batches/sec.[2K|###-----------------| 15.00%, 792/4330 sec. train epoch 1, iter 150/1000, loss 0.117204, 0.20 batches/sec.[2K|###-----------------| 16.00%, 842/4262 sec. train epoch 1, iter 160/1000, loss 0.115416, 0.20 batches/sec.[2K|###-----------------| 17.00%, 893/4211 sec. train epoch 1, iter 170/1000, loss 0.119117, 0.20 batches/sec.[2K|####----------------| 18.00%, 944/4163 sec. train epoch 1, iter 180/1000, loss 0.122788, 0.20 batches/sec.[2K|####----------------| 19.00%, 994/4108 sec. train epoch 1, iter 190/1000, loss 0.124402, 0.20 batches/sec.[2K|####----------------| 20.00%, 1045/4064 sec. train epoch 1, iter 200/1000, loss 0.124629, 0.20 batches/sec.[2K|####----------------| 21.00%, 1096/4013 sec. train epoch 1, iter 210/1000, loss 0.125138, 0.20 batches/sec.[2K|####----------------| 22.00%, 1147/3964 sec. train epoch 1, iter 220/1000, loss 0.124637, 0.20 batches/sec.[2K|#####---------------| 23.00%, 1198/3913 sec. train epoch 1, iter 230/1000, loss 0.123452, 0.20 batches/sec.[2K|#####---------------| 24.00%, 1248/3855 sec. train epoch 1, iter 240/1000, loss 0.123213, 0.20 batches/sec.[2K|#####---------------| 25.00%, 1299/3810 sec. train epoch 1, iter 250/1000, loss 0.124595, 0.20 batches/sec.[2K|#####---------------| 26.00%, 1350/3758 sec. train epoch 1, iter 260/1000, loss 0.124723, 0.20 batches/sec.[2K|#####---------------| 27.00%, 1401/3709 sec. train epoch 1, iter 270/1000, loss 0.125025, 0.20 batches/sec.[2K|######--------------| 28.00%, 1452/3653 sec. train epoch 1, iter 280/1000, loss 0.126672, 0.20 batches/sec.[2K|######--------------| 29.00%, 1502/3607 sec. train epoch 1, iter 290/1000, loss 0.125796, 0.20 batches/sec.[2K|######--------------| 30.00%, 1553/3561 sec. train epoch 1, iter 300/1000, loss 0.125917, 0.20 batches/sec.[2K|######--------------| 31.00%, 1604/3509 sec. train epoch 1, iter 310/1000, loss 0.126696, 0.20 batches/sec.[2K|######--------------| 32.00%, 1655/3446 sec. train epoch 1, iter 320/1000, loss 0.129160, 0.20 batches/sec.[2K|#######-------------| 33.00%, 1706/3402 sec. train epoch 1, iter 330/1000, loss 0.129869, 0.20 batches/sec.[2K|#######-------------| 34.00%, 1756/3351 sec. train epoch 1, iter 340/1000, loss 0.131906, 0.20 batches/sec.[2K|#######-------------| 35.00%, 1807/3300 sec. train epoch 1, iter 350/1000, loss 0.133606, 0.20 batches/sec.[2K|#######-------------| 36.00%, 1858/3255 sec. train epoch 1, iter 360/1000, loss 0.136302, 0.20 batches/sec.[2K|#######-------------| 37.00%, 1909/3203 sec. train epoch 1, iter 370/1000, loss 0.135870, 0.20 batches/sec.[2K|########------------| 38.00%, 1960/3154 sec. train epoch 1, iter 380/1000, loss 0.134734, 0.20 batches/sec.[2K|########------------| 39.00%, 2010/3100 sec. train epoch 1, iter 390/1000, loss 0.134364, 0.20 batches/sec.[2K|########------------| 40.00%, 2061/3047 sec. train epoch 1, iter 400/1000, loss 0.135039, 0.20 batches/sec.[2K|########------------| 41.00%, 2112/2992 sec. train epoch 1, iter 410/1000, loss 0.136265, 0.20 batches/sec.[2K|########------------| 42.00%, 2163/2948 sec. train epoch 1, iter 420/1000, loss 0.136440, 0.20 batches/sec.[2K|#########-----------| 43.00%, 2214/2898 sec. train epoch 1, iter 430/1000, loss 0.135898, 0.20 batches/sec.[2K|#########-----------| 44.00%, 2265/2847 sec. train epoch 1, iter 440/1000, loss 0.135356, 0.20 batches/sec.[2K|#########-----------| 45.00%, 2315/2785 sec. train epoch 1, iter 450/1000, loss 0.133326, 0.20 batches/sec.[2K|#########-----------| 46.00%, 2365/2697 sec. train epoch 1, iter 460/1000, loss 0.135569, 0.20 batches/sec.[2K|#########-----------| 47.00%, 2415/2664 sec. train epoch 1, iter 470/1000, loss 0.133872, 0.20 batches/sec.[2K|##########----------| 48.00%, 2465/2604 sec. train epoch 1, iter 480/1000, loss 0.134201, 0.20 batches/sec.[2K|##########----------| 49.00%, 2516/2565 sec. train epoch 1, iter 490/1000, loss 0.134916, 0.20 batches/sec.[2K|##########----------| 50.00%, 2566/2511 sec. train epoch 1, iter 500/1000, loss 0.135176, 0.20 batches/sec.[2K|##########----------| 51.00%, 2616/2461 sec. train epoch 1, iter 510/1000, loss 0.136022, 0.20 batches/sec.[2K|##########----------| 52.00%, 2666/2408 sec. train epoch 1, iter 520/1000, loss 0.136020, 0.20 batches/sec.[2K|###########---------| 53.00%, 2717/2359 sec. train epoch 1, iter 530/1000, loss 0.136282, 0.20 batches/sec.[2K|###########---------| 54.00%, 2767/2311 sec. train epoch 1, iter 540/1000, loss 0.136262, 0.20 batches/sec.[2K|###########---------| 55.00%, 2817/2258 sec. train epoch 1, iter 550/1000, loss 0.138639, 0.20 batches/sec.[2K|###########---------| 56.00%, 2867/2212 sec. train epoch 1, iter 560/1000, loss 0.139253, 0.20 batches/sec.[2K|###########---------| 57.00%, 2918/2160 sec. train epoch 1, iter 570/1000, loss 0.138516, 0.20 batches/sec.[2K|############--------| 58.00%, 2968/2106 sec. train epoch 1, iter 580/1000, loss 0.138104, 0.20 batches/sec.[2K|############--------| 59.00%, 3018/2060 sec. train epoch 1, iter 590/1000, loss 0.138712, 0.20 batches/sec.[2K|############--------| 60.00%, 3068/2009 sec. train epoch 1, iter 600/1000, loss 0.139373, 0.20 batches/sec.[2K|############--------| 61.00%, 3118/1963 sec. train epoch 1, iter 610/1000, loss 0.140659, 0.20 batches/sec.[2K|############--------| 62.00%, 3169/1906 sec. train epoch 1, iter 620/1000, loss 0.141484, 0.20 batches/sec.[2K|#############-------| 63.00%, 3219/1857 sec. train epoch 1, iter 630/1000, loss 0.141856, 0.20 batches/sec.[2K|#############-------| 64.00%, 3269/1810 sec. train epoch 1, iter 640/1000, loss 0.143772, 0.20 batches/sec.[2K|#############-------| 65.00%, 3319/1756 sec. train epoch 1, iter 650/1000, loss 0.144263, 0.20 batches/sec.[2K|#############-------| 66.00%, 3370/1709 sec. train epoch 1, iter 660/1000, loss 0.143745, 0.20 batches/sec.[2K|#############-------| 67.00%, 3420/1656 sec. train epoch 1, iter 670/1000, loss 0.143351, 0.20 batches/sec.[2K|##############------| 68.00%, 3470/1607 sec. train epoch 1, iter 680/1000, loss 0.141780, 0.20 batches/sec.[2K|##############------| 69.00%, 3520/1556 sec. train epoch 1, iter 690/1000, loss 0.143818, 0.20 batches/sec.[2K|##############------| 70.00%, 3570/1509 sec. train epoch 1, iter 700/1000, loss 0.145227, 0.20 batches/sec.[2K|##############------| 71.00%, 3621/1460 sec. train epoch 1, iter 710/1000, loss 0.143983, 0.20 batches/sec.[2K|##############------| 72.00%, 3671/1405 sec. train epoch 1, iter 720/1000, loss 0.145229, 0.20 batches/sec.[2K|###############-----| 73.00%, 3721/1358 sec. train epoch 1, iter 730/1000, loss 0.145514, 0.20 batches/sec.[32m[2019-03-17 12:38:41 @logger.py:146][0m [2K|####################| 100.00%, 5078/0 sec. train epoch 1, iter 1000/1000, loss 0.142189, 0.20 batches/sec.
[32m[2019-03-17 12:38:45 @logger.py:43][0m [32;1mTrigger callback: [0mTrigger ModelSaver: Save model to model_logs/20190317111349169013_10-255-0-254_mine_NORMAL_wgan_gp_full_model_celeba_hq_256/snap-1000.
[2K|###############-----| 74.00%, 3771/1305 sec. train epoch 1, iter 740/1000, loss 0.146397, 0.20 batches/sec.[2K|###############-----| 75.00%, 3822/1255 sec. train epoch 1, iter 750/1000, loss 0.145159, 0.20 batches/sec.[2K|###############-----| 76.00%, 3872/1207 sec. train epoch 1, iter 760/1000, loss 0.144906, 0.20 batches/sec.[2K|###############-----| 77.00%, 3922/1155 sec. train epoch 1, iter 770/1000, loss 0.143470, 0.20 batches/sec.[2K|################----| 78.00%, 3972/1105 sec. train epoch 1, iter 780/1000, loss 0.144370, 0.20 batches/sec.[2K|################----| 79.00%, 4023/1055 sec. train epoch 1, iter 790/1000, loss 0.145511, 0.20 batches/sec.[2K|################----| 80.00%, 4073/1006 sec. train epoch 1, iter 800/1000, loss 0.145596, 0.20 batches/sec.[2K|################----| 81.00%, 4123/955 sec. train epoch 1, iter 810/1000, loss 0.145128, 0.20 batches/sec.[2K|################----| 82.00%, 4173/905 sec. train epoch 1, iter 820/1000, loss 0.145689, 0.20 batches/sec.[2K|#################---| 83.00%, 4224/855 sec. train epoch 1, iter 830/1000, loss 0.145511, 0.20 batches/sec.[2K|#################---| 84.00%, 4274/803 sec. train epoch 1, iter 840/1000, loss 0.144446, 0.20 batches/sec.[2K|#################---| 85.00%, 4324/755 sec. train epoch 1, iter 850/1000, loss 0.142802, 0.20 batches/sec.[2K|#################---| 86.00%, 4374/703 sec. train epoch 1, iter 860/1000, loss 0.143056, 0.20 batches/sec.[2K|#################---| 87.00%, 4425/653 sec. train epoch 1, iter 870/1000, loss 0.142986, 0.20 batches/sec.[2K|##################--| 88.00%, 4475/603 sec. train epoch 1, iter 880/1000, loss 0.142576, 0.20 batches/sec.[2K|##################--| 89.00%, 4525/552 sec. train epoch 1, iter 890/1000, loss 0.143706, 0.20 batches/sec.[2K|##################--| 90.00%, 4575/503 sec. train epoch 1, iter 900/1000, loss 0.143712, 0.20 batches/sec.[2K|##################--| 91.00%, 4626/452 sec. train epoch 1, iter 910/1000, loss 0.143541, 0.20 batches/sec.[2K|##################--| 92.00%, 4676/402 sec. train epoch 1, iter 920/1000, loss 0.144025, 0.20 batches/sec.[2K|###################-| 93.00%, 4726/352 sec. train epoch 1, iter 930/1000, loss 0.144458, 0.20 batches/sec.[2K|###################-| 94.00%, 4776/301 sec. train epoch 1, iter 940/1000, loss 0.143509, 0.20 batches/sec.[2K|###################-| 95.00%, 4827/252 sec. train epoch 1, iter 950/1000, loss 0.143169, 0.20 batches/sec.[2K|###################-| 96.00%, 4877/201 sec. train epoch 1, iter 960/1000, loss 0.143493, 0.20 batches/sec.[2K|###################-| 97.00%, 4927/151 sec. train epoch 1, iter 970/1000, loss 0.142922, 0.20 batches/sec.[2K|####################| 98.00%, 4977/101 sec. train epoch 1, iter 980/1000, loss 0.142542, 0.20 batches/sec.[2K|####################| 99.00%, 5028/50 sec. train epoch 1, iter 990/1000, loss 0.142201, 0.20 batches/sec.[2K|--------------------| 1.00%, 110/10877 sec. train epoch 2, iter 10/1000, loss 0.045252, 0.10 batches/sec.[2K|--------------------| 2.00%, 160/4925 sec. train epoch 2, iter 20/1000, loss 0.037298, 0.13 batches/sec.[2K|#-------------------| 3.00%, 210/4869 sec. train epoch 2, iter 30/1000, loss 0.074430, 0.15 batches/sec.[2K|#-------------------| 4.00%, 261/4830 sec. train epoch 2, iter 40/1000, loss 0.079748, 0.16 batches/sec.[2K|#-------------------| 5.00%, 311/4771 sec. train epoch 2, iter 50/1000, loss 0.044384, 0.16 batches/sec.[2K|#-------------------| 6.00%, 361/4723 sec. train epoch 2, iter 60/1000, loss 0.088959, 0.17 batches/sec.[2K|#-------------------| 7.00%, 411/4675 sec. train epoch 2, iter 70/1000, loss 0.097547, 0.17 batches/sec.[2K|##------------------| 8.00%, 462/4631 sec. train epoch 2, iter 80/1000, loss 0.106261, 0.18 batches/sec.[2K|##------------------| 9.00%, 512/4574 sec. train epoch 2, iter 90/1000, loss 0.092882, 0.18 batches/sec.[2K|##------------------| 10.00%, 562/4521 sec. train epoch 2, iter 100/1000, loss 0.098203, 0.18 batches/sec.[2K|##------------------| 11.00%, 612/4476 sec. train epoch 2, iter 110/1000, loss 0.097548, 0.18 batches/sec.[2K|##------------------| 12.00%, 663/4425 sec. train epoch 2, iter 120/1000, loss 0.105121, 0.18 batches/sec.[2K|###-----------------| 13.00%, 713/4373 sec. train epoch 2, iter 130/1000, loss 0.112696, 0.18 batches/sec.[2K|###-----------------| 14.00%, 763/4327 sec. train epoch 2, iter 140/1000, loss 0.111318, 0.19 batches/sec.[2K|###-----------------| 15.00%, 814/4270 sec. train epoch 2, iter 150/1000, loss 0.106566, 0.19 batches/sec.[2K|###-----------------| 16.00%, 864/4231 sec. train epoch 2, iter 160/1000, loss 0.101117, 0.19 batches/sec.[2K|###-----------------| 17.00%, 914/4171 sec. train epoch 2, iter 170/1000, loss 0.108779, 0.19 batches/sec.[2K|####----------------| 18.00%, 965/4128 sec. train epoch 2, iter 180/1000, loss 0.115755, 0.19 batches/sec.[2K|####----------------| 19.00%, 1015/4078 sec. train epoch 2, iter 190/1000, loss 0.113000, 0.19 batches/sec.[2K|####----------------| 20.00%, 1065/4020 sec. train epoch 2, iter 200/1000, loss 0.118580, 0.19 batches/sec.[2K|####----------------| 21.00%, 1115/3972 sec. train epoch 2, iter 210/1000, loss 0.125778, 0.19 batches/sec.[2K|####----------------| 22.00%, 1166/3918 sec. train epoch 2, iter 220/1000, loss 0.114909, 0.19 batches/sec.[2K|#####---------------| 23.00%, 1216/3874 sec. train epoch 2, iter 230/1000, loss 0.115574, 0.19 batches/sec.[2K|#####---------------| 24.00%, 1266/3821 sec. train epoch 2, iter 240/1000, loss 0.113436, 0.19 batches/sec.[2K|#####---------------| 25.00%, 1317/3770 sec. train epoch 2, iter 250/1000, loss 0.112667, 0.19 batches/sec.[2K|#####---------------| 26.00%, 1367/3725 sec. train epoch 2, iter 260/1000, loss 0.112789, 0.19 batches/sec.[2K|#####---------------| 27.00%, 1417/3670 sec. train epoch 2, iter 270/1000, loss 0.105376, 0.19 batches/sec.[2K|######--------------| 28.00%, 1467/3627 sec. train epoch 2, iter 280/1000, loss 0.110571, 0.19 batches/sec.[2K|######--------------| 29.00%, 1518/3569 sec. train epoch 2, iter 290/1000, loss 0.111193, 0.19 batches/sec.[2K|######--------------| 30.00%, 1568/3520 sec. train epoch 2, iter 300/1000, loss 0.106491, 0.19 batches/sec.[2K|######--------------| 31.00%, 1618/3470 sec. train epoch 2, iter 310/1000, loss 0.101623, 0.19 batches/sec.[2K|######--------------| 32.00%, 1669/3418 sec. train epoch 2, iter 320/1000, loss 0.098312, 0.19 batches/sec.[2K|#######-------------| 33.00%, 1719/3373 sec. train epoch 2, iter 330/1000, loss 0.100604, 0.19 batches/sec.[2K|#######-------------| 34.00%, 1769/3317 sec. train epoch 2, iter 340/1000, loss 0.103894, 0.19 batches/sec.[2K|#######-------------| 35.00%, 1819/3267 sec. train epoch 2, iter 350/1000, loss 0.101451, 0.19 batches/sec.[2K|#######-------------| 36.00%, 1870/3214 sec. train epoch 2, iter 360/1000, loss 0.095995, 0.19 batches/sec.[2K|#######-------------| 37.00%, 1920/3165 sec. train epoch 2, iter 370/1000, loss 0.092739, 0.19 batches/sec.[2K|########------------| 38.00%, 1970/3120 sec. train epoch 2, iter 380/1000, loss 0.090513, 0.19 batches/sec.[2K|########------------| 39.00%, 2020/3064 sec. train epoch 2, iter 390/1000, loss 0.086964, 0.19 batches/sec.[2K|########------------| 40.00%, 2071/3021 sec. train epoch 2, iter 400/1000, loss 0.093163, 0.19 batches/sec.[2K|########------------| 41.00%, 2121/2966 sec. train epoch 2, iter 410/1000, loss 0.095991, 0.19 batches/sec.[2K|########------------| 42.00%, 2171/2914 sec. train epoch 2, iter 420/1000, loss 0.093177, 0.19 batches/sec.[2K|#########-----------| 43.00%, 2222/2870 sec. train epoch 2, iter 430/1000, loss 0.092144, 0.19 batches/sec.[2K|#########-----------| 44.00%, 2272/2810 sec. train epoch 2, iter 440/1000, loss 0.091959, 0.19 batches/sec.[2K|#########-----------| 45.00%, 2322/2771 sec. train epoch 2, iter 450/1000, loss 0.092473, 0.19 batches/sec.[2K|#########-----------| 46.00%, 2372/2713 sec. train epoch 2, iter 460/1000, loss 0.095050, 0.19 batches/sec.[2K|#########-----------| 47.00%, 2423/2666 sec. train epoch 2, iter 470/1000, loss 0.099020, 0.19 batches/sec.[32m[2019-03-17 14:03:31 @logger.py:146][0m [2K|####################| 100.00%, 5089/0 sec. train epoch 2, iter 1000/1000, loss 0.098268, 0.20 batches/sec.
[32m[2019-03-17 14:03:34 @logger.py:43][0m [32;1mTrigger callback: [0mTrigger ModelSaver: Save model to model_logs/20190317111349169013_10-255-0-254_mine_NORMAL_wgan_gp_full_model_celeba_hq_256/snap-2000.
[2K|##########----------| 48.00%, 2473/2611 sec. train epoch 2, iter 480/1000, loss 0.100962, 0.19 batches/sec.[2K|##########----------| 49.00%, 2523/2565 sec. train epoch 2, iter 490/1000, loss 0.099325, 0.19 batches/sec.[2K|##########----------| 50.00%, 2574/2513 sec. train epoch 2, iter 500/1000, loss 0.101767, 0.19 batches/sec.[2K|##########----------| 51.00%, 2624/2463 sec. train epoch 2, iter 510/1000, loss 0.104178, 0.19 batches/sec.[2K|##########----------| 52.00%, 2674/2414 sec. train epoch 2, iter 520/1000, loss 0.107208, 0.19 batches/sec.[2K|###########---------| 53.00%, 2724/2360 sec. train epoch 2, iter 530/1000, loss 0.105426, 0.20 batches/sec.[2K|###########---------| 54.00%, 2775/2314 sec. train epoch 2, iter 540/1000, loss 0.107823, 0.20 batches/sec.[2K|###########---------| 55.00%, 2825/2261 sec. train epoch 2, iter 550/1000, loss 0.111486, 0.20 batches/sec.[2K|###########---------| 56.00%, 2875/2212 sec. train epoch 2, iter 560/1000, loss 0.112587, 0.20 batches/sec.[2K|###########---------| 57.00%, 2925/2164 sec. train epoch 2, iter 570/1000, loss 0.113330, 0.20 batches/sec.[2K|############--------| 58.00%, 2976/2109 sec. train epoch 2, iter 580/1000, loss 0.117447, 0.20 batches/sec.[2K|############--------| 59.00%, 3026/2066 sec. train epoch 2, iter 590/1000, loss 0.120195, 0.20 batches/sec.[2K|############--------| 60.00%, 3076/2009 sec. train epoch 2, iter 600/1000, loss 0.119420, 0.20 batches/sec.[2K|############--------| 61.00%, 3127/1959 sec. train epoch 2, iter 610/1000, loss 0.120628, 0.20 batches/sec.[2K|############--------| 62.00%, 3177/1910 sec. train epoch 2, iter 620/1000, loss 0.120866, 0.20 batches/sec.[2K|#############-------| 63.00%, 3227/1858 sec. train epoch 2, iter 630/1000, loss 0.124451, 0.20 batches/sec.[2K|#############-------| 64.00%, 3277/1814 sec. train epoch 2, iter 640/1000, loss 0.124490, 0.20 batches/sec.[2K|#############-------| 65.00%, 3328/1757 sec. train epoch 2, iter 650/1000, loss 0.122456, 0.20 batches/sec.[2K|#############-------| 66.00%, 3378/1708 sec. train epoch 2, iter 660/1000, loss 0.123997, 0.20 batches/sec.[2K|#############-------| 67.00%, 3428/1660 sec. train epoch 2, iter 670/1000, loss 0.120770, 0.20 batches/sec.[2K|##############------| 68.00%, 3478/1608 sec. train epoch 2, iter 680/1000, loss 0.117598, 0.20 batches/sec.[2K|##############------| 69.00%, 3529/1560 sec. train epoch 2, iter 690/1000, loss 0.116285, 0.20 batches/sec.[2K|##############------| 70.00%, 3579/1507 sec. train epoch 2, iter 700/1000, loss 0.114930, 0.20 batches/sec.[2K|##############------| 71.00%, 3629/1461 sec. train epoch 2, iter 710/1000, loss 0.114336, 0.20 batches/sec.[2K|##############------| 72.00%, 3680/1405 sec. train epoch 2, iter 720/1000, loss 0.113584, 0.20 batches/sec.[2K|###############-----| 73.00%, 3730/1358 sec. train epoch 2, iter 730/1000, loss 0.112071, 0.20 batches/sec.[2K|###############-----| 74.00%, 3780/1308 sec. train epoch 2, iter 740/1000, loss 0.108944, 0.20 batches/sec.[2K|###############-----| 75.00%, 3830/1256 sec. train epoch 2, iter 750/1000, loss 0.110328, 0.20 batches/sec.[2K|###############-----| 76.00%, 3881/1206 sec. train epoch 2, iter 760/1000, loss 0.106975, 0.20 batches/sec.[2K|###############-----| 77.00%, 3931/1156 sec. train epoch 2, iter 770/1000, loss 0.104731, 0.20 batches/sec.[2K|################----| 78.00%, 3981/1107 sec. train epoch 2, iter 780/1000, loss 0.104547, 0.20 batches/sec.[2K|################----| 79.00%, 4031/1056 sec. train epoch 2, iter 790/1000, loss 0.102665, 0.20 batches/sec.[2K|################----| 80.00%, 4082/1005 sec. train epoch 2, iter 800/1000, loss 0.099927, 0.20 batches/sec.[2K|################----| 81.00%, 4132/957 sec. train epoch 2, iter 810/1000, loss 0.098648, 0.20 batches/sec.[2K|################----| 82.00%, 4182/903 sec. train epoch 2, iter 820/1000, loss 0.097320, 0.20 batches/sec.[2K|#################---| 83.00%, 4233/856 sec. train epoch 2, iter 830/1000, loss 0.099144, 0.20 batches/sec.[2K|#################---| 84.00%, 4283/804 sec. train epoch 2, iter 840/1000, loss 0.097943, 0.20 batches/sec.[2K|#################---| 85.00%, 4333/753 sec. train epoch 2, iter 850/1000, loss 0.099993, 0.20 batches/sec.[2K|#################---| 86.00%, 4383/704 sec. train epoch 2, iter 860/1000, loss 0.097896, 0.20 batches/sec.[2K|#################---| 87.00%, 4434/653 sec. train epoch 2, iter 870/1000, loss 0.097208, 0.20 batches/sec.[2K|##################--| 88.00%, 4484/604 sec. train epoch 2, iter 880/1000, loss 0.098757, 0.20 batches/sec.[2K|##################--| 89.00%, 4534/554 sec. train epoch 2, iter 890/1000, loss 0.100148, 0.20 batches/sec.[2K|##################--| 90.00%, 4584/502 sec. train epoch 2, iter 900/1000, loss 0.098906, 0.20 batches/sec.[2K|##################--| 91.00%, 4635/453 sec. train epoch 2, iter 910/1000, loss 0.098091, 0.20 batches/sec.[2K|##################--| 92.00%, 4685/402 sec. train epoch 2, iter 920/1000, loss 0.098100, 0.20 batches/sec.[2K|###################-| 93.00%, 4735/352 sec. train epoch 2, iter 930/1000, loss 0.098016, 0.20 batches/sec.[2K|###################-| 94.00%, 4786/301 sec. train epoch 2, iter 940/1000, loss 0.099887, 0.20 batches/sec.[2K|###################-| 95.00%, 4836/251 sec. train epoch 2, iter 950/1000, loss 0.100259, 0.20 batches/sec.[2K|###################-| 96.00%, 4886/201 sec. train epoch 2, iter 960/1000, loss 0.098875, 0.20 batches/sec.[2K|###################-| 97.00%, 4937/152 sec. train epoch 2, iter 970/1000, loss 0.097815, 0.20 batches/sec.[2K|####################| 98.00%, 4987/101 sec. train epoch 2, iter 980/1000, loss 0.100574, 0.20 batches/sec.[2K|####################| 99.00%, 5038/51 sec. train epoch 2, iter 990/1000, loss 0.099138, 0.20 batches/sec.[2K|--------------------| 1.00%, 56/5498 sec. train epoch 3, iter 10/1000, loss 0.285217, 0.21 batches/sec.[2K|--------------------| 2.00%, 106/4985 sec. train epoch 3, iter 20/1000, loss 0.238696, 0.20 batches/sec.[2K|#-------------------| 3.00%, 157/4940 sec. train epoch 3, iter 30/1000, loss 0.174978, 0.20 batches/sec.[2K|#-------------------| 4.00%, 208/4889 sec. train epoch 3, iter 40/1000, loss 0.145658, 0.20 batches/sec.[2K|#-------------------| 5.00%, 259/4847 sec. train epoch 3, iter 50/1000, loss 0.130761, 0.20 batches/sec.[2K|#-------------------| 6.00%, 310/4787 sec. train epoch 3, iter 60/1000, loss 0.106812, 0.20 batches/sec.[2K|#-------------------| 7.00%, 361/4730 sec. train epoch 3, iter 70/1000, loss 0.073091, 0.20 batches/sec.[2K|##------------------| 8.00%, 412/4685 sec. train epoch 3, iter 80/1000, loss 0.082494, 0.20 batches/sec.[2K|##------------------| 9.00%, 463/4638 sec. train epoch 3, iter 90/1000, loss 0.085120, 0.20 batches/sec.[2K|##------------------| 10.00%, 514/4579 sec. train epoch 3, iter 100/1000, loss 0.081849, 0.20 batches/sec.[2K|##------------------| 11.00%, 565/4533 sec. train epoch 3, iter 110/1000, loss 0.097351, 0.20 batches/sec.[2K|##------------------| 12.00%, 616/4483 sec. train epoch 3, iter 120/1000, loss 0.108910, 0.20 batches/sec.[2K|###-----------------| 13.00%, 667/4426 sec. train epoch 3, iter 130/1000, loss 0.105826, 0.20 batches/sec.[2K|###-----------------| 14.00%, 717/4375 sec. train epoch 3, iter 140/1000, loss 0.111250, 0.20 batches/sec.[2K|###-----------------| 15.00%, 768/4324 sec. train epoch 3, iter 150/1000, loss 0.122538, 0.20 batches/sec.[2K|###-----------------| 16.00%, 819/4274 sec. train epoch 3, iter 160/1000, loss 0.137216, 0.20 batches/sec.[2K|###-----------------| 17.00%, 870/4220 sec. train epoch 3, iter 170/1000, loss 0.132279, 0.20 batches/sec.[2K|####----------------| 18.00%, 920/4117 sec. train epoch 3, iter 180/1000, loss 0.121683, 0.20 batches/sec.[2K|####----------------| 19.00%, 971/4071 sec. train epoch 3, iter 190/1000, loss 0.133146, 0.20 batches/sec.[2K|####----------------| 20.00%, 1021/4021 sec. train epoch 3, iter 200/1000, loss 0.126788, 0.20 batches/sec.[2K|####----------------| 21.00%, 1071/3974 sec. train epoch 3, iter 210/1000, loss 0.118299, 0.20 batches/sec.[2K|####----------------| 22.00%, 1121/3920 sec. train epoch 3, iter 220/1000, loss 0.114546, 0.20 batches/sec.[2K|#####---------------| 23.00%, 1172/3883 sec. train epoch 3, iter 230/1000, loss 0.123243, 0.20 batches/sec.[2K|#####---------------| 24.00%, 1222/3821 sec. train epoch 3, iter 240/1000, loss 0.132645, 0.20 batches/sec.[2K|#####---------------| 25.00%, 1272/3772 sec. train epoch 3, iter 250/1000, loss 0.125609, 0.20 batches/sec.[2K|#####---------------| 26.00%, 1323/3722 sec. train epoch 3, iter 260/1000, loss 0.130185, 0.20 batches/sec.[2K|#####---------------| 27.00%, 1373/3673 sec. train epoch 3, iter 270/1000, loss 0.123045, 0.20 batches/sec.[2K|######--------------| 28.00%, 1423/3626 sec. train epoch 3, iter 280/1000, loss 0.119234, 0.20 batches/sec.[2K|######--------------| 29.00%, 1474/3571 sec. train epoch 3, iter 290/1000, loss 0.119118, 0.20 batches/sec.[2K|######--------------| 30.00%, 1524/3523 sec. train epoch 3, iter 300/1000, loss 0.122031, 0.20 batches/sec.[2K|######--------------| 31.00%, 1574/3469 sec. train epoch 3, iter 310/1000, loss 0.115351, 0.20 batches/sec.[2K|######--------------| 32.00%, 1624/3418 sec. train epoch 3, iter 320/1000, loss 0.116141, 0.20 batches/sec.[2K|#######-------------| 33.00%, 1675/3374 sec. train epoch 3, iter 330/1000, loss 0.114197, 0.20 batches/sec.[2K|#######-------------| 34.00%, 1725/3318 sec. train epoch 3, iter 340/1000, loss 0.110525, 0.20 batches/sec.[2K|#######-------------| 35.00%, 1775/3270 sec. train epoch 3, iter 350/1000, loss 0.108306, 0.20 batches/sec.[2K|#######-------------| 36.00%, 1826/3216 sec. train epoch 3, iter 360/1000, loss 0.112577, 0.20 batches/sec.[2K|#######-------------| 37.00%, 1876/3173 sec. train epoch 3, iter 370/1000, loss 0.104238, 0.20 batches/sec.[2K|########------------| 38.00%, 1926/3118 sec. train epoch 3, iter 380/1000, loss 0.100978, 0.20 batches/sec.[2K|########------------| 39.00%, 1977/3067 sec. train epoch 3, iter 390/1000, loss 0.094343, 0.20 batches/sec.[2K|########------------| 40.00%, 2027/3022 sec. train epoch 3, iter 400/1000, loss 0.089141, 0.20 batches/sec.[2K|########------------| 41.00%, 2077/2965 sec. train epoch 3, iter 410/1000, loss 0.089617, 0.20 batches/sec.[2K|########------------| 42.00%, 2127/2915 sec. train epoch 3, iter 420/1000, loss 0.086256, 0.20 batches/sec.[2K|#########-----------| 43.00%, 2178/2868 sec. train epoch 3, iter 430/1000, loss 0.086097, 0.20 batches/sec.[2K|#########-----------| 44.00%, 2228/2818 sec. train epoch 3, iter 440/1000, loss 0.092890, 0.20 batches/sec.[2K|#########-----------| 45.00%, 2278/2772 sec. train epoch 3, iter 450/1000, loss 0.087889, 0.20 batches/sec.[2K|#########-----------| 46.00%, 2329/2714 sec. train epoch 3, iter 460/1000, loss 0.085842, 0.20 batches/sec.[2K|#########-----------| 47.00%, 2379/2673 sec. train epoch 3, iter 470/1000, loss 0.091952, 0.20 batches/sec.[2K|##########----------| 48.00%, 2429/2616 sec. train epoch 3, iter 480/1000, loss 0.090810, 0.20 batches/sec.[2K|##########----------| 49.00%, 2480/2563 sec. train epoch 3, iter 490/1000, loss 0.088671, 0.20 batches/sec.[2K|##########----------| 50.00%, 2530/2514 sec. train epoch 3, iter 500/1000, loss 0.083104, 0.20 batches/sec.[2K|##########----------| 51.00%, 2580/2463 sec. train epoch 3, iter 510/1000, loss 0.080926, 0.20 batches/sec.[2K|##########----------| 52.00%, 2631/2416 sec. train epoch 3, iter 520/1000, loss 0.078596, 0.20 batches/sec.[2K|###########---------| 53.00%, 2681/2360 sec. train epoch 3, iter 530/1000, loss 0.075598, 0.20 batches/sec.[2K|###########---------| 54.00%, 2731/2318 sec. train epoch 3, iter 540/1000, loss 0.075526, 0.20 batches/sec.[2K|###########---------| 55.00%, 2782/2264 sec. train epoch 3, iter 550/1000, loss 0.075326, 0.20 batches/sec.[2K|###########---------| 56.00%, 2832/2210 sec. train epoch 3, iter 560/1000, loss 0.072808, 0.20 batches/sec.[2K|###########---------| 57.00%, 2882/2167 sec. train epoch 3, iter 570/1000, loss 0.074761, 0.20 batches/sec.[2K|############--------| 58.00%, 2932/2111 sec. train epoch 3, iter 580/1000, loss 0.074744, 0.20 batches/sec.[2K|############--------| 59.00%, 2983/2066 sec. train epoch 3, iter 590/1000, loss 0.074163, 0.20 batches/sec.[2K|############--------| 60.00%, 3033/2011 sec. train epoch 3, iter 600/1000, loss 0.074338, 0.20 batches/sec.[2K|############--------| 61.00%, 3083/1962 sec. train epoch 3, iter 610/1000, loss 0.074165, 0.20 batches/sec.[2K|############--------| 62.00%, 3134/1913 sec. train epoch 3, iter 620/1000, loss 0.074861, 0.20 batches/sec.[2K|#############-------| 63.00%, 3184/1860 sec. train epoch 3, iter 630/1000, loss 0.075378, 0.20 batches/sec.[2K|#############-------| 64.00%, 3234/1813 sec. train epoch 3, iter 640/1000, loss 0.074581, 0.20 batches/sec.[2K|#############-------| 65.00%, 3285/1759 sec. train epoch 3, iter 650/1000, loss 0.076499, 0.20 batches/sec.[2K|#############-------| 66.00%, 3335/1713 sec. train epoch 3, iter 660/1000, loss 0.079060, 0.20 batches/sec.[2K|#############-------| 67.00%, 3385/1663 sec. train epoch 3, iter 670/1000, loss 0.077899, 0.20 batches/sec.[2K|##############------| 68.00%, 3436/1608 sec. train epoch 3, iter 680/1000, loss 0.077794, 0.20 batches/sec.[2K|##############------| 69.00%, 3486/1560 sec. train epoch 3, iter 690/1000, loss 0.075668, 0.20 batches/sec.[2K|##############------| 70.00%, 3536/1508 sec. train epoch 3, iter 700/1000, loss 0.073315, 0.20 batches/sec.[2K|##############------| 71.00%, 3587/1461 sec. train epoch 3, iter 710/1000, loss 0.075285, 0.20 batches/sec.[2K|##############------| 72.00%, 3637/1409 sec. train epoch 3, iter 720/1000, loss 0.074863, 0.20 batches/sec.[2K|###############-----| 73.00%, 3687/1357 sec. train epoch 3, iter 730/1000, loss 0.071175, 0.20 batches/sec.[2K|###############-----| 74.00%, 3738/1310 sec. train epoch 3, iter 740/1000, loss 0.074381, 0.20 batches/sec.[2K|###############-----| 75.00%, 3788/1258 sec. train epoch 3, iter 750/1000, loss 0.074367, 0.20 batches/sec.[2K|###############-----| 76.00%, 3838/1209 sec. train epoch 3, iter 760/1000, loss 0.076053, 0.20 batches/sec.[2K|###############-----| 77.00%, 3889/1157 sec. train epoch 3, iter 770/1000, loss 0.074179, 0.20 batches/sec.[2K|################----| 78.00%, 3939/1106 sec. train epoch 3, iter 780/1000, loss 0.076386, 0.20 batches/sec.[2K|################----| 79.00%, 3989/1056 sec. train epoch 3, iter 790/1000, loss 0.077408, 0.20 batches/sec.[2K|################----| 80.00%, 4039/1005 sec. train epoch 3, iter 800/1000, loss 0.077942, 0.20 batches/sec.[2K|################----| 81.00%, 4090/956 sec. train epoch 3, iter 810/1000, loss 0.078902, 0.20 batches/sec.[2K|################----| 82.00%, 4140/906 sec. train epoch 3, iter 820/1000, loss 0.077627, 0.20 batches/sec.[2K|#################---| 83.00%, 4190/855 sec. train epoch 3, iter 830/1000, loss 0.079589, 0.20 batches/sec.[2K|#################---| 84.00%, 4241/806 sec. train epoch 3, iter 840/1000, loss 0.079727, 0.20 batches/sec.[2K|#################---| 85.00%, 4291/754 sec. train epoch 3, iter 850/1000, loss 0.080166, 0.20 batches/sec.[2K|#################---| 86.00%, 4341/704 sec. train epoch 3, iter 860/1000, loss 0.082397, 0.20 batches/sec.[2K|#################---| 87.00%, 4391/653 sec. train epoch 3, iter 870/1000, loss 0.081808, 0.20 batches/sec.[2K|##################--| 88.00%, 4442/604 sec. train epoch 3, iter 880/1000, loss 0.081860, 0.20 batches/sec.[2K|##################--| 89.00%, 4492/553 sec. train epoch 3, iter 890/1000, loss 0.083716, 0.20 batches/sec.[2K|##################--| 90.00%, 4542/503 sec. train epoch 3, iter 900/1000, loss 0.087267, 0.20 batches/sec.[2K|##################--| 91.00%, 4593/453 sec. train epoch 3, iter 910/1000, loss 0.085711, 0.20 batches/sec.[2K|##################--| 92.00%, 4643/402 sec. train epoch 3, iter 920/1000, loss 0.085201, 0.20 batches/sec.[2K|###################-| 93.00%, 4693/352 sec. train epoch 3, iter 930/1000, loss 0.087380, 0.20 batches/sec.[2K|###################-| 94.00%, 4743/302 sec. train epoch 3, iter 940/1000, loss 0.087908, 0.20 batches/sec.[2K|###################-| 95.00%, 4794/252 sec. train epoch 3, iter 950/1000, loss 0.087756, 0.20 batches/sec.[32m[2019-03-17 15:27:36 @logger.py:146][0m [2K|####################| 100.00%, 5045/0 sec. train epoch 3, iter 1000/1000, loss 0.082214, 0.20 batches/sec.
[32m[2019-03-17 15:27:40 @logger.py:43][0m [32;1mTrigger callback: [0mTrigger ModelSaver: Save model to model_logs/20190317111349169013_10-255-0-254_mine_NORMAL_wgan_gp_full_model_celeba_hq_256/snap-3000.
[2K|###################-| 96.00%, 4844/201 sec. train epoch 3, iter 960/1000, loss 0.086357, 0.20 batches/sec.[2K|###################-| 97.00%, 4894/151 sec. train epoch 3, iter 970/1000, loss 0.084825, 0.20 batches/sec.[2K|####################| 98.00%, 4945/101 sec. train epoch 3, iter 980/1000, loss 0.083662, 0.20 batches/sec.[2K|####################| 99.00%, 4995/50 sec. train epoch 3, iter 990/1000, loss 0.084581, 0.20 batches/sec.[2K|--------------------| 1.00%, 55/5440 sec. train epoch 4, iter 10/1000, loss 0.145717, 0.21 batches/sec.[2K|--------------------| 2.00%, 105/4918 sec. train epoch 4, iter 20/1000, loss 0.142244, 0.20 batches/sec.[2K|#-------------------| 3.00%, 155/4878 sec. train epoch 4, iter 30/1000, loss 0.132094, 0.20 batches/sec.[2K|#-------------------| 4.00%, 206/4825 sec. train epoch 4, iter 40/1000, loss 0.149435, 0.20 batches/sec.[2K|#-------------------| 5.00%, 256/4775 sec. train epoch 4, iter 50/1000, loss 0.142263, 0.20 batches/sec.[2K|#-------------------| 6.00%, 306/4728 sec. train epoch 4, iter 60/1000, loss 0.117233, 0.20 batches/sec.[2K|#-------------------| 7.00%, 356/4671 sec. train epoch 4, iter 70/1000, loss 0.108185, 0.20 batches/sec.[2K|##------------------| 8.00%, 407/4630 sec. train epoch 4, iter 80/1000, loss 0.096657, 0.20 batches/sec.[2K|##------------------| 9.00%, 457/4572 sec. train epoch 4, iter 90/1000, loss 0.115191, 0.20 batches/sec.[2K|##------------------| 10.00%, 507/4525 sec. train epoch 4, iter 100/1000, loss 0.129118, 0.20 batches/sec.[2K|##------------------| 11.00%, 558/4478 sec. train epoch 4, iter 110/1000, loss 0.093524, 0.20 batches/sec.[2K|##------------------| 12.00%, 608/4419 sec. train epoch 4, iter 120/1000, loss 0.081767, 0.20 batches/sec.[2K|###-----------------| 13.00%, 658/4384 sec. train epoch 4, iter 130/1000, loss 0.077187, 0.20 batches/sec.[2K|###-----------------| 14.00%, 709/4325 sec. train epoch 4, iter 140/1000, loss 0.071033, 0.20 batches/sec.[2K|###-----------------| 15.00%, 759/4285 sec. train epoch 4, iter 150/1000, loss 0.057686, 0.20 batches/sec.[2K|###-----------------| 16.00%, 809/4226 sec. train epoch 4, iter 160/1000, loss 0.049664, 0.20 batches/sec.[2K|###-----------------| 17.00%, 860/4178 sec. train epoch 4, iter 170/1000, loss 0.049244, 0.20 batches/sec.[2K|####----------------| 18.00%, 910/4136 sec. train epoch 4, iter 180/1000, loss 0.043784, 0.20 batches/sec.[2K|####----------------| 19.00%, 960/4071 sec. train epoch 4, iter 190/1000, loss 0.043208, 0.20 batches/sec.[2K|####----------------| 20.00%, 1011/4028 sec. train epoch 4, iter 200/1000, loss 0.037847, 0.20 batches/sec.[2K|####----------------| 21.00%, 1061/3974 sec. train epoch 4, iter 210/1000, loss 0.043577, 0.20 batches/sec.[2K|####----------------| 22.00%, 1111/3928 sec. train epoch 4, iter 220/1000, loss 0.048788, 0.20 batches/sec.[2K|#####---------------| 23.00%, 1162/3879 sec. train epoch 4, iter 230/1000, loss 0.045448, 0.20 batches/sec.[2K|#####---------------| 24.00%, 1212/3820 sec. train epoch 4, iter 240/1000, loss 0.038237, 0.20 batches/sec.[2K|#####---------------| 25.00%, 1262/3779 sec. train epoch 4, iter 250/1000, loss 0.040331, 0.20 batches/sec.[2K|#####---------------| 26.00%, 1313/3723 sec. train epoch 4, iter 260/1000, loss 0.040015, 0.20 batches/sec.[2K|#####---------------| 27.00%, 1363/3673 sec. train epoch 4, iter 270/1000, loss 0.043748, 0.20 batches/sec.[2K|######--------------| 28.00%, 1413/3620 sec. train epoch 4, iter 280/1000, loss 0.047625, 0.20 batches/sec.[2K|######--------------| 29.00%, 1463/3568 sec. train epoch 4, iter 290/1000, loss 0.050483, 0.20 batches/sec.[2K|######--------------| 30.00%, 1514/3528 sec. train epoch 4, iter 300/1000, loss 0.045745, 0.20 batches/sec.[2K|######--------------| 31.00%, 1564/3469 sec. train epoch 4, iter 310/1000, loss 0.044997, 0.20 batches/sec.[2K|######--------------| 32.00%, 1615/3424 sec. train epoch 4, iter 320/1000, loss 0.043744, 0.20 batches/sec.[2K|#######-------------| 33.00%, 1665/3373 sec. train epoch 4, iter 330/1000, loss 0.037702, 0.20 batches/sec.[2K|#######-------------| 34.00%, 1715/3319 sec. train epoch 4, iter 340/1000, loss 0.034588, 0.20 batches/sec.[2K|#######-------------| 35.00%, 1765/3269 sec. train epoch 4, iter 350/1000, loss 0.033206, 0.20 batches/sec.[2K|#######-------------| 36.00%, 1816/3218 sec. train epoch 4, iter 360/1000, loss 0.028661, 0.20 batches/sec.[2K|#######-------------| 37.00%, 1866/3172 sec. train epoch 4, iter 370/1000, loss 0.030762, 0.20 batches/sec.[2K|########------------| 38.00%, 1916/3121 sec. train epoch 4, iter 380/1000, loss 0.033032, 0.20 batches/sec.[2K|########------------| 39.00%, 1967/3072 sec. train epoch 4, iter 390/1000, loss 0.031360, 0.20 batches/sec.[2K|########------------| 40.00%, 2017/3023 sec. train epoch 4, iter 400/1000, loss 0.035490, 0.20 batches/sec.[2K|########------------| 41.00%, 2067/2965 sec. train epoch 4, iter 410/1000, loss 0.035947, 0.20 batches/sec.[2K|########------------| 42.00%, 2118/2919 sec. train epoch 4, iter 420/1000, loss 0.037508, 0.20 batches/sec.[2K|#########-----------| 43.00%, 2168/2870 sec. train epoch 4, iter 430/1000, loss 0.041357, 0.20 batches/sec.[2K|#########-----------| 44.00%, 2218/2818 sec. train epoch 4, iter 440/1000, loss 0.042069, 0.20 batches/sec.[2K|#########-----------| 45.00%, 2269/2768 sec. train epoch 4, iter 450/1000, loss 0.044163, 0.20 batches/sec.[2K|#########-----------| 46.00%, 2319/2719 sec. train epoch 4, iter 460/1000, loss 0.042778, 0.20 batches/sec.[2K|#########-----------| 47.00%, 2369/2667 sec. train epoch 4, iter 470/1000, loss 0.039736, 0.20 batches/sec.[2K|##########----------| 48.00%, 2420/2613 sec. train epoch 4, iter 480/1000, loss 0.038001, 0.20 batches/sec.[2K|##########----------| 49.00%, 2470/2566 sec. train epoch 4, iter 490/1000, loss 0.040839, 0.20 batches/sec.[2K|##########----------| 50.00%, 2520/2511 sec. train epoch 4, iter 500/1000, loss 0.036305, 0.20 batches/sec.[2K|##########----------| 51.00%, 2571/2471 sec. train epoch 4, iter 510/1000, loss 0.036300, 0.20 batches/sec.[2K|##########----------| 52.00%, 2621/2416 sec. train epoch 4, iter 520/1000, loss 0.035021, 0.20 batches/sec.[2K|###########---------| 53.00%, 2671/2365 sec. train epoch 4, iter 530/1000, loss 0.031533, 0.20 batches/sec.[2K|###########---------| 54.00%, 2722/2319 sec. train epoch 4, iter 540/1000, loss 0.033297, 0.20 batches/sec.[2K|###########---------| 55.00%, 2772/2267 sec. train epoch 4, iter 550/1000, loss 0.032530, 0.20 batches/sec.[2K|###########---------| 56.00%, 2822/2214 sec. train epoch 4, iter 560/1000, loss 0.031482, 0.20 batches/sec.[2K|###########---------| 57.00%, 2873/2164 sec. train epoch 4, iter 570/1000, loss 0.030159, 0.20 batches/sec.[2K|############--------| 58.00%, 2923/2114 sec. train epoch 4, iter 580/1000, loss 0.026609, 0.20 batches/sec.[2K|############--------| 59.00%, 2973/2066 sec. train epoch 4, iter 590/1000, loss 0.025303, 0.20 batches/sec.[2K|############--------| 60.00%, 3024/2013 sec. train epoch 4, iter 600/1000, loss 0.021503, 0.20 batches/sec.[2K|############--------| 61.00%, 3074/1967 sec. train epoch 4, iter 610/1000, loss 0.020366, 0.20 batches/sec.[2K|############--------| 62.00%, 3125/1913 sec. train epoch 4, iter 620/1000, loss 0.023659, 0.20 batches/sec.[2K|#############-------| 63.00%, 3175/1862 sec. train epoch 4, iter 630/1000, loss 0.023506, 0.20 batches/sec.[2K|#############-------| 64.00%, 3225/1817 sec. train epoch 4, iter 640/1000, loss 0.024193, 0.20 batches/sec.[2K|#############-------| 65.00%, 3276/1759 sec. train epoch 4, iter 650/1000, loss 0.026021, 0.20 batches/sec.[2K|#############-------| 66.00%, 3326/1714 sec. train epoch 4, iter 660/1000, loss 0.020141, 0.20 batches/sec.[2K|#############-------| 67.00%, 3376/1659 sec. train epoch 4, iter 670/1000, loss 0.021818, 0.20 batches/sec.[2K|##############------| 68.00%, 3427/1611 sec. train epoch 4, iter 680/1000, loss 0.021709, 0.20 batches/sec.[2K|##############------| 69.00%, 3477/1561 sec. train epoch 4, iter 690/1000, loss 0.021995, 0.20 batches/sec.[32m[2019-03-17 16:51:33 @logger.py:146][0m [2K|####################| 100.00%, 5037/0 sec. train epoch 4, iter 1000/1000, loss 0.030062, 0.20 batches/sec.
[32m[2019-03-17 16:51:37 @logger.py:43][0m [32;1mTrigger callback: [0mTrigger ModelSaver: Save model to model_logs/20190317111349169013_10-255-0-254_mine_NORMAL_wgan_gp_full_model_celeba_hq_256/snap-4000.
[2K|##############------| 70.00%, 3527/1507 sec. train epoch 4, iter 700/1000, loss 0.023258, 0.20 batches/sec.[2K|##############------| 71.00%, 3577/1459 sec. train epoch 4, iter 710/1000, loss 0.022796, 0.20 batches/sec.[2K|##############------| 72.00%, 3628/1407 sec. train epoch 4, iter 720/1000, loss 0.022722, 0.20 batches/sec.[2K|###############-----| 73.00%, 3678/1357 sec. train epoch 4, iter 730/1000, loss 0.025666, 0.20 batches/sec.[2K|###############-----| 74.00%, 3728/1310 sec. train epoch 4, iter 740/1000, loss 0.027403, 0.20 batches/sec.[2K|###############-----| 75.00%, 3779/1258 sec. train epoch 4, iter 750/1000, loss 0.032138, 0.20 batches/sec.[2K|###############-----| 76.00%, 3829/1207 sec. train epoch 4, iter 760/1000, loss 0.029141, 0.20 batches/sec.[2K|###############-----| 77.00%, 3879/1156 sec. train epoch 4, iter 770/1000, loss 0.032096, 0.20 batches/sec.[2K|################----| 78.00%, 3930/1109 sec. train epoch 4, iter 780/1000, loss 0.029321, 0.20 batches/sec.[2K|################----| 79.00%, 3980/1057 sec. train epoch 4, iter 790/1000, loss 0.030738, 0.20 batches/sec.[2K|################----| 80.00%, 4030/1005 sec. train epoch 4, iter 800/1000, loss 0.033326, 0.20 batches/sec.[2K|################----| 81.00%, 4081/958 sec. train epoch 4, iter 810/1000, loss 0.029118, 0.20 batches/sec.[2K|################----| 82.00%, 4131/904 sec. train epoch 4, iter 820/1000, loss 0.026595, 0.20 batches/sec.[2K|#################---| 83.00%, 4181/856 sec. train epoch 4, iter 830/1000, loss 0.030383, 0.20 batches/sec.[2K|#################---| 84.00%, 4232/805 sec. train epoch 4, iter 840/1000, loss 0.032399, 0.20 batches/sec.[2K|#################---| 85.00%, 4282/755 sec. train epoch 4, iter 850/1000, loss 0.034797, 0.20 batches/sec.[2K|#################---| 86.00%, 4332/705 sec. train epoch 4, iter 860/1000, loss 0.033882, 0.20 batches/sec.[2K|#################---| 87.00%, 4383/654 sec. train epoch 4, iter 870/1000, loss 0.032612, 0.20 batches/sec.[2K|##################--| 88.00%, 4433/605 sec. train epoch 4, iter 880/1000, loss 0.031282, 0.20 batches/sec.[2K|##################--| 89.00%, 4483/554 sec. train epoch 4, iter 890/1000, loss 0.029410, 0.20 batches/sec.[2K|##################--| 90.00%, 4534/504 sec. train epoch 4, iter 900/1000, loss 0.029481, 0.20 batches/sec.[2K|##################--| 91.00%, 4584/453 sec. train epoch 4, iter 910/1000, loss 0.030533, 0.20 batches/sec.[2K|##################--| 92.00%, 4634/402 sec. train epoch 4, iter 920/1000, loss 0.032024, 0.20 batches/sec.[2K|###################-| 93.00%, 4685/353 sec. train epoch 4, iter 930/1000, loss 0.033321, 0.20 batches/sec.[2K|###################-| 94.00%, 4735/302 sec. train epoch 4, iter 940/1000, loss 0.033157, 0.20 batches/sec.[2K|###################-| 95.00%, 4785/252 sec. train epoch 4, iter 950/1000, loss 0.034130, 0.20 batches/sec.[2K|###################-| 96.00%, 4836/201 sec. train epoch 4, iter 960/1000, loss 0.033149, 0.20 batches/sec.[2K|###################-| 97.00%, 4886/151 sec. train epoch 4, iter 970/1000, loss 0.035878, 0.20 batches/sec.[2K|####################| 98.00%, 4936/101 sec. train epoch 4, iter 980/1000, loss 0.032946, 0.20 batches/sec.[2K|####################| 99.00%, 4987/50 sec. train epoch 4, iter 990/1000, loss 0.029107, 0.20 batches/sec.[2K|--------------------| 1.00%, 55/5448 sec. train epoch 5, iter 10/1000, loss 0.082588, 0.21 batches/sec.[2K|--------------------| 2.00%, 105/4926 sec. train epoch 5, iter 20/1000, loss 0.070542, 0.20 batches/sec.[2K|#-------------------| 3.00%, 156/4888 sec. train epoch 5, iter 30/1000, loss 0.090345, 0.20 batches/sec.[2K|#-------------------| 4.00%, 206/4829 sec. train epoch 5, iter 40/1000, loss 0.132263, 0.20 batches/sec.[2K|#-------------------| 5.00%, 256/4782 sec. train epoch 5, iter 50/1000, loss 0.145226, 0.20 batches/sec.[2K|#-------------------| 6.00%, 307/4729 sec. train epoch 5, iter 60/1000, loss 0.128787, 0.20 batches/sec.[2K|#-------------------| 7.00%, 357/4686 sec. train epoch 5, iter 70/1000, loss 0.096731, 0.20 batches/sec.[2K|##------------------| 8.00%, 407/4631 sec. train epoch 5, iter 80/1000, loss 0.090829, 0.20 batches/sec.[2K|##------------------| 9.00%, 458/4575 sec. train epoch 5, iter 90/1000, loss 0.102114, 0.20 batches/sec.[2K|##------------------| 10.00%, 508/4540 sec. train epoch 5, iter 100/1000, loss 0.109661, 0.20 batches/sec.[2K|##------------------| 11.00%, 558/4477 sec. train epoch 5, iter 110/1000, loss 0.071916, 0.20 batches/sec.[2K|##------------------| 12.00%, 609/4429 sec. train epoch 5, iter 120/1000, loss 0.097686, 0.20 batches/sec.[2K|###-----------------| 13.00%, 659/4381 sec. train epoch 5, iter 130/1000, loss 0.097399, 0.20 batches/sec.[2K|###-----------------| 14.00%, 709/4324 sec. train epoch 5, iter 140/1000, loss 0.088724, 0.20 batches/sec.[2K|###-----------------| 15.00%, 760/4280 sec. train epoch 5, iter 150/1000, loss 0.071432, 0.20 batches/sec.[2K|###-----------------| 16.00%, 810/4223 sec. train epoch 5, iter 160/1000, loss 0.058539, 0.20 batches/sec.[2K|###-----------------| 17.00%, 860/4172 sec. train epoch 5, iter 170/1000, loss 0.052313, 0.20 batches/sec.[2K|####----------------| 18.00%, 911/4124 sec. train epoch 5, iter 180/1000, loss 0.048465, 0.20 batches/sec.[2K|####----------------| 19.00%, 961/4069 sec. train epoch 5, iter 190/1000, loss 0.038415, 0.20 batches/sec.[2K|####----------------| 20.00%, 1011/4025 sec. train epoch 5, iter 200/1000, loss 0.027906, 0.20 batches/sec.[2K|####----------------| 21.00%, 1061/3971 sec. train epoch 5, iter 210/1000, loss 0.035733, 0.20 batches/sec.[2K|####----------------| 22.00%, 1112/3928 sec. train epoch 5, iter 220/1000, loss 0.038689, 0.20 batches/sec.[2K|#####---------------| 23.00%, 1162/3874 sec. train epoch 5, iter 230/1000, loss 0.046480, 0.20 batches/sec.[2K|#####---------------| 24.00%, 1212/3825 sec. train epoch 5, iter 240/1000, loss 0.054060, 0.20 batches/sec.[2K|#####---------------| 25.00%, 1263/3776 sec. train epoch 5, iter 250/1000, loss 0.052799, 0.20 batches/sec.[2K|#####---------------| 26.00%, 1313/3721 sec. train epoch 5, iter 260/1000, loss 0.055124, 0.20 batches/sec.[2K|#####---------------| 27.00%, 1363/3677 sec. train epoch 5, iter 270/1000, loss 0.053725, 0.20 batches/sec.[2K|######--------------| 28.00%, 1414/3619 sec. train epoch 5, iter 280/1000, loss 0.060554, 0.20 batches/sec.[2K|######--------------| 29.00%, 1464/3570 sec. train epoch 5, iter 290/1000, loss 0.065021, 0.20 batches/sec.[2K|######--------------| 30.00%, 1514/3520 sec. train epoch 5, iter 300/1000, loss 0.054193, 0.20 batches/sec.[2K|######--------------| 31.00%, 1564/3468 sec. train epoch 5, iter 310/1000, loss 0.049189, 0.20 batches/sec.[2K|######--------------| 32.00%, 1615/3424 sec. train epoch 5, iter 320/1000, loss 0.043315, 0.20 batches/sec.[2K|#######-------------| 33.00%, 1665/3368 sec. train epoch 5, iter 330/1000, loss 0.042323, 0.20 batches/sec.[2K|#######-------------| 34.00%, 1716/3332 sec. train epoch 5, iter 340/1000, loss 0.039495, 0.20 batches/sec.[2K|#######-------------| 35.00%, 1766/3271 sec. train epoch 5, iter 350/1000, loss 0.030466, 0.20 batches/sec.[2K|#######-------------| 36.00%, 1816/3217 sec. train epoch 5, iter 360/1000, loss 0.041414, 0.20 batches/sec.[2K|#######-------------| 37.00%, 1867/3176 sec. train epoch 5, iter 370/1000, loss 0.044881, 0.20 batches/sec.[2K|########------------| 38.00%, 1917/3119 sec. train epoch 5, iter 380/1000, loss 0.044742, 0.20 batches/sec.[2K|########------------| 39.00%, 1967/3071 sec. train epoch 5, iter 390/1000, loss 0.048285, 0.20 batches/sec.[2K|########------------| 40.00%, 2018/3020 sec. train epoch 5, iter 400/1000, loss 0.051574, 0.20 batches/sec.[2K|########------------| 41.00%, 2068/2966 sec. train epoch 5, iter 410/1000, loss 0.044412, 0.20 batches/sec.[2K|########------------| 42.00%, 2118/2921 sec. train epoch 5, iter 420/1000, loss 0.037485, 0.20 batches/sec.[2K|#########-----------| 43.00%, 2168/2868 sec. train epoch 5, iter 430/1000, loss 0.034444, 0.20 batches/sec.[2K|#########-----------| 44.00%, 2219/2825 sec. train epoch 5, iter 440/1000, loss 0.030208, 0.20 batches/sec.[32m[2019-03-17 18:15:31 @logger.py:146][0m [2K|####################| 100.00%, 5038/0 sec. train epoch 5, iter 1000/1000, loss 0.061337, 0.20 batches/sec.
[32m[2019-03-17 18:15:35 @logger.py:43][0m [32;1mTrigger callback: [0mTrigger ModelSaver: Save model to model_logs/20190317111349169013_10-255-0-254_mine_NORMAL_wgan_gp_full_model_celeba_hq_256/snap-5000.
[2K|#########-----------| 45.00%, 2269/2765 sec. train epoch 5, iter 450/1000, loss 0.029226, 0.20 batches/sec.[2K|#########-----------| 46.00%, 2320/2719 sec. train epoch 5, iter 460/1000, loss 0.027086, 0.20 batches/sec.[2K|#########-----------| 47.00%, 2370/2665 sec. train epoch 5, iter 470/1000, loss 0.027531, 0.20 batches/sec.[2K|##########----------| 48.00%, 2420/2616 sec. train epoch 5, iter 480/1000, loss 0.027229, 0.20 batches/sec.[2K|##########----------| 49.00%, 2471/2573 sec. train epoch 5, iter 490/1000, loss 0.033285, 0.20 batches/sec.[2K|##########----------| 50.00%, 2521/2516 sec. train epoch 5, iter 500/1000, loss 0.028087, 0.20 batches/sec.[2K|##########----------| 51.00%, 2571/2468 sec. train epoch 5, iter 510/1000, loss 0.036298, 0.20 batches/sec.[2K|##########----------| 52.00%, 2622/2418 sec. train epoch 5, iter 520/1000, loss 0.035024, 0.20 batches/sec.[2K|###########---------| 53.00%, 2672/2366 sec. train epoch 5, iter 530/1000, loss 0.031556, 0.20 batches/sec.[2K|###########---------| 54.00%, 2722/2314 sec. train epoch 5, iter 540/1000, loss 0.038712, 0.20 batches/sec.[2K|###########---------| 55.00%, 2772/2258 sec. train epoch 5, iter 550/1000, loss 0.042959, 0.20 batches/sec.[2K|###########---------| 56.00%, 2823/2216 sec. train epoch 5, iter 560/1000, loss 0.057616, 0.20 batches/sec.[2K|###########---------| 57.00%, 2873/2164 sec. train epoch 5, iter 570/1000, loss 0.060940, 0.20 batches/sec.[2K|############--------| 58.00%, 2923/2114 sec. train epoch 5, iter 580/1000, loss 0.060478, 0.20 batches/sec.[2K|############--------| 59.00%, 2974/2065 sec. train epoch 5, iter 590/1000, loss 0.058068, 0.20 batches/sec.[2K|############--------| 60.00%, 3024/2012 sec. train epoch 5, iter 600/1000, loss 0.061520, 0.20 batches/sec.[2K|############--------| 61.00%, 3075/1967 sec. train epoch 5, iter 610/1000, loss 0.064969, 0.20 batches/sec.[2K|############--------| 62.00%, 3125/1910 sec. train epoch 5, iter 620/1000, loss 0.067319, 0.20 batches/sec.[2K|#############-------| 63.00%, 3175/1864 sec. train epoch 5, iter 630/1000, loss 0.072058, 0.20 batches/sec.[2K|#############-------| 64.00%, 3226/1813 sec. train epoch 5, iter 640/1000, loss 0.074711, 0.20 batches/sec.[2K|#############-------| 65.00%, 3276/1761 sec. train epoch 5, iter 650/1000, loss 0.072898, 0.20 batches/sec.[2K|#############-------| 66.00%, 3326/1713 sec. train epoch 5, iter 660/1000, loss 0.079275, 0.20 batches/sec.[2K|#############-------| 67.00%, 3377/1659 sec. train epoch 5, iter 670/1000, loss 0.077092, 0.20 batches/sec.[2K|##############------| 68.00%, 3427/1613 sec. train epoch 5, iter 680/1000, loss 0.073034, 0.20 batches/sec.[2K|##############------| 69.00%, 3477/1558 sec. train epoch 5, iter 690/1000, loss 0.072877, 0.20 batches/sec.[2K|##############------| 70.00%, 3528/1510 sec. train epoch 5, iter 700/1000, loss 0.074863, 0.20 batches/sec.[2K|##############------| 71.00%, 3578/1463 sec. train epoch 5, iter 710/1000, loss 0.070794, 0.20 batches/sec.[2K|##############------| 72.00%, 3628/1407 sec. train epoch 5, iter 720/1000, loss 0.067784, 0.20 batches/sec.[2K|###############-----| 73.00%, 3679/1361 sec. train epoch 5, iter 730/1000, loss 0.065433, 0.20 batches/sec.[2K|###############-----| 74.00%, 3729/1308 sec. train epoch 5, iter 740/1000, loss 0.065972, 0.20 batches/sec.[2K|###############-----| 75.00%, 3779/1258 sec. train epoch 5, iter 750/1000, loss 0.068522, 0.20 batches/sec.[2K|###############-----| 76.00%, 3830/1208 sec. train epoch 5, iter 760/1000, loss 0.064741, 0.20 batches/sec.[2K|###############-----| 77.00%, 3880/1156 sec. train epoch 5, iter 770/1000, loss 0.065766, 0.20 batches/sec.[2K|################----| 78.00%, 3930/1110 sec. train epoch 5, iter 780/1000, loss 0.065321, 0.20 batches/sec.[2K|################----| 79.00%, 3981/1056 sec. train epoch 5, iter 790/1000, loss 0.065208, 0.20 batches/sec.[2K|################----| 80.00%, 4031/1008 sec. train epoch 5, iter 800/1000, loss 0.068846, 0.20 batches/sec.[2K|################----| 81.00%, 4081/956 sec. train epoch 5, iter 810/1000, loss 0.067496, 0.20 batches/sec.[2K|################----| 82.00%, 4132/907 sec. train epoch 5, iter 820/1000, loss 0.068027, 0.20 batches/sec.[2K|#################---| 83.00%, 4182/858 sec. train epoch 5, iter 830/1000, loss 0.068613, 0.20 batches/sec.[2K|#################---| 84.00%, 4233/805 sec. train epoch 5, iter 840/1000, loss 0.069567, 0.20 batches/sec.[2K|#################---| 85.00%, 4283/755 sec. train epoch 5, iter 850/1000, loss 0.069844, 0.20 batches/sec.[2K|#################---| 86.00%, 4333/705 sec. train epoch 5, iter 860/1000, loss 0.070529, 0.20 batches/sec.[2K|#################---| 87.00%, 4384/654 sec. train epoch 5, iter 870/1000, loss 0.070796, 0.20 batches/sec.[2K|##################--| 88.00%, 4434/605 sec. train epoch 5, iter 880/1000, loss 0.071332, 0.20 batches/sec.[2K|##################--| 89.00%, 4484/553 sec. train epoch 5, iter 890/1000, loss 0.073859, 0.20 batches/sec.[2K|##################--| 90.00%, 4535/504 sec. train epoch 5, iter 900/1000, loss 0.072346, 0.20 batches/sec.[2K|##################--| 91.00%, 4585/453 sec. train epoch 5, iter 910/1000, loss 0.071484, 0.20 batches/sec.[2K|##################--| 92.00%, 4635/403 sec. train epoch 5, iter 920/1000, loss 0.072101, 0.20 batches/sec.[2K|###################-| 93.00%, 4686/352 sec. train epoch 5, iter 930/1000, loss 0.068733, 0.20 batches/sec.[2K|###################-| 94.00%, 4736/302 sec. train epoch 5, iter 940/1000, loss 0.068186, 0.20 batches/sec.[2K|###################-| 95.00%, 4786/252 sec. train epoch 5, iter 950/1000, loss 0.065752, 0.20 batches/sec.[2K|###################-| 96.00%, 4837/202 sec. train epoch 5, iter 960/1000, loss 0.064095, 0.20 batches/sec.[2K|###################-| 97.00%, 4887/151 sec. train epoch 5, iter 970/1000, loss 0.062291, 0.20 batches/sec.[2K|####################| 98.00%, 4938/101 sec. train epoch 5, iter 980/1000, loss 0.060929, 0.20 batches/sec.[2K|####################| 99.00%, 4988/50 sec. train epoch 5, iter 990/1000, loss 0.062043, 0.20 batches/sec.[2K|--------------------| 1.00%, 55/5441 sec. train epoch 6, iter 10/1000, loss 0.081681, 0.21 batches/sec.[2K|--------------------| 2.00%, 105/4943 sec. train epoch 6, iter 20/1000, loss 0.083264, 0.20 batches/sec.[2K|#-------------------| 3.00%, 156/4893 sec. train epoch 6, iter 30/1000, loss 0.077832, 0.20 batches/sec.[2K|#-------------------| 4.00%, 206/4826 sec. train epoch 6, iter 40/1000, loss 0.152263, 0.20 batches/sec.[2K|#-------------------| 5.00%, 256/4787 sec. train epoch 6, iter 50/1000, loss 0.183090, 0.20 batches/sec.[2K|#-------------------| 6.00%, 307/4725 sec. train epoch 6, iter 60/1000, loss 0.231219, 0.20 batches/sec.[2K|#-------------------| 7.00%, 357/4683 sec. train epoch 6, iter 70/1000, loss 0.234173, 0.20 batches/sec.[2K|##------------------| 8.00%, 407/4629 sec. train epoch 6, iter 80/1000, loss 0.227855, 0.20 batches/sec.[2K|##------------------| 9.00%, 458/4581 sec. train epoch 6, iter 90/1000, loss 0.219031, 0.20 batches/sec.[2K|##------------------| 10.00%, 508/4536 sec. train epoch 6, iter 100/1000, loss 0.182069, 0.20 batches/sec.[2K|##------------------| 11.00%, 558/4472 sec. train epoch 6, iter 110/1000, loss 0.204536, 0.20 batches/sec.[2K|##------------------| 12.00%, 609/4440 sec. train epoch 6, iter 120/1000, loss 0.181018, 0.20 batches/sec.[2K|###-----------------| 13.00%, 659/4369 sec. train epoch 6, iter 130/1000, loss 0.168891, 0.20 batches/sec.[2K|###-----------------| 14.00%, 709/4324 sec. train epoch 6, iter 140/1000, loss 0.174522, 0.20 batches/sec.[2K|###-----------------| 15.00%, 760/4275 sec. train epoch 6, iter 150/1000, loss 0.189890, 0.20 batches/sec.[2K|###-----------------| 16.00%, 810/4223 sec. train epoch 6, iter 160/1000, loss 0.177429, 0.20 batches/sec.[2K|###-----------------| 17.00%, 860/4179 sec. train epoch 6, iter 170/1000, loss 0.159970, 0.20 batches/sec.[2K|####----------------| 18.00%, 911/4126 sec. train epoch 6, iter 180/1000, loss 0.155840, 0.20 batches/sec.[2K|####----------------| 19.00%, 961/4077 sec. train epoch 6, iter 190/1000, loss 0.155907, 0.20 batches/sec.[2K|####----------------| 20.00%, 1011/4027 sec. train epoch 6, iter 200/1000, loss 0.149621, 0.20 batches/sec.[2K|####----------------| 21.00%, 1062/3970 sec. train epoch 6, iter 210/1000, loss 0.149468, 0.20 batches/sec.[2K|####----------------| 22.00%, 1112/3936 sec. train epoch 6, iter 220/1000, loss 0.137312, 0.20 batches/sec.[2K|#####---------------| 23.00%, 1162/3872 sec. train epoch 6, iter 230/1000, loss 0.132537, 0.20 batches/sec.[2K|#####---------------| 24.00%, 1213/3828 sec. train epoch 6, iter 240/1000, loss 0.146259, 0.20 batches/sec.[2K|#####---------------| 25.00%, 1263/3772 sec. train epoch 6, iter 250/1000, loss 0.154525, 0.20 batches/sec.[2K|#####---------------| 26.00%, 1313/3728 sec. train epoch 6, iter 260/1000, loss 0.147894, 0.20 batches/sec.[2K|#####---------------| 27.00%, 1364/3676 sec. train epoch 6, iter 270/1000, loss 0.145109, 0.20 batches/sec.[2K|######--------------| 28.00%, 1414/3616 sec. train epoch 6, iter 280/1000, loss 0.151668, 0.20 batches/sec.[2K|######--------------| 29.00%, 1464/3577 sec. train epoch 6, iter 290/1000, loss 0.167310, 0.20 batches/sec.[2K|######--------------| 30.00%, 1515/3520 sec. train epoch 6, iter 300/1000, loss 0.165252, 0.20 batches/sec.[2K|######--------------| 31.00%, 1565/3474 sec. train epoch 6, iter 310/1000, loss 0.168788, 0.20 batches/sec.[2K|######--------------| 32.00%, 1615/3418 sec. train epoch 6, iter 320/1000, loss 0.166658, 0.20 batches/sec.[2K|#######-------------| 33.00%, 1665/3365 sec. train epoch 6, iter 330/1000, loss 0.158722, 0.20 batches/sec.[2K|#######-------------| 34.00%, 1716/3326 sec. train epoch 6, iter 340/1000, loss 0.149628, 0.20 batches/sec.[2K|#######-------------| 35.00%, 1766/3270 sec. train epoch 6, iter 350/1000, loss 0.138385, 0.20 batches/sec.[2K|#######-------------| 36.00%, 1816/3225 sec. train epoch 6, iter 360/1000, loss 0.139147, 0.20 batches/sec.[2K|#######-------------| 37.00%, 1867/3175 sec. train epoch 6, iter 370/1000, loss 0.136397, 0.20 batches/sec.[2K|########------------| 38.00%, 1917/3120 sec. train epoch 6, iter 380/1000, loss 0.141096, 0.20 batches/sec.[2K|########------------| 39.00%, 1968/3073 sec. train epoch 6, iter 390/1000, loss 0.140880, 0.20 batches/sec.[2K|########------------| 40.00%, 2018/3016 sec. train epoch 6, iter 400/1000, loss 0.146011, 0.20 batches/sec.[2K|########------------| 41.00%, 2068/2969 sec. train epoch 6, iter 410/1000, loss 0.146918, 0.20 batches/sec.[2K|########------------| 42.00%, 2118/2918 sec. train epoch 6, iter 420/1000, loss 0.144366, 0.20 batches/sec.[2K|#########-----------| 43.00%, 2169/2868 sec. train epoch 6, iter 430/1000, loss 0.143747, 0.20 batches/sec.[2K|#########-----------| 44.00%, 2219/2818 sec. train epoch 6, iter 440/1000, loss 0.141197, 0.20 batches/sec.[2K|#########-----------| 45.00%, 2269/2763 sec. train epoch 6, iter 450/1000, loss 0.145404, 0.20 batches/sec.[2K|#########-----------| 46.00%, 2320/2721 sec. train epoch 6, iter 460/1000, loss 0.146333, 0.20 batches/sec.[2K|#########-----------| 47.00%, 2370/2665 sec. train epoch 6, iter 470/1000, loss 0.157987, 0.20 batches/sec.[2K|##########----------| 48.00%, 2420/2617 sec. train epoch 6, iter 480/1000, loss 0.152638, 0.20 batches/sec.[2K|##########----------| 49.00%, 2471/2573 sec. train epoch 6, iter 490/1000, loss 0.143462, 0.20 batches/sec.[2K|##########----------| 50.00%, 2521/2514 sec. train epoch 6, iter 500/1000, loss 0.135281, 0.20 batches/sec.[2K|##########----------| 51.00%, 2571/2471 sec. train epoch 6, iter 510/1000, loss 0.139542, 0.20 batches/sec.[2K|##########----------| 52.00%, 2622/2413 sec. train epoch 6, iter 520/1000, loss 0.128631, 0.20 batches/sec.[2K|###########---------| 53.00%, 2672/2364 sec. train epoch 6, iter 530/1000, loss 0.116053, 0.20 batches/sec.[2K|###########---------| 54.00%, 2722/2317 sec. train epoch 6, iter 540/1000, loss 0.116560, 0.20 batches/sec.[2K|###########---------| 55.00%, 2773/2264 sec. train epoch 6, iter 550/1000, loss 0.116254, 0.20 batches/sec.[2K|###########---------| 56.00%, 2823/2216 sec. train epoch 6, iter 560/1000, loss 0.110511, 0.20 batches/sec.[2K|###########---------| 57.00%, 2873/2162 sec. train epoch 6, iter 570/1000, loss 0.110595, 0.20 batches/sec.[2K|############--------| 58.00%, 2924/2114 sec. train epoch 6, iter 580/1000, loss 0.120382, 0.20 batches/sec.[2K|############--------| 59.00%, 2974/2061 sec. train epoch 6, iter 590/1000, loss 0.116226, 0.20 batches/sec.[2K|############--------| 60.00%, 3024/2010 sec. train epoch 6, iter 600/1000, loss 0.115034, 0.20 batches/sec.[2K|############--------| 61.00%, 3075/1963 sec. train epoch 6, iter 610/1000, loss 0.122486, 0.20 batches/sec.[2K|############--------| 62.00%, 3125/1910 sec. train epoch 6, iter 620/1000, loss 0.118507, 0.20 batches/sec.[2K|#############-------| 63.00%, 3175/1859 sec. train epoch 6, iter 630/1000, loss 0.118859, 0.20 batches/sec.[2K|#############-------| 64.00%, 3225/1811 sec. train epoch 6, iter 640/1000, loss 0.117632, 0.20 batches/sec.[2K|#############-------| 65.00%, 3276/1759 sec. train epoch 6, iter 650/1000, loss 0.123068, 0.20 batches/sec.[2K|#############-------| 66.00%, 3326/1712 sec. train epoch 6, iter 660/1000, loss 0.121976, 0.20 batches/sec.[2K|#############-------| 67.00%, 3376/1659 sec. train epoch 6, iter 670/1000, loss 0.121750, 0.20 batches/sec.[2K|##############------| 68.00%, 3427/1611 sec. train epoch 6, iter 680/1000, loss 0.120722, 0.20 batches/sec.[2K|##############------| 69.00%, 3477/1559 sec. train epoch 6, iter 690/1000, loss 0.123131, 0.20 batches/sec.[2K|##############------| 70.00%, 3527/1511 sec. train epoch 6, iter 700/1000, loss 0.121354, 0.20 batches/sec.[2K|##############------| 71.00%, 3578/1458 sec. train epoch 6, iter 710/1000, loss 0.116930, 0.20 batches/sec.[2K|##############------| 72.00%, 3628/1409 sec. train epoch 6, iter 720/1000, loss 0.117757, 0.20 batches/sec.[2K|###############-----| 73.00%, 3678/1360 sec. train epoch 6, iter 730/1000, loss 0.118745, 0.20 batches/sec.[2K|###############-----| 74.00%, 3728/1306 sec. train epoch 6, iter 740/1000, loss 0.119739, 0.20 batches/sec.[2K|###############-----| 75.00%, 3779/1259 sec. train epoch 6, iter 750/1000, loss 0.120111, 0.20 batches/sec.[2K|###############-----| 76.00%, 3829/1207 sec. train epoch 6, iter 760/1000, loss 0.117841, 0.20 batches/sec.[2K|###############-----| 77.00%, 3879/1155 sec. train epoch 6, iter 770/1000, loss 0.122732, 0.20 batches/sec.[2K|################----| 78.00%, 3930/1108 sec. train epoch 6, iter 780/1000, loss 0.126937, 0.20 batches/sec.[2K|################----| 79.00%, 3980/1055 sec. train epoch 6, iter 790/1000, loss 0.131579, 0.20 batches/sec.[2K|################----| 80.00%, 4030/1009 sec. train epoch 6, iter 800/1000, loss 0.133087, 0.20 batches/sec.[2K|################----| 81.00%, 4081/955 sec. train epoch 6, iter 810/1000, loss 0.130410, 0.20 batches/sec.[2K|################----| 82.00%, 4131/907 sec. train epoch 6, iter 820/1000, loss 0.129452, 0.20 batches/sec.[2K|#################---| 83.00%, 4181/855 sec. train epoch 6, iter 830/1000, loss 0.127733, 0.20 batches/sec.[2K|#################---| 84.00%, 4232/805 sec. train epoch 6, iter 840/1000, loss 0.128345, 0.20 batches/sec.[2K|#################---| 85.00%, 4282/756 sec. train epoch 6, iter 850/1000, loss 0.127660, 0.20 batches/sec.[2K|#################---| 86.00%, 4332/704 sec. train epoch 6, iter 860/1000, loss 0.127392, 0.20 batches/sec.[2K|#################---| 87.00%, 4383/656 sec. train epoch 6, iter 870/1000, loss 0.133035, 0.20 batches/sec.[2K|##################--| 88.00%, 4433/604 sec. train epoch 6, iter 880/1000, loss 0.131885, 0.20 batches/sec.[2K|##################--| 89.00%, 4483/554 sec. train epoch 6, iter 890/1000, loss 0.130126, 0.20 batches/sec.[2K|##################--| 90.00%, 4534/504 sec. train epoch 6, iter 900/1000, loss 0.132125, 0.20 batches/sec.[2K|##################--| 91.00%, 4584/452 sec. train epoch 6, iter 910/1000, loss 0.134085, 0.20 batches/sec.[2K|##################--| 92.00%, 4634/403 sec. train epoch 6, iter 920/1000, loss 0.136251, 0.20 batches/sec.[32m[2019-03-17 19:39:28 @logger.py:146][0m [2K|####################| 100.00%, 5037/0 sec. train epoch 6, iter 1000/1000, loss 0.118006, 0.20 batches/sec.
[32m[2019-03-17 19:39:32 @logger.py:43][0m [32;1mTrigger callback: [0mTrigger ModelSaver: Save model to model_logs/20190317111349169013_10-255-0-254_mine_NORMAL_wgan_gp_full_model_celeba_hq_256/snap-6000.
[2K|###################-| 93.00%, 4685/352 sec. train epoch 6, iter 930/1000, loss 0.134081, 0.20 batches/sec.[2K|###################-| 94.00%, 4735/302 sec. train epoch 6, iter 940/1000, loss 0.130831, 0.20 batches/sec.[2K|###################-| 95.00%, 4785/252 sec. train epoch 6, iter 950/1000, loss 0.130842, 0.20 batches/sec.[2K|###################-| 96.00%, 4836/201 sec. train epoch 6, iter 960/1000, loss 0.127595, 0.20 batches/sec.[2K|###################-| 97.00%, 4886/151 sec. train epoch 6, iter 970/1000, loss 0.127261, 0.20 batches/sec.[2K|####################| 98.00%, 4936/101 sec. train epoch 6, iter 980/1000, loss 0.126601, 0.20 batches/sec.[2K|####################| 99.00%, 4987/50 sec. train epoch 6, iter 990/1000, loss 0.121218, 0.20 batches/sec.[2K|--------------------| 1.00%, 55/5461 sec. train epoch 7, iter 10/1000, loss -0.077943, 0.21 batches/sec.[2K|--------------------| 2.00%, 106/4937 sec. train epoch 7, iter 20/1000, loss 0.071593, 0.20 batches/sec.[2K|#-------------------| 3.00%, 156/4881 sec. train epoch 7, iter 30/1000, loss 0.206676, 0.20 batches/sec.[2K|#-------------------| 4.00%, 206/4836 sec. train epoch 7, iter 40/1000, loss 0.198119, 0.20 batches/sec.[2K|#-------------------| 5.00%, 257/4779 sec. train epoch 7, iter 50/1000, loss 0.194575, 0.20 batches/sec.[2K|#-------------------| 6.00%, 307/4728 sec. train epoch 7, iter 60/1000, loss 0.184975, 0.20 batches/sec.[2K|#-------------------| 7.00%, 357/4688 sec. train epoch 7, iter 70/1000, loss 0.128040, 0.20 batches/sec.[2K|##------------------| 8.00%, 408/4625 sec. train epoch 7, iter 80/1000, loss 0.123381, 0.20 batches/sec.[2K|##------------------| 9.00%, 458/4584 sec. train epoch 7, iter 90/1000, loss 0.151255, 0.20 batches/sec.[2K|##------------------| 10.00%, 508/4535 sec. train epoch 7, iter 100/1000, loss 0.133493, 0.20 batches/sec.[2K|##------------------| 11.00%, 559/4483 sec. train epoch 7, iter 110/1000, loss 0.109196, 0.20 batches/sec.[2K|##------------------| 12.00%, 609/4432 sec. train epoch 7, iter 120/1000, loss 0.098627, 0.20 batches/sec.[2K|###-----------------| 13.00%, 659/4380 sec. train epoch 7, iter 130/1000, loss 0.097556, 0.20 batches/sec.[2K|###-----------------| 14.00%, 710/4332 sec. train epoch 7, iter 140/1000, loss 0.062040, 0.20 batches/sec.[2K|###-----------------| 15.00%, 760/4280 sec. train epoch 7, iter 150/1000, loss 0.054985, 0.20 batches/sec.[2K|###-----------------| 16.00%, 810/4223 sec. train epoch 7, iter 160/1000, loss 0.057666, 0.20 batches/sec.[2K|###-----------------| 17.00%, 861/4179 sec. train epoch 7, iter 170/1000, loss 0.062266, 0.20 batches/sec.[2K|####----------------| 18.00%, 911/4124 sec. train epoch 7, iter 180/1000, loss 0.059146, 0.20 batches/sec.[2K|####----------------| 19.00%, 961/4082 sec. train epoch 7, iter 190/1000, loss 0.066859, 0.20 batches/sec.[2K|####----------------| 20.00%, 1012/4018 sec. train epoch 7, iter 200/1000, loss 0.052764, 0.20 batches/sec.[2K|####----------------| 21.00%, 1062/3978 sec. train epoch 7, iter 210/1000, loss 0.051062, 0.20 batches/sec.[2K|####----------------| 22.00%, 1112/3927 sec. train epoch 7, iter 220/1000, loss 0.052121, 0.20 batches/sec.[2K|#####---------------| 23.00%, 1163/3871 sec. train epoch 7, iter 230/1000, loss 0.052865, 0.20 batches/sec.[2K|#####---------------| 24.00%, 1213/3826 sec. train epoch 7, iter 240/1000, loss 0.049659, 0.20 batches/sec.[2K|#####---------------| 25.00%, 1263/3771 sec. train epoch 7, iter 250/1000, loss 0.051386, 0.20 batches/sec.[2K|#####---------------| 26.00%, 1314/3728 sec. train epoch 7, iter 260/1000, loss 0.059010, 0.20 batches/sec.[2K|#####---------------| 27.00%, 1364/3672 sec. train epoch 7, iter 270/1000, loss 0.053591, 0.20 batches/sec.[2K|######--------------| 28.00%, 1414/3619 sec. train epoch 7, iter 280/1000, loss 0.064513, 0.20 batches/sec.[2K|######--------------| 29.00%, 1465/3579 sec. train epoch 7, iter 290/1000, loss 0.055855, 0.20 batches/sec.[2K|######--------------| 30.00%, 1515/3522 sec. train epoch 7, iter 300/1000, loss 0.052071, 0.20 batches/sec.[2K|######--------------| 31.00%, 1565/3477 sec. train epoch 7, iter 310/1000, loss 0.050227, 0.20 batches/sec.[2K|######--------------| 32.00%, 1616/3419 sec. train epoch 7, iter 320/1000, loss 0.060739, 0.20 batches/sec.[2K|#######-------------| 33.00%, 1666/3370 sec. train epoch 7, iter 330/1000, loss 0.059964, 0.20 batches/sec.[2K|#######-------------| 34.00%, 1716/3317 sec. train epoch 7, iter 340/1000, loss 0.064041, 0.20 batches/sec.[2K|#######-------------| 35.00%, 1766/3266 sec. train epoch 7, iter 350/1000, loss 0.060515, 0.20 batches/sec.[2K|#######-------------| 36.00%, 1817/3227 sec. train epoch 7, iter 360/1000, loss 0.058900, 0.20 batches/sec.[2K|#######-------------| 37.00%, 1867/3171 sec. train epoch 7, iter 370/1000, loss 0.066702, 0.20 batches/sec.[2K|########------------| 38.00%, 1917/3124 sec. train epoch 7, iter 380/1000, loss 0.068629, 0.20 batches/sec.[2K|########------------| 39.00%, 1968/3068 sec. train epoch 7, iter 390/1000, loss 0.066637, 0.20 batches/sec.[2K|########------------| 40.00%, 2018/3016 sec. train epoch 7, iter 400/1000, loss 0.068435, 0.20 batches/sec.[2K|########------------| 41.00%, 2068/2974 sec. train epoch 7, iter 410/1000, loss 0.076033, 0.20 batches/sec.[2K|########------------| 42.00%, 2119/2919 sec. train epoch 7, iter 420/1000, loss 0.078397, 0.20 batches/sec.[2K|#########-----------| 43.00%, 2169/2875 sec. train epoch 7, iter 430/1000, loss 0.079318, 0.20 batches/sec.[2K|#########-----------| 44.00%, 2220/2819 sec. train epoch 7, iter 440/1000, loss 0.080107, 0.20 batches/sec.[2K|#########-----------| 45.00%, 2270/2767 sec. train epoch 7, iter 450/1000, loss 0.081542, 0.20 batches/sec.[2K|#########-----------| 46.00%, 2320/2719 sec. train epoch 7, iter 460/1000, loss 0.092497, 0.20 batches/sec.[2K|#########-----------| 47.00%, 2371/2667 sec. train epoch 7, iter 470/1000, loss 0.099539, 0.20 batches/sec.[2K|##########----------| 48.00%, 2421/2619 sec. train epoch 7, iter 480/1000, loss 0.094993, 0.20 batches/sec.[2K|##########----------| 49.00%, 2471/2562 sec. train epoch 7, iter 490/1000, loss 0.094409, 0.20 batches/sec.[2K|##########----------| 50.00%, 2522/2520 sec. train epoch 7, iter 500/1000, loss 0.095136, 0.20 batches/sec.[2K|##########----------| 51.00%, 2572/2468 sec. train epoch 7, iter 510/1000, loss 0.104109, 0.20 batches/sec.[2K|##########----------| 52.00%, 2622/2413 sec. train epoch 7, iter 520/1000, loss 0.105049, 0.20 batches/sec.[2K|###########---------| 53.00%, 2673/2370 sec. train epoch 7, iter 530/1000, loss 0.108239, 0.20 batches/sec.[2K|###########---------| 54.00%, 2723/2312 sec. train epoch 7, iter 540/1000, loss 0.106053, 0.20 batches/sec.[2K|###########---------| 55.00%, 2773/2262 sec. train epoch 7, iter 550/1000, loss 0.100804, 0.20 batches/sec.[2K|###########---------| 56.00%, 2824/2222 sec. train epoch 7, iter 560/1000, loss 0.101277, 0.20 batches/sec.[2K|###########---------| 57.00%, 2874/2161 sec. train epoch 7, iter 570/1000, loss 0.097667, 0.20 batches/sec.[2K|############--------| 58.00%, 2924/2116 sec. train epoch 7, iter 580/1000, loss 0.095374, 0.20 batches/sec.[2K|############--------| 59.00%, 2975/2060 sec. train epoch 7, iter 590/1000, loss 0.095502, 0.20 batches/sec.[2K|############--------| 60.00%, 3025/2013 sec. train epoch 7, iter 600/1000, loss 0.096531, 0.20 batches/sec.[2K|############--------| 61.00%, 3075/1962 sec. train epoch 7, iter 610/1000, loss 0.095508, 0.20 batches/sec.[2K|############--------| 62.00%, 3125/1911 sec. train epoch 7, iter 620/1000, loss 0.097470, 0.20 batches/sec.[2K|#############-------| 63.00%, 3176/1862 sec. train epoch 7, iter 630/1000, loss 0.102858, 0.20 batches/sec.[2K|#############-------| 64.00%, 3226/1807 sec. train epoch 7, iter 640/1000, loss 0.100847, 0.20 batches/sec.[2K|#############-------| 65.00%, 3276/1765 sec. train epoch 7, iter 650/1000, loss 0.098628, 0.20 batches/sec.[2K|#############-------| 66.00%, 3327/1711 sec. train epoch 7, iter 660/1000, loss 0.101587, 0.20 batches/sec.[32m[2019-03-17 21:03:26 @logger.py:146][0m [2K|####################| 100.00%, 5038/0 sec. train epoch 7, iter 1000/1000, loss 0.104629, 0.20 batches/sec.
[32m[2019-03-17 21:03:30 @logger.py:43][0m [32;1mTrigger callback: [0mTrigger ModelSaver: Save model to model_logs/20190317111349169013_10-255-0-254_mine_NORMAL_wgan_gp_full_model_celeba_hq_256/snap-7000.
[2K|#############-------| 67.00%, 3377/1662 sec. train epoch 7, iter 670/1000, loss 0.106060, 0.20 batches/sec.[2K|##############------| 68.00%, 3427/1613 sec. train epoch 7, iter 680/1000, loss 0.105899, 0.20 batches/sec.[2K|##############------| 69.00%, 3478/1561 sec. train epoch 7, iter 690/1000, loss 0.107185, 0.20 batches/sec.[2K|##############------| 70.00%, 3528/1510 sec. train epoch 7, iter 700/1000, loss 0.108322, 0.20 batches/sec.[2K|##############------| 71.00%, 3578/1460 sec. train epoch 7, iter 710/1000, loss 0.107195, 0.20 batches/sec.[2K|##############------| 72.00%, 3629/1409 sec. train epoch 7, iter 720/1000, loss 0.107708, 0.20 batches/sec.[2K|###############-----| 73.00%, 3679/1359 sec. train epoch 7, iter 730/1000, loss 0.105609, 0.20 batches/sec.[2K|###############-----| 74.00%, 3729/1308 sec. train epoch 7, iter 740/1000, loss 0.103595, 0.20 batches/sec.[2K|###############-----| 75.00%, 3780/1258 sec. train epoch 7, iter 750/1000, loss 0.103002, 0.20 batches/sec.[2K|###############-----| 76.00%, 3830/1207 sec. train epoch 7, iter 760/1000, loss 0.102695, 0.20 batches/sec.[2K|###############-----| 77.00%, 3881/1159 sec. train epoch 7, iter 770/1000, loss 0.104722, 0.20 batches/sec.[2K|################----| 78.00%, 3931/1107 sec. train epoch 7, iter 780/1000, loss 0.102992, 0.20 batches/sec.[2K|################----| 79.00%, 3981/1057 sec. train epoch 7, iter 790/1000, loss 0.103143, 0.20 batches/sec.[2K|################----| 80.00%, 4032/1008 sec. train epoch 7, iter 800/1000, loss 0.100595, 0.20 batches/sec.[2K|################----| 81.00%, 4082/955 sec. train epoch 7, iter 810/1000, loss 0.097297, 0.20 batches/sec.[2K|################----| 82.00%, 4132/907 sec. train epoch 7, iter 820/1000, loss 0.095201, 0.20 batches/sec.[2K|#################---| 83.00%, 4183/856 sec. train epoch 7, iter 830/1000, loss 0.095417, 0.20 batches/sec.[2K|#################---| 84.00%, 4233/806 sec. train epoch 7, iter 840/1000, loss 0.095098, 0.20 batches/sec.[2K|#################---| 85.00%, 4283/756 sec. train epoch 7, iter 850/1000, loss 0.094417, 0.20 batches/sec.[2K|#################---| 86.00%, 4334/704 sec. train epoch 7, iter 860/1000, loss 0.092901, 0.20 batches/sec.[2K|#################---| 87.00%, 4384/655 sec. train epoch 7, iter 870/1000, loss 0.092409, 0.20 batches/sec.[2K|##################--| 88.00%, 4434/603 sec. train epoch 7, iter 880/1000, loss 0.090089, 0.20 batches/sec.[2K|##################--| 89.00%, 4485/554 sec. train epoch 7, iter 890/1000, loss 0.090931, 0.20 batches/sec.[2K|##################--| 90.00%, 4535/503 sec. train epoch 7, iter 900/1000, loss 0.092640, 0.20 batches/sec.[2K|##################--| 91.00%, 4585/452 sec. train epoch 7, iter 910/1000, loss 0.094625, 0.20 batches/sec.[2K|##################--| 92.00%, 4635/402 sec. train epoch 7, iter 920/1000, loss 0.095699, 0.20 batches/sec.[2K|###################-| 93.00%, 4686/352 sec. train epoch 7, iter 930/1000, loss 0.099160, 0.20 batches/sec.[2K|###################-| 94.00%, 4736/302 sec. train epoch 7, iter 940/1000, loss 0.098893, 0.20 batches/sec.[2K|###################-| 95.00%, 4786/252 sec. train epoch 7, iter 950/1000, loss 0.099770, 0.20 batches/sec.[2K|###################-| 96.00%, 4837/201 sec. train epoch 7, iter 960/1000, loss 0.103191, 0.20 batches/sec.[2K|###################-| 97.00%, 4887/151 sec. train epoch 7, iter 970/1000, loss 0.103437, 0.20 batches/sec.[2K|####################| 98.00%, 4937/101 sec. train epoch 7, iter 980/1000, loss 0.101604, 0.20 batches/sec.[2K|####################| 99.00%, 4988/50 sec. train epoch 7, iter 990/1000, loss 0.100749, 0.20 batches/sec.[2K|--------------------| 1.00%, 55/5447 sec. train epoch 8, iter 10/1000, loss 0.123827, 0.21 batches/sec.[2K|--------------------| 2.00%, 105/4945 sec. train epoch 8, iter 20/1000, loss 0.242831, 0.20 batches/sec.[2K|#-------------------| 3.00%, 156/4886 sec. train epoch 8, iter 30/1000, loss 0.272429, 0.20 batches/sec.[2K|#-------------------| 4.00%, 206/4835 sec. train epoch 8, iter 40/1000, loss 0.205304, 0.20 batches/sec.[2K|#-------------------| 5.00%, 257/4779 sec. train epoch 8, iter 50/1000, loss 0.103272, 0.20 batches/sec.[2K|#-------------------| 6.00%, 307/4726 sec. train epoch 8, iter 60/1000, loss 0.077641, 0.20 batches/sec.[2K|#-------------------| 7.00%, 357/4676 sec. train epoch 8, iter 70/1000, loss 0.133309, 0.20 batches/sec.[2K|##------------------| 8.00%, 407/4623 sec. train epoch 8, iter 80/1000, loss 0.140786, 0.20 batches/sec.[2K|##------------------| 9.00%, 458/4581 sec. train epoch 8, iter 90/1000, loss 0.156321, 0.20 batches/sec.[2K|##------------------| 10.00%, 508/4523 sec. train epoch 8, iter 100/1000, loss 0.185047, 0.20 batches/sec.[2K|##------------------| 11.00%, 558/4481 sec. train epoch 8, iter 110/1000, loss 0.200638, 0.20 batches/sec.[2K|##------------------| 12.00%, 609/4442 sec. train epoch 8, iter 120/1000, loss 0.189606, 0.20 batches/sec.[2K|###-----------------| 13.00%, 659/4382 sec. train epoch 8, iter 130/1000, loss 0.206470, 0.20 batches/sec.[2K|###-----------------| 14.00%, 710/4335 sec. train epoch 8, iter 140/1000, loss 0.231357, 0.20 batches/sec.[2K|###-----------------| 15.00%, 760/4279 sec. train epoch 8, iter 150/1000, loss 0.218539, 0.20 batches/sec.[2K|###-----------------| 16.00%, 810/4236 sec. train epoch 8, iter 160/1000, loss 0.231226, 0.20 batches/sec.[2K|###-----------------| 17.00%, 861/4177 sec. train epoch 8, iter 170/1000, loss 0.233688, 0.20 batches/sec.[2K|####----------------| 18.00%, 911/4121 sec. train epoch 8, iter 180/1000, loss 0.223344, 0.20 batches/sec.[2K|####----------------| 19.00%, 961/4078 sec. train epoch 8, iter 190/1000, loss 0.217554, 0.20 batches/sec.[2K|####----------------| 20.00%, 1012/4027 sec. train epoch 8, iter 200/1000, loss 0.222418, 0.20 batches/sec.[2K|####----------------| 21.00%, 1062/3981 sec. train epoch 8, iter 210/1000, loss 0.223412, 0.20 batches/sec.[2K|####----------------| 22.00%, 1112/3929 sec. train epoch 8, iter 220/1000, loss 0.233670, 0.20 batches/sec.[2K|#####---------------| 23.00%, 1163/3881 sec. train epoch 8, iter 230/1000, loss 0.222691, 0.20 batches/sec.[2K|#####---------------| 24.00%, 1213/3824 sec. train epoch 8, iter 240/1000, loss 0.220993, 0.20 batches/sec.[2K|#####---------------| 25.00%, 1263/3774 sec. train epoch 8, iter 250/1000, loss 0.233549, 0.20 batches/sec.[2K|#####---------------| 26.00%, 1314/3730 sec. train epoch 8, iter 260/1000, loss 0.238211, 0.20 batches/sec.[2K|#####---------------| 27.00%, 1364/3669 sec. train epoch 8, iter 270/1000, loss 0.233232, 0.20 batches/sec.[2K|######--------------| 28.00%, 1414/3630 sec. train epoch 8, iter 280/1000, loss 0.241891, 0.20 batches/sec.[2K|######--------------| 29.00%, 1465/3573 sec. train epoch 8, iter 290/1000, loss 0.235984, 0.20 batches/sec.[2K|######--------------| 30.00%, 1515/3520 sec. train epoch 8, iter 300/1000, loss 0.239892, 0.20 batches/sec.[2K|######--------------| 31.00%, 1565/3478 sec. train epoch 8, iter 310/1000, loss 0.240252, 0.20 batches/sec.[2K|######--------------| 32.00%, 1616/3416 sec. train epoch 8, iter 320/1000, loss 0.231522, 0.20 batches/sec.[2K|#######-------------| 33.00%, 1666/3376 sec. train epoch 8, iter 330/1000, loss 0.238532, 0.20 batches/sec.[2K|#######-------------| 34.00%, 1716/3324 sec. train epoch 8, iter 340/1000, loss 0.245915, 0.20 batches/sec.[2K|#######-------------| 35.00%, 1767/3270 sec. train epoch 8, iter 350/1000, loss 0.248698, 0.20 batches/sec.[2K|#######-------------| 36.00%, 1817/3224 sec. train epoch 8, iter 360/1000, loss 0.249188, 0.20 batches/sec.[2K|#######-------------| 37.00%, 1867/3167 sec. train epoch 8, iter 370/1000, loss 0.245605, 0.20 batches/sec.[2K|########------------| 38.00%, 1918/3123 sec. train epoch 8, iter 380/1000, loss 0.245636, 0.20 batches/sec.[2K|########------------| 39.00%, 1968/3067 sec. train epoch 8, iter 390/1000, loss 0.237946, 0.20 batches/sec.[2K|########------------| 40.00%, 2018/3016 sec. train epoch 8, iter 400/1000, loss 0.236846, 0.20 batches/sec.[2K|########------------| 41.00%, 2069/2977 sec. train epoch 8, iter 410/1000, loss 0.228886, 0.20 batches/sec.[32m[2019-03-17 22:27:26 @logger.py:146][0m [2K|####################| 100.00%, 5039/0 sec. train epoch 8, iter 1000/1000, loss 0.227407, 0.20 batches/sec.
[32m[2019-03-17 22:27:30 @logger.py:43][0m [32;1mTrigger callback: [0mTrigger ModelSaver: Save model to model_logs/20190317111349169013_10-255-0-254_mine_NORMAL_wgan_gp_full_model_celeba_hq_256/snap-8000.
[2K|########------------| 42.00%, 2119/2915 sec. train epoch 8, iter 420/1000, loss 0.224223, 0.20 batches/sec.[2K|#########-----------| 43.00%, 2169/2871 sec. train epoch 8, iter 430/1000, loss 0.222535, 0.20 batches/sec.[2K|#########-----------| 44.00%, 2220/2819 sec. train epoch 8, iter 440/1000, loss 0.216583, 0.20 batches/sec.[2K|#########-----------| 45.00%, 2270/2769 sec. train epoch 8, iter 450/1000, loss 0.207740, 0.20 batches/sec.[2K|#########-----------| 46.00%, 2320/2717 sec. train epoch 8, iter 460/1000, loss 0.193962, 0.20 batches/sec.[2K|#########-----------| 47.00%, 2371/2667 sec. train epoch 8, iter 470/1000, loss 0.194504, 0.20 batches/sec.[2K|##########----------| 48.00%, 2421/2617 sec. train epoch 8, iter 480/1000, loss 0.185567, 0.20 batches/sec.[2K|##########----------| 49.00%, 2471/2565 sec. train epoch 8, iter 490/1000, loss 0.186414, 0.20 batches/sec.[2K|##########----------| 50.00%, 2522/2519 sec. train epoch 8, iter 500/1000, loss 0.186151, 0.20 batches/sec.[2K|##########----------| 51.00%, 2572/2464 sec. train epoch 8, iter 510/1000, loss 0.186302, 0.20 batches/sec.[2K|##########----------| 52.00%, 2622/2411 sec. train epoch 8, iter 520/1000, loss 0.199316, 0.20 batches/sec.[2K|###########---------| 53.00%, 2673/2371 sec. train epoch 8, iter 530/1000, loss 0.205064, 0.20 batches/sec.[2K|###########---------| 54.00%, 2723/2313 sec. train epoch 8, iter 540/1000, loss 0.204441, 0.20 batches/sec.[2K|###########---------| 55.00%, 2773/2265 sec. train epoch 8, iter 550/1000, loss 0.206998, 0.20 batches/sec.[2K|###########---------| 56.00%, 2824/2215 sec. train epoch 8, iter 560/1000, loss 0.204323, 0.20 batches/sec.[2K|###########---------| 57.00%, 2874/2164 sec. train epoch 8, iter 570/1000, loss 0.201239, 0.20 batches/sec.[2K|############--------| 58.00%, 2924/2118 sec. train epoch 8, iter 580/1000, loss 0.200047, 0.20 batches/sec.[2K|############--------| 59.00%, 2975/2061 sec. train epoch 8, iter 590/1000, loss 0.201396, 0.20 batches/sec.[2K|############--------| 60.00%, 3025/2018 sec. train epoch 8, iter 600/1000, loss 0.209975, 0.20 batches/sec.[2K|############--------| 61.00%, 3075/1961 sec. train epoch 8, iter 610/1000, loss 0.216386, 0.20 batches/sec.[2K|############--------| 62.00%, 3126/1917 sec. train epoch 8, iter 620/1000, loss 0.223251, 0.20 batches/sec.[2K|#############-------| 63.00%, 3176/1861 sec. train epoch 8, iter 630/1000, loss 0.225802, 0.20 batches/sec.[2K|#############-------| 64.00%, 3227/1815 sec. train epoch 8, iter 640/1000, loss 0.222437, 0.20 batches/sec.[2K|#############-------| 65.00%, 3277/1759 sec. train epoch 8, iter 650/1000, loss 0.224489, 0.20 batches/sec.[2K|#############-------| 66.00%, 3327/1711 sec. train epoch 8, iter 660/1000, loss 0.224396, 0.20 batches/sec.[2K|#############-------| 67.00%, 3378/1664 sec. train epoch 8, iter 670/1000, loss 0.228477, 0.20 batches/sec.[2K|##############------| 68.00%, 3428/1607 sec. train epoch 8, iter 680/1000, loss 0.230336, 0.20 batches/sec.[2K|##############------| 69.00%, 3478/1564 sec. train epoch 8, iter 690/1000, loss 0.226870, 0.20 batches/sec.[2K|##############------| 70.00%, 3529/1512 sec. train epoch 8, iter 700/1000, loss 0.225645, 0.20 batches/sec.[2K|##############------| 71.00%, 3579/1459 sec. train epoch 8, iter 710/1000, loss 0.224964, 0.20 batches/sec.[2K|##############------| 72.00%, 3629/1410 sec. train epoch 8, iter 720/1000, loss 0.219023, 0.20 batches/sec.[2K|###############-----| 73.00%, 3680/1359 sec. train epoch 8, iter 730/1000, loss 0.217093, 0.20 batches/sec.[2K|###############-----| 74.00%, 3730/1314 sec. train epoch 8, iter 740/1000, loss 0.211933, 0.20 batches/sec.[2K|###############-----| 75.00%, 3780/1259 sec. train epoch 8, iter 750/1000, loss 0.210431, 0.20 batches/sec.[2K|###############-----| 76.00%, 3831/1211 sec. train epoch 8, iter 760/1000, loss 0.206459, 0.20 batches/sec.[2K|###############-----| 77.00%, 3881/1159 sec. train epoch 8, iter 770/1000, loss 0.201516, 0.20 batches/sec.[2K|################----| 78.00%, 3932/1106 sec. train epoch 8, iter 780/1000, loss 0.198648, 0.20 batches/sec.[2K|################----| 79.00%, 3982/1059 sec. train epoch 8, iter 790/1000, loss 0.194721, 0.20 batches/sec.[2K|################----| 80.00%, 4032/1006 sec. train epoch 8, iter 800/1000, loss 0.196534, 0.20 batches/sec.[2K|################----| 81.00%, 4083/957 sec. train epoch 8, iter 810/1000, loss 0.197967, 0.20 batches/sec.[2K|################----| 82.00%, 4133/908 sec. train epoch 8, iter 820/1000, loss 0.198367, 0.20 batches/sec.[2K|#################---| 83.00%, 4183/855 sec. train epoch 8, iter 830/1000, loss 0.201797, 0.20 batches/sec.[2K|#################---| 84.00%, 4234/807 sec. train epoch 8, iter 840/1000, loss 0.204538, 0.20 batches/sec.[2K|#################---| 85.00%, 4284/755 sec. train epoch 8, iter 850/1000, loss 0.207164, 0.20 batches/sec.[2K|#################---| 86.00%, 4335/705 sec. train epoch 8, iter 860/1000, loss 0.206836, 0.20 batches/sec.[2K|#################---| 87.00%, 4385/654 sec. train epoch 8, iter 870/1000, loss 0.209286, 0.20 batches/sec.[2K|##################--| 88.00%, 4435/603 sec. train epoch 8, iter 880/1000, loss 0.212362, 0.20 batches/sec.[2K|##################--| 89.00%, 4486/554 sec. train epoch 8, iter 890/1000, loss 0.211741, 0.20 batches/sec.[2K|##################--| 90.00%, 4536/504 sec. train epoch 8, iter 900/1000, loss 0.211776, 0.20 batches/sec.[2K|##################--| 91.00%, 4586/455 sec. train epoch 8, iter 910/1000, loss 0.212313, 0.20 batches/sec.[2K|##################--| 92.00%, 4637/402 sec. train epoch 8, iter 920/1000, loss 0.211144, 0.20 batches/sec.[2K|###################-| 93.00%, 4687/352 sec. train epoch 8, iter 930/1000, loss 0.212454, 0.20 batches/sec.[2K|###################-| 94.00%, 4737/302 sec. train epoch 8, iter 940/1000, loss 0.215053, 0.20 batches/sec.[2K|###################-| 95.00%, 4788/252 sec. train epoch 8, iter 950/1000, loss 0.215747, 0.20 batches/sec.[2K|###################-| 96.00%, 4838/202 sec. train epoch 8, iter 960/1000, loss 0.216236, 0.20 batches/sec.[2K|###################-| 97.00%, 4888/151 sec. train epoch 8, iter 970/1000, loss 0.218240, 0.20 batches/sec.[2K|####################| 98.00%, 4939/101 sec. train epoch 8, iter 980/1000, loss 0.223428, 0.20 batches/sec.[2K|####################| 99.00%, 4989/50 sec. train epoch 8, iter 990/1000, loss 0.224824, 0.20 batches/sec.[2K|--------------------| 1.00%, 55/5461 sec. train epoch 9, iter 10/1000, loss 0.391055, 0.21 batches/sec.[2K|--------------------| 2.00%, 106/4934 sec. train epoch 9, iter 20/1000, loss 0.473497, 0.20 batches/sec.[2K|#-------------------| 3.00%, 156/4881 sec. train epoch 9, iter 30/1000, loss 0.396872, 0.20 batches/sec.[2K|#-------------------| 4.00%, 206/4830 sec. train epoch 9, iter 40/1000, loss 0.369323, 0.20 batches/sec.[2K|#-------------------| 5.00%, 256/4784 sec. train epoch 9, iter 50/1000, loss 0.352607, 0.20 batches/sec.[2K|#-------------------| 6.00%, 307/4739 sec. train epoch 9, iter 60/1000, loss 0.367412, 0.20 batches/sec.[2K|#-------------------| 7.00%, 357/4677 sec. train epoch 9, iter 70/1000, loss 0.317617, 0.20 batches/sec.[2K|##------------------| 8.00%, 408/4639 sec. train epoch 9, iter 80/1000, loss 0.320498, 0.20 batches/sec.[2K|##------------------| 9.00%, 458/4581 sec. train epoch 9, iter 90/1000, loss 0.326098, 0.20 batches/sec.[2K|##------------------| 10.00%, 508/4532 sec. train epoch 9, iter 100/1000, loss 0.335975, 0.20 batches/sec.[2K|##------------------| 11.00%, 559/4486 sec. train epoch 9, iter 110/1000, loss 0.341688, 0.20 batches/sec.[2K|##------------------| 12.00%, 609/4423 sec. train epoch 9, iter 120/1000, loss 0.308760, 0.20 batches/sec.[2K|###-----------------| 13.00%, 659/4386 sec. train epoch 9, iter 130/1000, loss 0.287823, 0.20 batches/sec.[2K|###-----------------| 14.00%, 710/4324 sec. train epoch 9, iter 140/1000, loss 0.280493, 0.20 batches/sec.[2K|###-----------------| 15.00%, 760/4272 sec. train epoch 9, iter 150/1000, loss 0.277608, 0.20 batches/sec.[2K|###-----------------| 16.00%, 810/4231 sec. train epoch 9, iter 160/1000, loss 0.270601, 0.20 batches/sec.[2K|###-----------------| 17.00%, 861/4176 sec. train epoch 9, iter 170/1000, loss 0.258436, 0.20 batches/sec.[2K|####----------------| 18.00%, 911/4135 sec. train epoch 9, iter 180/1000, loss 0.260363, 0.20 batches/sec.[2K|####----------------| 19.00%, 961/4074 sec. train epoch 9, iter 190/1000, loss 0.261995, 0.20 batches/sec.[2K|####----------------| 20.00%, 1012/4033 sec. train epoch 9, iter 200/1000, loss 0.258225, 0.20 batches/sec.[2K|####----------------| 21.00%, 1062/3977 sec. train epoch 9, iter 210/1000, loss 0.248204, 0.20 batches/sec.[2K|####----------------| 22.00%, 1112/3927 sec. train epoch 9, iter 220/1000, loss 0.267046, 0.20 batches/sec.[2K|#####---------------| 23.00%, 1163/3882 sec. train epoch 9, iter 230/1000, loss 0.263121, 0.20 batches/sec.[2K|#####---------------| 24.00%, 1213/3823 sec. train epoch 9, iter 240/1000, loss 0.253160, 0.20 batches/sec.[2K|#####---------------| 25.00%, 1264/3785 sec. train epoch 9, iter 250/1000, loss 0.248136, 0.20 batches/sec.[2K|#####---------------| 26.00%, 1314/3723 sec. train epoch 9, iter 260/1000, loss 0.246675, 0.20 batches/sec.[2K|#####---------------| 27.00%, 1364/3681 sec. train epoch 9, iter 270/1000, loss 0.247668, 0.20 batches/sec.[2K|######--------------| 28.00%, 1415/3628 sec. train epoch 9, iter 280/1000, loss 0.245199, 0.20 batches/sec.[2K|######--------------| 29.00%, 1465/3574 sec. train epoch 9, iter 290/1000, loss 0.251350, 0.20 batches/sec.[2K|######--------------| 30.00%, 1516/3531 sec. train epoch 9, iter 300/1000, loss 0.252885, 0.20 batches/sec.[2K|######--------------| 31.00%, 1566/3473 sec. train epoch 9, iter 310/1000, loss 0.249326, 0.20 batches/sec.[2K|######--------------| 32.00%, 1616/3426 sec. train epoch 9, iter 320/1000, loss 0.241924, 0.20 batches/sec.[2K|#######-------------| 33.00%, 1667/3371 sec. train epoch 9, iter 330/1000, loss 0.236957, 0.20 batches/sec.[2K|#######-------------| 34.00%, 1717/3318 sec. train epoch 9, iter 340/1000, loss 0.220706, 0.20 batches/sec.[2K|#######-------------| 35.00%, 1767/3277 sec. train epoch 9, iter 350/1000, loss 0.210130, 0.20 batches/sec.[2K|#######-------------| 36.00%, 1818/3217 sec. train epoch 9, iter 360/1000, loss 0.206380, 0.20 batches/sec.[2K|#######-------------| 37.00%, 1868/3177 sec. train epoch 9, iter 370/1000, loss 0.192305, 0.20 batches/sec.[2K|########------------| 38.00%, 1918/3119 sec. train epoch 9, iter 380/1000, loss 0.193812, 0.20 batches/sec.[2K|########------------| 39.00%, 1969/3075 sec. train epoch 9, iter 390/1000, loss 0.179415, 0.20 batches/sec.[2K|########------------| 40.00%, 2019/3022 sec. train epoch 9, iter 400/1000, loss 0.169748, 0.20 batches/sec.[2K|########------------| 41.00%, 2069/2968 sec. train epoch 9, iter 410/1000, loss 0.170609, 0.20 batches/sec.[2K|########------------| 42.00%, 2120/2918 sec. train epoch 9, iter 420/1000, loss 0.162921, 0.20 batches/sec.[2K|#########-----------| 43.00%, 2170/2868 sec. train epoch 9, iter 430/1000, loss 0.157651, 0.20 batches/sec.[2K|#########-----------| 44.00%, 2220/2819 sec. train epoch 9, iter 440/1000, loss 0.150250, 0.20 batches/sec.[2K|#########-----------| 45.00%, 2271/2768 sec. train epoch 9, iter 450/1000, loss 0.150197, 0.20 batches/sec.[2K|#########-----------| 46.00%, 2321/2719 sec. train epoch 9, iter 460/1000, loss 0.143706, 0.20 batches/sec.[2K|#########-----------| 47.00%, 2371/2666 sec. train epoch 9, iter 470/1000, loss 0.148342, 0.20 batches/sec.[2K|##########----------| 48.00%, 2422/2613 sec. train epoch 9, iter 480/1000, loss 0.146976, 0.20 batches/sec.[2K|##########----------| 49.00%, 2472/2566 sec. train epoch 9, iter 490/1000, loss 0.155357, 0.20 batches/sec.[2K|##########----------| 50.00%, 2522/2516 sec. train epoch 9, iter 500/1000, loss 0.161446, 0.20 batches/sec.[2K|##########----------| 51.00%, 2573/2466 sec. train epoch 9, iter 510/1000, loss 0.161080, 0.20 batches/sec.[2K|##########----------| 52.00%, 2623/2415 sec. train epoch 9, iter 520/1000, loss 0.158924, 0.20 batches/sec.[2K|###########---------| 53.00%, 2673/2363 sec. train epoch 9, iter 530/1000, loss 0.152982, 0.20 batches/sec.[2K|###########---------| 54.00%, 2724/2320 sec. train epoch 9, iter 540/1000, loss 0.154700, 0.20 batches/sec.[2K|###########---------| 55.00%, 2774/2270 sec. train epoch 9, iter 550/1000, loss 0.151045, 0.20 batches/sec.[2K|###########---------| 56.00%, 2824/2215 sec. train epoch 9, iter 560/1000, loss 0.144770, 0.20 batches/sec.[2K|###########---------| 57.00%, 2875/2170 sec. train epoch 9, iter 570/1000, loss 0.144335, 0.20 batches/sec.[2K|############--------| 58.00%, 2925/2113 sec. train epoch 9, iter 580/1000, loss 0.141528, 0.20 batches/sec.[2K|############--------| 59.00%, 2976/2069 sec. train epoch 9, iter 590/1000, loss 0.142945, 0.20 batches/sec.[2K|############--------| 60.00%, 3026/2014 sec. train epoch 9, iter 600/1000, loss 0.138250, 0.20 batches/sec.[2K|############--------| 61.00%, 3076/1965 sec. train epoch 9, iter 610/1000, loss 0.129383, 0.20 batches/sec.[2K|############--------| 62.00%, 3127/1914 sec. train epoch 9, iter 620/1000, loss 0.124406, 0.20 batches/sec.[2K|#############-------| 63.00%, 3177/1860 sec. train epoch 9, iter 630/1000, loss 0.121339, 0.20 batches/sec.[2K|#############-------| 64.00%, 3227/1815 sec. train epoch 9, iter 640/1000, loss 0.115308, 0.20 batches/sec.[2K|#############-------| 65.00%, 3278/1759 sec. train epoch 9, iter 650/1000, loss 0.116642, 0.20 batches/sec.[2K|#############-------| 66.00%, 3328/1713 sec. train epoch 9, iter 660/1000, loss 0.112199, 0.20 batches/sec.[2K|#############-------| 67.00%, 3378/1661 sec. train epoch 9, iter 670/1000, loss 0.108084, 0.20 batches/sec.[2K|##############------| 68.00%, 3429/1612 sec. train epoch 9, iter 680/1000, loss 0.108841, 0.20 batches/sec.[2K|##############------| 69.00%, 3479/1562 sec. train epoch 9, iter 690/1000, loss 0.110741, 0.20 batches/sec.[2K|##############------| 70.00%, 3529/1511 sec. train epoch 9, iter 700/1000, loss 0.111801, 0.20 batches/sec.[2K|##############------| 71.00%, 3580/1462 sec. train epoch 9, iter 710/1000, loss 0.108393, 0.20 batches/sec.[2K|##############------| 72.00%, 3630/1411 sec. train epoch 9, iter 720/1000, loss 0.113453, 0.20 batches/sec.[2K|###############-----| 73.00%, 3681/1359 sec. train epoch 9, iter 730/1000, loss 0.109074, 0.20 batches/sec.[2K|###############-----| 74.00%, 3731/1312 sec. train epoch 9, iter 740/1000, loss 0.110101, 0.20 batches/sec.[2K|###############-----| 75.00%, 3781/1258 sec. train epoch 9, iter 750/1000, loss 0.115291, 0.20 batches/sec.[2K|###############-----| 76.00%, 3832/1210 sec. train epoch 9, iter 760/1000, loss 0.123402, 0.20 batches/sec.[2K|###############-----| 77.00%, 3882/1159 sec. train epoch 9, iter 770/1000, loss 0.121905, 0.20 batches/sec.[2K|################----| 78.00%, 3932/1105 sec. train epoch 9, iter 780/1000, loss 0.125846, 0.20 batches/sec.[2K|################----| 79.00%, 3983/1058 sec. train epoch 9, iter 790/1000, loss 0.133648, 0.20 batches/sec.[2K|################----| 80.00%, 4033/1006 sec. train epoch 9, iter 800/1000, loss 0.137304, 0.20 batches/sec.[2K|################----| 81.00%, 4084/958 sec. train epoch 9, iter 810/1000, loss 0.142557, 0.20 batches/sec.[2K|################----| 82.00%, 4134/908 sec. train epoch 9, iter 820/1000, loss 0.145575, 0.20 batches/sec.[2K|#################---| 83.00%, 4184/857 sec. train epoch 9, iter 830/1000, loss 0.147953, 0.20 batches/sec.[2K|#################---| 84.00%, 4235/807 sec. train epoch 9, iter 840/1000, loss 0.150486, 0.20 batches/sec.[2K|#################---| 85.00%, 4285/754 sec. train epoch 9, iter 850/1000, loss 0.150173, 0.20 batches/sec.[2K|#################---| 86.00%, 4336/707 sec. train epoch 9, iter 860/1000, loss 0.150744, 0.20 batches/sec.[2K|#################---| 87.00%, 4386/654 sec. train epoch 9, iter 870/1000, loss 0.150992, 0.20 batches/sec.[2K|##################--| 88.00%, 4436/604 sec. train epoch 9, iter 880/1000, loss 0.152120, 0.20 batches/sec.[32m[2019-03-17 23:51:26 @logger.py:146][0m [2K|####################| 100.00%, 5041/0 sec. train epoch 9, iter 1000/1000, loss 0.147279, 0.20 batches/sec.
[32m[2019-03-17 23:51:30 @logger.py:43][0m [32;1mTrigger callback: [0mTrigger ModelSaver: Save model to model_logs/20190317111349169013_10-255-0-254_mine_NORMAL_wgan_gp_full_model_celeba_hq_256/snap-9000.
[2K|##################--| 89.00%, 4487/553 sec. train epoch 9, iter 890/1000, loss 0.151104, 0.20 batches/sec.[2K|##################--| 90.00%, 4537/503 sec. train epoch 9, iter 900/1000, loss 0.150583, 0.20 batches/sec.[2K|##################--| 91.00%, 4587/454 sec. train epoch 9, iter 910/1000, loss 0.148620, 0.20 batches/sec.[2K|##################--| 92.00%, 4638/402 sec. train epoch 9, iter 920/1000, loss 0.144970, 0.20 batches/sec.[2K|###################-| 93.00%, 4688/353 sec. train epoch 9, iter 930/1000, loss 0.146824, 0.20 batches/sec.[2K|###################-| 94.00%, 4738/302 sec. train epoch 9, iter 940/1000, loss 0.147022, 0.20 batches/sec.[2K|###################-| 95.00%, 4789/252 sec. train epoch 9, iter 950/1000, loss 0.147251, 0.20 batches/sec.[2K|###################-| 96.00%, 4839/201 sec. train epoch 9, iter 960/1000, loss 0.146441, 0.20 batches/sec.[2K|###################-| 97.00%, 4889/151 sec. train epoch 9, iter 970/1000, loss 0.147173, 0.20 batches/sec.[2K|####################| 98.00%, 4940/101 sec. train epoch 9, iter 980/1000, loss 0.147553, 0.20 batches/sec.[2K|####################| 99.00%, 4990/50 sec. train epoch 9, iter 990/1000, loss 0.149379, 0.20 batches/sec.[2K|--------------------| 1.00%, 55/5463 sec. train epoch 10, iter 10/1000, loss -0.184182, 0.21 batches/sec.[2K|--------------------| 2.00%, 105/4928 sec. train epoch 10, iter 20/1000, loss 0.000970, 0.20 batches/sec.[2K|#-------------------| 3.00%, 156/4890 sec. train epoch 10, iter 30/1000, loss -0.004766, 0.20 batches/sec.[2K|#-------------------| 4.00%, 206/4834 sec. train epoch 10, iter 40/1000, loss 0.013696, 0.20 batches/sec.[2K|#-------------------| 5.00%, 257/4786 sec. train epoch 10, iter 50/1000, loss -0.027675, 0.20 batches/sec.[2K|#-------------------| 6.00%, 307/4731 sec. train epoch 10, iter 60/1000, loss -0.069709, 0.20 batches/sec.[2K|#-------------------| 7.00%, 357/4683 sec. train epoch 10, iter 70/1000, loss -0.085169, 0.20 batches/sec.[2K|##------------------| 8.00%, 408/4640 sec. train epoch 10, iter 80/1000, loss -0.107743, 0.20 batches/sec.[2K|##------------------| 9.00%, 458/4578 sec. train epoch 10, iter 90/1000, loss -0.092368, 0.20 batches/sec.[2K|##------------------| 10.00%, 508/4541 sec. train epoch 10, iter 100/1000, loss -0.053669, 0.20 batches/sec.[2K|##------------------| 11.00%, 559/4487 sec. train epoch 10, iter 110/1000, loss -0.058737, 0.20 batches/sec.[2K|##------------------| 12.00%, 609/4433 sec. train epoch 10, iter 120/1000, loss -0.028726, 0.20 batches/sec.[2K|###-----------------| 13.00%, 660/4396 sec. train epoch 10, iter 130/1000, loss -0.015604, 0.20 batches/sec.[2K|###-----------------| 14.00%, 710/4325 sec. train epoch 10, iter 140/1000, loss -0.007347, 0.20 batches/sec.[2K|###-----------------| 15.00%, 761/4286 sec. train epoch 10, iter 150/1000, loss -0.008726, 0.20 batches/sec.[2K|###-----------------| 16.00%, 811/4231 sec. train epoch 10, iter 160/1000, loss 0.001541, 0.20 batches/sec.[2K|###-----------------| 17.00%, 861/4183 sec. train epoch 10, iter 170/1000, loss 0.014206, 0.20 batches/sec.[2K|####----------------| 18.00%, 912/4137 sec. train epoch 10, iter 180/1000, loss -0.005054, 0.20 batches/sec.[2K|####----------------| 19.00%, 962/4082 sec. train epoch 10, iter 190/1000, loss 0.007094, 0.20 batches/sec.[2K|####----------------| 20.00%, 1013/4035 sec. train epoch 10, iter 200/1000, loss 0.010609, 0.20 batches/sec.[2K|####----------------| 21.00%, 1063/3971 sec. train epoch 10, iter 210/1000, loss 0.016325, 0.20 batches/sec.[2K|####----------------| 22.00%, 1113/3931 sec. train epoch 10, iter 220/1000, loss 0.021688, 0.20 batches/sec.[2K|#####---------------| 23.00%, 1164/3875 sec. train epoch 10, iter 230/1000, loss 0.026027, 0.20 batches/sec.[2K|#####---------------| 24.00%, 1214/3828 sec. train epoch 10, iter 240/1000, loss 0.030159, 0.20 batches/sec.[2K|#####---------------| 25.00%, 1264/3782 sec. train epoch 10, iter 250/1000, loss 0.043049, 0.20 batches/sec.[2K|#####---------------| 26.00%, 1315/3724 sec. train epoch 10, iter 260/1000, loss 0.045519, 0.20 batches/sec.[2K|#####---------------| 27.00%, 1365/3682 sec. train epoch 10, iter 270/1000, loss 0.051319, 0.20 batches/sec.[2K|######--------------| 28.00%, 1416/3629 sec. train epoch 10, iter 280/1000, loss 0.051956, 0.20 batches/sec.[2K|######--------------| 29.00%, 1466/3578 sec. train epoch 10, iter 290/1000, loss 0.051168, 0.20 batches/sec.[2K|######--------------| 30.00%, 1516/3520 sec. train epoch 10, iter 300/1000, loss 0.049369, 0.20 batches/sec.[2K|######--------------| 31.00%, 1567/3480 sec. train epoch 10, iter 310/1000, loss 0.055895, 0.20 batches/sec.[2K|######--------------| 32.00%, 1617/3425 sec. train epoch 10, iter 320/1000, loss 0.062985, 0.20 batches/sec.[2K|#######-------------| 33.00%, 1667/3372 sec. train epoch 10, iter 330/1000, loss 0.066877, 0.20 batches/sec.[2K|#######-------------| 34.00%, 1718/3326 sec. train epoch 10, iter 340/1000, loss 0.075364, 0.20 batches/sec.[2K|#######-------------| 35.00%, 1768/3275 sec. train epoch 10, iter 350/1000, loss 0.085493, 0.20 batches/sec.[2K|#######-------------| 36.00%, 1819/3230 sec. train epoch 10, iter 360/1000, loss 0.086476, 0.20 batches/sec.[2K|#######-------------| 37.00%, 1869/3175 sec. train epoch 10, iter 370/1000, loss 0.088172, 0.20 batches/sec.[2K|########------------| 38.00%, 1919/3123 sec. train epoch 10, iter 380/1000, loss 0.094974, 0.20 batches/sec.[2K|########------------| 39.00%, 1970/3077 sec. train epoch 10, iter 390/1000, loss 0.098933, 0.20 batches/sec.[2K|########------------| 40.00%, 2020/3014 sec. train epoch 10, iter 400/1000, loss 0.089732, 0.20 batches/sec.[2K|########------------| 41.00%, 2070/2967 sec. train epoch 10, iter 410/1000, loss 0.094912, 0.20 batches/sec.[2K|########------------| 42.00%, 2121/2923 sec. train epoch 10, iter 420/1000, loss 0.099696, 0.20 batches/sec.[2K|#########-----------| 43.00%, 2171/2867 sec. train epoch 10, iter 430/1000, loss 0.096615, 0.20 batches/sec.[2K|#########-----------| 44.00%, 2221/2826 sec. train epoch 10, iter 440/1000, loss 0.097982, 0.20 batches/sec.[2K|#########-----------| 45.00%, 2272/2770 sec. train epoch 10, iter 450/1000, loss 0.094278, 0.20 batches/sec.[2K|#########-----------| 46.00%, 2322/2727 sec. train epoch 10, iter 460/1000, loss 0.091496, 0.20 batches/sec.[2K|#########-----------| 47.00%, 2373/2670 sec. train epoch 10, iter 470/1000, loss 0.089421, 0.20 batches/sec.[2K|##########----------| 48.00%, 2423/2616 sec. train epoch 10, iter 480/1000, loss 0.098591, 0.20 batches/sec.[2K|##########----------| 49.00%, 2473/2569 sec. train epoch 10, iter 490/1000, loss 0.101864, 0.20 batches/sec.[2K|##########----------| 50.00%, 2524/2516 sec. train epoch 10, iter 500/1000, loss 0.106980, 0.20 batches/sec.[2K|##########----------| 51.00%, 2574/2470 sec. train epoch 10, iter 510/1000, loss 0.109590, 0.20 batches/sec.[2K|##########----------| 52.00%, 2624/2415 sec. train epoch 10, iter 520/1000, loss 0.113327, 0.20 batches/sec.[2K|###########---------| 53.00%, 2675/2370 sec. train epoch 10, iter 530/1000, loss 0.119128, 0.20 batches/sec.[2K|###########---------| 54.00%, 2725/2317 sec. train epoch 10, iter 540/1000, loss 0.119284, 0.20 batches/sec.[2K|###########---------| 55.00%, 2776/2265 sec. train epoch 10, iter 550/1000, loss 0.127584, 0.20 batches/sec.[2K|###########---------| 56.00%, 2826/2219 sec. train epoch 10, iter 560/1000, loss 0.127612, 0.20 batches/sec.[2K|###########---------| 57.00%, 2876/2161 sec. train epoch 10, iter 570/1000, loss 0.131452, 0.20 batches/sec.[2K|############--------| 58.00%, 2927/2118 sec. train epoch 10, iter 580/1000, loss 0.126257, 0.20 batches/sec.[2K|############--------| 59.00%, 2977/2062 sec. train epoch 10, iter 590/1000, loss 0.121672, 0.20 batches/sec.[2K|############--------| 60.00%, 3027/2011 sec. train epoch 10, iter 600/1000, loss 0.125492, 0.20 batches/sec.[2K|############--------| 61.00%, 3078/1964 sec. train epoch 10, iter 610/1000, loss 0.122604, 0.20 batches/sec.[2K|############--------| 62.00%, 3128/1913 sec. train epoch 10, iter 620/1000, loss 0.123520, 0.20 batches/sec.[32m[2019-03-18 01:15:29 @logger.py:146][0m [2K|####################| 100.00%, 5043/0 sec. train epoch 10, iter 1000/1000, loss 0.090545, 0.20 batches/sec.
[32m[2019-03-18 01:15:33 @logger.py:43][0m [32;1mTrigger callback: [0mTrigger ModelSaver: Save model to model_logs/20190317111349169013_10-255-0-254_mine_NORMAL_wgan_gp_full_model_celeba_hq_256/snap-10000.
[2K|#############-------| 63.00%, 3178/1867 sec. train epoch 10, iter 630/1000, loss 0.120691, 0.20 batches/sec.[2K|#############-------| 64.00%, 3229/1812 sec. train epoch 10, iter 640/1000, loss 0.118972, 0.20 batches/sec.[2K|#############-------| 65.00%, 3279/1762 sec. train epoch 10, iter 650/1000, loss 0.120038, 0.20 batches/sec.[2K|#############-------| 66.00%, 3330/1714 sec. train epoch 10, iter 660/1000, loss 0.118332, 0.20 batches/sec.[2K|#############-------| 67.00%, 3380/1660 sec. train epoch 10, iter 670/1000, loss 0.117451, 0.20 batches/sec.[2K|##############------| 68.00%, 3430/1617 sec. train epoch 10, iter 680/1000, loss 0.112276, 0.20 batches/sec.[2K|##############------| 69.00%, 3481/1561 sec. train epoch 10, iter 690/1000, loss 0.106675, 0.20 batches/sec.[2K|##############------| 70.00%, 3531/1512 sec. train epoch 10, iter 700/1000, loss 0.103516, 0.20 batches/sec.[2K|##############------| 71.00%, 3582/1464 sec. train epoch 10, iter 710/1000, loss 0.100121, 0.20 batches/sec.[2K|##############------| 72.00%, 3632/1411 sec. train epoch 10, iter 720/1000, loss 0.096657, 0.20 batches/sec.[2K|###############-----| 73.00%, 3682/1361 sec. train epoch 10, iter 730/1000, loss 0.097071, 0.20 batches/sec.[2K|###############-----| 74.00%, 3733/1308 sec. train epoch 10, iter 740/1000, loss 0.093335, 0.20 batches/sec.[2K|###############-----| 75.00%, 3783/1258 sec. train epoch 10, iter 750/1000, loss 0.098524, 0.20 batches/sec.[2K|###############-----| 76.00%, 3833/1208 sec. train epoch 10, iter 760/1000, loss 0.097121, 0.20 batches/sec.[2K|###############-----| 77.00%, 3884/1157 sec. train epoch 10, iter 770/1000, loss 0.095155, 0.20 batches/sec.[2K|################----| 78.00%, 3934/1110 sec. train epoch 10, iter 780/1000, loss 0.095497, 0.20 batches/sec.[2K|################----| 79.00%, 3984/1056 sec. train epoch 10, iter 790/1000, loss 0.095822, 0.20 batches/sec.[2K|################----| 80.00%, 4035/1008 sec. train epoch 10, iter 800/1000, loss 0.094616, 0.20 batches/sec.[2K|################----| 81.00%, 4085/959 sec. train epoch 10, iter 810/1000, loss 0.093597, 0.20 batches/sec.[2K|################----| 82.00%, 4136/909 sec. train epoch 10, iter 820/1000, loss 0.094057, 0.20 batches/sec.[2K|#################---| 83.00%, 4186/859 sec. train epoch 10, iter 830/1000, loss 0.090645, 0.20 batches/sec.[2K|#################---| 84.00%, 4237/804 sec. train epoch 10, iter 840/1000, loss 0.095697, 0.20 batches/sec.[2K|#################---| 85.00%, 4287/755 sec. train epoch 10, iter 850/1000, loss 0.096816, 0.20 batches/sec.[2K|#################---| 86.00%, 4337/705 sec. train epoch 10, iter 860/1000, loss 0.096911, 0.20 batches/sec.[2K|#################---| 87.00%, 4388/656 sec. train epoch 10, iter 870/1000, loss 0.097063, 0.20 batches/sec.[2K|##################--| 88.00%, 4438/605 sec. train epoch 10, iter 880/1000, loss 0.097528, 0.20 batches/sec.[2K|##################--| 89.00%, 4488/554 sec. train epoch 10, iter 890/1000, loss 0.099993, 0.20 batches/sec.[2K|##################--| 90.00%, 4539/504 sec. train epoch 10, iter 900/1000, loss 0.096884, 0.20 batches/sec.[2K|##################--| 91.00%, 4589/454 sec. train epoch 10, iter 910/1000, loss 0.099054, 0.20 batches/sec.[2K|##################--| 92.00%, 4640/404 sec. train epoch 10, iter 920/1000, loss 0.098663, 0.20 batches/sec.[2K|###################-| 93.00%, 4690/353 sec. train epoch 10, iter 930/1000, loss 0.099131, 0.20 batches/sec.[2K|###################-| 94.00%, 4741/302 sec. train epoch 10, iter 940/1000, loss 0.101291, 0.20 batches/sec.[2K|###################-| 95.00%, 4791/252 sec. train epoch 10, iter 950/1000, loss 0.096751, 0.20 batches/sec.[2K|###################-| 96.00%, 4841/201 sec. train epoch 10, iter 960/1000, loss 0.094888, 0.20 batches/sec.[2K|###################-| 97.00%, 4892/151 sec. train epoch 10, iter 970/1000, loss 0.093024, 0.20 batches/sec.[2K|####################| 98.00%, 4942/101 sec. train epoch 10, iter 980/1000, loss 0.090318, 0.20 batches/sec.[2K|####################| 99.00%, 4993/50 sec. train epoch 10, iter 990/1000, loss 0.092544, 0.20 batches/sec.[2K|--------------------| 1.00%, 55/5452 sec. train epoch 11, iter 10/1000, loss 0.270811, 0.21 batches/sec.[2K|--------------------| 2.00%, 105/4940 sec. train epoch 11, iter 20/1000, loss 0.186648, 0.20 batches/sec.[2K|#-------------------| 3.00%, 156/4888 sec. train epoch 11, iter 30/1000, loss 0.071206, 0.20 batches/sec.[2K|#-------------------| 4.00%, 206/4832 sec. train epoch 11, iter 40/1000, loss 0.061185, 0.20 batches/sec.[2K|#-------------------| 5.00%, 257/4786 sec. train epoch 11, iter 50/1000, loss 0.094242, 0.20 batches/sec.[2K|#-------------------| 6.00%, 307/4730 sec. train epoch 11, iter 60/1000, loss 0.049071, 0.20 batches/sec.[2K|#-------------------| 7.00%, 357/4697 sec. train epoch 11, iter 70/1000, loss 0.008444, 0.20 batches/sec.[2K|##------------------| 8.00%, 408/4627 sec. train epoch 11, iter 80/1000, loss -0.000792, 0.20 batches/sec.[2K|##------------------| 9.00%, 458/4583 sec. train epoch 11, iter 90/1000, loss -0.033523, 0.20 batches/sec.[2K|##------------------| 10.00%, 508/4538 sec. train epoch 11, iter 100/1000, loss 0.003238, 0.20 batches/sec.[2K|##------------------| 11.00%, 559/4479 sec. train epoch 11, iter 110/1000, loss -0.002360, 0.20 batches/sec.[2K|##------------------| 12.00%, 609/4445 sec. train epoch 11, iter 120/1000, loss -0.022690, 0.20 batches/sec.[2K|###-----------------| 13.00%, 660/4381 sec. train epoch 11, iter 130/1000, loss -0.036327, 0.20 batches/sec.[2K|###-----------------| 14.00%, 710/4337 sec. train epoch 11, iter 140/1000, loss -0.018656, 0.20 batches/sec.[2K|###-----------------| 15.00%, 760/4282 sec. train epoch 11, iter 150/1000, loss 0.002176, 0.20 batches/sec.[2K|###-----------------| 16.00%, 811/4228 sec. train epoch 11, iter 160/1000, loss 0.007277, 0.20 batches/sec.[2K|###-----------------| 17.00%, 861/4184 sec. train epoch 11, iter 170/1000, loss 0.013822, 0.20 batches/sec.[2K|####----------------| 18.00%, 912/4131 sec. train epoch 11, iter 180/1000, loss 0.021645, 0.20 batches/sec.[2K|####----------------| 19.00%, 962/4083 sec. train epoch 11, iter 190/1000, loss 0.024304, 0.20 batches/sec.[2K|####----------------| 20.00%, 1012/4026 sec. train epoch 11, iter 200/1000, loss 0.022056, 0.20 batches/sec.[2K|####----------------| 21.00%, 1063/3981 sec. train epoch 11, iter 210/1000, loss 0.021318, 0.20 batches/sec.[2K|####----------------| 22.00%, 1113/3931 sec. train epoch 11, iter 220/1000, loss 0.022253, 0.20 batches/sec.[2K|#####---------------| 23.00%, 1163/3876 sec. train epoch 11, iter 230/1000, loss 0.013090, 0.20 batches/sec.[2K|#####---------------| 24.00%, 1214/3834 sec. train epoch 11, iter 240/1000, loss 0.005739, 0.20 batches/sec.[2K|#####---------------| 25.00%, 1264/3775 sec. train epoch 11, iter 250/1000, loss 0.011909, 0.20 batches/sec.[2K|#####---------------| 26.00%, 1315/3733 sec. train epoch 11, iter 260/1000, loss 0.014767, 0.20 batches/sec.[2K|#####---------------| 27.00%, 1365/3677 sec. train epoch 11, iter 270/1000, loss 0.011809, 0.20 batches/sec.[2K|######--------------| 28.00%, 1415/3621 sec. train epoch 11, iter 280/1000, loss 0.017616, 0.20 batches/sec.[2K|######--------------| 29.00%, 1466/3583 sec. train epoch 11, iter 290/1000, loss 0.014726, 0.20 batches/sec.[2K|######--------------| 30.00%, 1516/3521 sec. train epoch 11, iter 300/1000, loss 0.023420, 0.20 batches/sec.[2K|######--------------| 31.00%, 1566/3476 sec. train epoch 11, iter 310/1000, loss 0.028880, 0.20 batches/sec.[2K|######--------------| 32.00%, 1617/3429 sec. train epoch 11, iter 320/1000, loss 0.031021, 0.20 batches/sec.[2K|#######-------------| 33.00%, 1667/3375 sec. train epoch 11, iter 330/1000, loss 0.037171, 0.20 batches/sec.[2K|#######-------------| 34.00%, 1718/3335 sec. train epoch 11, iter 340/1000, loss 0.036920, 0.20 batches/sec.[2K|#######-------------| 35.00%, 1768/3268 sec. train epoch 11, iter 350/1000, loss 0.036336, 0.20 batches/sec.[2K|#######-------------| 36.00%, 1818/3224 sec. train epoch 11, iter 360/1000, loss 0.031833, 0.20 batches/sec.[32m[2019-03-18 02:39:32 @logger.py:146][0m [2K|####################| 100.00%, 5042/0 sec. train epoch 11, iter 1000/1000, loss 0.056234, 0.20 batches/sec.
[32m[2019-03-18 02:39:35 @logger.py:43][0m [32;1mTrigger callback: [0mTrigger ModelSaver: Save model to model_logs/20190317111349169013_10-255-0-254_mine_NORMAL_wgan_gp_full_model_celeba_hq_256/snap-11000.
[2K|#######-------------| 37.00%, 1869/3170 sec. train epoch 11, iter 370/1000, loss 0.029023, 0.20 batches/sec.[2K|########------------| 38.00%, 1919/3120 sec. train epoch 11, iter 380/1000, loss 0.027474, 0.20 batches/sec.[2K|########------------| 39.00%, 1970/3080 sec. train epoch 11, iter 390/1000, loss 0.031926, 0.20 batches/sec.[2K|########------------| 40.00%, 2020/3021 sec. train epoch 11, iter 400/1000, loss 0.031288, 0.20 batches/sec.[2K|########------------| 41.00%, 2070/2974 sec. train epoch 11, iter 410/1000, loss 0.034319, 0.20 batches/sec.[2K|########------------| 42.00%, 2121/2922 sec. train epoch 11, iter 420/1000, loss 0.036668, 0.20 batches/sec.[2K|#########-----------| 43.00%, 2171/2872 sec. train epoch 11, iter 430/1000, loss 0.038735, 0.20 batches/sec.[2K|#########-----------| 44.00%, 2221/2821 sec. train epoch 11, iter 440/1000, loss 0.037379, 0.20 batches/sec.[2K|#########-----------| 45.00%, 2272/2772 sec. train epoch 11, iter 450/1000, loss 0.024808, 0.20 batches/sec.[2K|#########-----------| 46.00%, 2322/2724 sec. train epoch 11, iter 460/1000, loss 0.028215, 0.20 batches/sec.[2K|#########-----------| 47.00%, 2373/2670 sec. train epoch 11, iter 470/1000, loss 0.029409, 0.20 batches/sec.[2K|##########----------| 48.00%, 2423/2618 sec. train epoch 11, iter 480/1000, loss 0.031209, 0.20 batches/sec.[2K|##########----------| 49.00%, 2473/2570 sec. train epoch 11, iter 490/1000, loss 0.031711, 0.20 batches/sec.[2K|##########----------| 50.00%, 2524/2518 sec. train epoch 11, iter 500/1000, loss 0.028479, 0.20 batches/sec.[2K|##########----------| 51.00%, 2574/2474 sec. train epoch 11, iter 510/1000, loss 0.032380, 0.20 batches/sec.[2K|##########----------| 52.00%, 2625/2415 sec. train epoch 11, iter 520/1000, loss 0.028907, 0.20 batches/sec.[2K|###########---------| 53.00%, 2675/2370 sec. train epoch 11, iter 530/1000, loss 0.029192, 0.20 batches/sec.[2K|###########---------| 54.00%, 2725/2316 sec. train epoch 11, iter 540/1000, loss 0.036780, 0.20 batches/sec.[2K|###########---------| 55.00%, 2776/2267 sec. train epoch 11, iter 550/1000, loss 0.036399, 0.20 batches/sec.[2K|###########---------| 56.00%, 2826/2217 sec. train epoch 11, iter 560/1000, loss 0.038699, 0.20 batches/sec.[2K|###########---------| 57.00%, 2876/2163 sec. train epoch 11, iter 570/1000, loss 0.037427, 0.20 batches/sec.[2K|############--------| 58.00%, 2927/2118 sec. train epoch 11, iter 580/1000, loss 0.039685, 0.20 batches/sec.[2K|############--------| 59.00%, 2977/2062 sec. train epoch 11, iter 590/1000, loss 0.036599, 0.20 batches/sec.[2K|############--------| 60.00%, 3028/2015 sec. train epoch 11, iter 600/1000, loss 0.035336, 0.20 batches/sec.[2K|############--------| 61.00%, 3078/1968 sec. train epoch 11, iter 610/1000, loss 0.033959, 0.20 batches/sec.[2K|############--------| 62.00%, 3128/1909 sec. train epoch 11, iter 620/1000, loss 0.036674, 0.20 batches/sec.[2K|#############-------| 63.00%, 3179/1868 sec. train epoch 11, iter 630/1000, loss 0.037418, 0.20 batches/sec.[2K|#############-------| 64.00%, 3229/1809 sec. train epoch 11, iter 640/1000, loss 0.036486, 0.20 batches/sec.[2K|#############-------| 65.00%, 3279/1764 sec. train epoch 11, iter 650/1000, loss 0.031920, 0.20 batches/sec.[2K|#############-------| 66.00%, 3330/1714 sec. train epoch 11, iter 660/1000, loss 0.033611, 0.20 batches/sec.[2K|#############-------| 67.00%, 3380/1661 sec. train epoch 11, iter 670/1000, loss 0.033814, 0.20 batches/sec.[2K|##############------| 68.00%, 3431/1613 sec. train epoch 11, iter 680/1000, loss 0.031140, 0.20 batches/sec.[2K|##############------| 69.00%, 3481/1557 sec. train epoch 11, iter 690/1000, loss 0.032308, 0.20 batches/sec.[2K|##############------| 70.00%, 3531/1509 sec. train epoch 11, iter 700/1000, loss 0.033665, 0.20 batches/sec.[2K|##############------| 71.00%, 3581/1459 sec. train epoch 11, iter 710/1000, loss 0.034418, 0.20 batches/sec.[2K|##############------| 72.00%, 3632/1408 sec. train epoch 11, iter 720/1000, loss 0.030919, 0.20 batches/sec.[2K|###############-----| 73.00%, 3682/1361 sec. train epoch 11, iter 730/1000, loss 0.032327, 0.20 batches/sec.[2K|###############-----| 74.00%, 3732/1306 sec. train epoch 11, iter 740/1000, loss 0.029298, 0.20 batches/sec.[2K|###############-----| 75.00%, 3783/1261 sec. train epoch 11, iter 750/1000, loss 0.030693, 0.20 batches/sec.[2K|###############-----| 76.00%, 3833/1208 sec. train epoch 11, iter 760/1000, loss 0.032815, 0.20 batches/sec.[2K|###############-----| 77.00%, 3883/1158 sec. train epoch 11, iter 770/1000, loss 0.032714, 0.20 batches/sec.[2K|################----| 78.00%, 3934/1110 sec. train epoch 11, iter 780/1000, loss 0.032387, 0.20 batches/sec.[2K|################----| 79.00%, 3984/1057 sec. train epoch 11, iter 790/1000, loss 0.032143, 0.20 batches/sec.[2K|################----| 80.00%, 4035/1010 sec. train epoch 11, iter 800/1000, loss 0.035814, 0.20 batches/sec.[2K|################----| 81.00%, 4085/955 sec. train epoch 11, iter 810/1000, loss 0.037872, 0.20 batches/sec.[2K|################----| 82.00%, 4135/906 sec. train epoch 11, iter 820/1000, loss 0.036171, 0.20 batches/sec.[2K|#################---| 83.00%, 4186/858 sec. train epoch 11, iter 830/1000, loss 0.034586, 0.20 batches/sec.[2K|#################---| 84.00%, 4236/806 sec. train epoch 11, iter 840/1000, loss 0.033198, 0.20 batches/sec.[2K|#################---| 85.00%, 4287/756 sec. train epoch 11, iter 850/1000, loss 0.031389, 0.20 batches/sec.[2K|#################---| 86.00%, 4337/705 sec. train epoch 11, iter 860/1000, loss 0.037973, 0.20 batches/sec.[2K|#################---| 87.00%, 4387/655 sec. train epoch 11, iter 870/1000, loss 0.035941, 0.20 batches/sec.[2K|##################--| 88.00%, 4438/605 sec. train epoch 11, iter 880/1000, loss 0.033148, 0.20 batches/sec.[2K|##################--| 89.00%, 4488/554 sec. train epoch 11, iter 890/1000, loss 0.030668, 0.20 batches/sec.[2K|##################--| 90.00%, 4539/505 sec. train epoch 11, iter 900/1000, loss 0.033260, 0.20 batches/sec.[2K|##################--| 91.00%, 4589/452 sec. train epoch 11, iter 910/1000, loss 0.034738, 0.20 batches/sec.[2K|##################--| 92.00%, 4639/403 sec. train epoch 11, iter 920/1000, loss 0.037031, 0.20 batches/sec.[2K|###################-| 93.00%, 4690/352 sec. train epoch 11, iter 930/1000, loss 0.041206, 0.20 batches/sec.[2K|###################-| 94.00%, 4740/302 sec. train epoch 11, iter 940/1000, loss 0.044016, 0.20 batches/sec.[2K|###################-| 95.00%, 4790/252 sec. train epoch 11, iter 950/1000, loss 0.047149, 0.20 batches/sec.[2K|###################-| 96.00%, 4841/201 sec. train epoch 11, iter 960/1000, loss 0.053077, 0.20 batches/sec.[2K|###################-| 97.00%, 4891/151 sec. train epoch 11, iter 970/1000, loss 0.051804, 0.20 batches/sec.[2K|####################| 98.00%, 4941/101 sec. train epoch 11, iter 980/1000, loss 0.051409, 0.20 batches/sec.[2K|####################| 99.00%, 4992/50 sec. train epoch 11, iter 990/1000, loss 0.052616, 0.20 batches/sec.[2K|--------------------| 1.00%, 55/5443 sec. train epoch 12, iter 10/1000, loss 0.230686, 0.21 batches/sec.[2K|--------------------| 2.00%, 105/4937 sec. train epoch 12, iter 20/1000, loss 0.112344, 0.20 batches/sec.[2K|#-------------------| 3.00%, 156/4879 sec. train epoch 12, iter 30/1000, loss 0.110848, 0.20 batches/sec.[2K|#-------------------| 4.00%, 206/4842 sec. train epoch 12, iter 40/1000, loss 0.109842, 0.20 batches/sec.[2K|#-------------------| 5.00%, 257/4789 sec. train epoch 12, iter 50/1000, loss 0.084987, 0.20 batches/sec.[2K|#-------------------| 6.00%, 307/4728 sec. train epoch 12, iter 60/1000, loss 0.116757, 0.20 batches/sec.[2K|#-------------------| 7.00%, 357/4676 sec. train epoch 12, iter 70/1000, loss 0.121129, 0.20 batches/sec.[2K|##------------------| 8.00%, 407/4631 sec. train epoch 12, iter 80/1000, loss 0.119894, 0.20 batches/sec.[2K|##------------------| 9.00%, 458/4586 sec. train epoch 12, iter 90/1000, loss 0.130870, 0.20 batches/sec.[2K|##------------------| 10.00%, 508/4535 sec. train epoch 12, iter 100/1000, loss 0.152263, 0.20 batches/sec.[2K|##------------------| 11.00%, 559/4479 sec. train epoch 12, iter 110/1000, loss 0.139095, 0.20 batches/sec.[2K|##------------------| 12.00%, 609/4437 sec. train epoch 12, iter 120/1000, loss 0.118049, 0.20 batches/sec.[2K|###-----------------| 13.00%, 659/4377 sec. train epoch 12, iter 130/1000, loss 0.106436, 0.20 batches/sec.[2K|###-----------------| 14.00%, 710/4336 sec. train epoch 12, iter 140/1000, loss 0.105430, 0.20 batches/sec.[2K|###-----------------| 15.00%, 760/4277 sec. train epoch 12, iter 150/1000, loss 0.087931, 0.20 batches/sec.[2K|###-----------------| 16.00%, 810/4220 sec. train epoch 12, iter 160/1000, loss 0.097728, 0.20 batches/sec.[2K|###-----------------| 17.00%, 861/4181 sec. train epoch 12, iter 170/1000, loss 0.101728, 0.20 batches/sec.[2K|####----------------| 18.00%, 911/4133 sec. train epoch 12, iter 180/1000, loss 0.102436, 0.20 batches/sec.[2K|####----------------| 19.00%, 961/4084 sec. train epoch 12, iter 190/1000, loss 0.087695, 0.20 batches/sec.[2K|####----------------| 20.00%, 1012/4022 sec. train epoch 12, iter 200/1000, loss 0.085382, 0.20 batches/sec.[2K|####----------------| 21.00%, 1062/3982 sec. train epoch 12, iter 210/1000, loss 0.086237, 0.20 batches/sec.[2K|####----------------| 22.00%, 1113/3933 sec. train epoch 12, iter 220/1000, loss 0.104724, 0.20 batches/sec.[2K|#####---------------| 23.00%, 1163/3873 sec. train epoch 12, iter 230/1000, loss 0.119862, 0.20 batches/sec.[2K|#####---------------| 24.00%, 1213/3830 sec. train epoch 12, iter 240/1000, loss 0.108380, 0.20 batches/sec.[2K|#####---------------| 25.00%, 1264/3782 sec. train epoch 12, iter 250/1000, loss 0.103806, 0.20 batches/sec.[2K|#####---------------| 26.00%, 1314/3730 sec. train epoch 12, iter 260/1000, loss 0.099785, 0.20 batches/sec.[2K|#####---------------| 27.00%, 1364/3679 sec. train epoch 12, iter 270/1000, loss 0.097031, 0.20 batches/sec.[2K|######--------------| 28.00%, 1415/3621 sec. train epoch 12, iter 280/1000, loss 0.092703, 0.20 batches/sec.[2K|######--------------| 29.00%, 1465/3581 sec. train epoch 12, iter 290/1000, loss 0.089900, 0.20 batches/sec.[2K|######--------------| 30.00%, 1516/3523 sec. train epoch 12, iter 300/1000, loss 0.088598, 0.20 batches/sec.[2K|######--------------| 31.00%, 1566/3478 sec. train epoch 12, iter 310/1000, loss 0.082682, 0.20 batches/sec.[2K|######--------------| 32.00%, 1616/3423 sec. train epoch 12, iter 320/1000, loss 0.081488, 0.20 batches/sec.[2K|#######-------------| 33.00%, 1667/3375 sec. train epoch 12, iter 330/1000, loss 0.070337, 0.20 batches/sec.[2K|#######-------------| 34.00%, 1717/3328 sec. train epoch 12, iter 340/1000, loss 0.066886, 0.20 batches/sec.[2K|#######-------------| 35.00%, 1767/3270 sec. train epoch 12, iter 350/1000, loss 0.075304, 0.20 batches/sec.[2K|#######-------------| 36.00%, 1818/3227 sec. train epoch 12, iter 360/1000, loss 0.066171, 0.20 batches/sec.[2K|#######-------------| 37.00%, 1868/3169 sec. train epoch 12, iter 370/1000, loss 0.069335, 0.20 batches/sec.[2K|########------------| 38.00%, 1918/3123 sec. train epoch 12, iter 380/1000, loss 0.067638, 0.20 batches/sec.[2K|########------------| 39.00%, 1969/3071 sec. train epoch 12, iter 390/1000, loss 0.067782, 0.20 batches/sec.[2K|########------------| 40.00%, 2019/3012 sec. train epoch 12, iter 400/1000, loss 0.062954, 0.20 batches/sec.[2K|########------------| 41.00%, 2069/2977 sec. train epoch 12, iter 410/1000, loss 0.072408, 0.20 batches/sec.[2K|########------------| 42.00%, 2120/2919 sec. train epoch 12, iter 420/1000, loss 0.079971, 0.20 batches/sec.[2K|#########-----------| 43.00%, 2170/2870 sec. train epoch 12, iter 430/1000, loss 0.077831, 0.20 batches/sec.[2K|#########-----------| 44.00%, 2220/2817 sec. train epoch 12, iter 440/1000, loss 0.078703, 0.20 batches/sec.[2K|#########-----------| 45.00%, 2271/2768 sec. train epoch 12, iter 450/1000, loss 0.074469, 0.20 batches/sec.[2K|#########-----------| 46.00%, 2321/2725 sec. train epoch 12, iter 460/1000, loss 0.071989, 0.20 batches/sec.[2K|#########-----------| 47.00%, 2372/2664 sec. train epoch 12, iter 470/1000, loss 0.074340, 0.20 batches/sec.[2K|##########----------| 48.00%, 2422/2618 sec. train epoch 12, iter 480/1000, loss 0.068554, 0.20 batches/sec.[2K|##########----------| 49.00%, 2472/2567 sec. train epoch 12, iter 490/1000, loss 0.064111, 0.20 batches/sec.[2K|##########----------| 50.00%, 2523/2520 sec. train epoch 12, iter 500/1000, loss 0.063163, 0.20 batches/sec.[2K|##########----------| 51.00%, 2573/2467 sec. train epoch 12, iter 510/1000, loss 0.064824, 0.20 batches/sec.[2K|##########----------| 52.00%, 2623/2415 sec. train epoch 12, iter 520/1000, loss 0.068121, 0.20 batches/sec.[2K|###########---------| 53.00%, 2674/2364 sec. train epoch 12, iter 530/1000, loss 0.072064, 0.20 batches/sec.[2K|###########---------| 54.00%, 2724/2312 sec. train epoch 12, iter 540/1000, loss 0.066500, 0.20 batches/sec.[2K|###########---------| 55.00%, 2774/2264 sec. train epoch 12, iter 550/1000, loss 0.055673, 0.20 batches/sec.[2K|###########---------| 56.00%, 2825/2219 sec. train epoch 12, iter 560/1000, loss 0.058861, 0.20 batches/sec.[2K|###########---------| 57.00%, 2875/2163 sec. train epoch 12, iter 570/1000, loss 0.063950, 0.20 batches/sec.[2K|############--------| 58.00%, 2925/2115 sec. train epoch 12, iter 580/1000, loss 0.063208, 0.20 batches/sec.[2K|############--------| 59.00%, 2976/2063 sec. train epoch 12, iter 590/1000, loss 0.068930, 0.20 batches/sec.[2K|############--------| 60.00%, 3026/2014 sec. train epoch 12, iter 600/1000, loss 0.070829, 0.20 batches/sec.[2K|############--------| 61.00%, 3076/1967 sec. train epoch 12, iter 610/1000, loss 0.071772, 0.20 batches/sec.[2K|############--------| 62.00%, 3127/1914 sec. train epoch 12, iter 620/1000, loss 0.072444, 0.20 batches/sec.[2K|#############-------| 63.00%, 3177/1865 sec. train epoch 12, iter 630/1000, loss 0.071962, 0.20 batches/sec.[2K|#############-------| 64.00%, 3227/1813 sec. train epoch 12, iter 640/1000, loss 0.064069, 0.20 batches/sec.[2K|#############-------| 65.00%, 3278/1763 sec. train epoch 12, iter 650/1000, loss 0.061463, 0.20 batches/sec.[2K|#############-------| 66.00%, 3328/1713 sec. train epoch 12, iter 660/1000, loss 0.062177, 0.20 batches/sec.[2K|#############-------| 67.00%, 3379/1660 sec. train epoch 12, iter 670/1000, loss 0.064856, 0.20 batches/sec.[2K|##############------| 68.00%, 3429/1610 sec. train epoch 12, iter 680/1000, loss 0.065307, 0.20 batches/sec.[2K|##############------| 69.00%, 3479/1560 sec. train epoch 12, iter 690/1000, loss 0.066384, 0.20 batches/sec.[2K|##############------| 70.00%, 3530/1511 sec. train epoch 12, iter 700/1000, loss 0.067767, 0.20 batches/sec.[2K|##############------| 71.00%, 3580/1460 sec. train epoch 12, iter 710/1000, loss 0.068654, 0.20 batches/sec.[2K|##############------| 72.00%, 3630/1410 sec. train epoch 12, iter 720/1000, loss 0.066990, 0.20 batches/sec.[2K|###############-----| 73.00%, 3681/1362 sec. train epoch 12, iter 730/1000, loss 0.064348, 0.20 batches/sec.[2K|###############-----| 74.00%, 3731/1309 sec. train epoch 12, iter 740/1000, loss 0.061942, 0.20 batches/sec.[2K|###############-----| 75.00%, 3782/1262 sec. train epoch 12, iter 750/1000, loss 0.062238, 0.20 batches/sec.[2K|###############-----| 76.00%, 3832/1209 sec. train epoch 12, iter 760/1000, loss 0.063157, 0.20 batches/sec.[2K|###############-----| 77.00%, 3882/1160 sec. train epoch 12, iter 770/1000, loss 0.066063, 0.20 batches/sec.[2K|################----| 78.00%, 3933/1108 sec. train epoch 12, iter 780/1000, loss 0.061831, 0.20 batches/sec.[2K|################----| 79.00%, 3983/1058 sec. train epoch 12, iter 790/1000, loss 0.053850, 0.20 batches/sec.[2K|################----| 80.00%, 4033/1008 sec. train epoch 12, iter 800/1000, loss 0.055709, 0.20 batches/sec.[2K|################----| 81.00%, 4084/955 sec. train epoch 12, iter 810/1000, loss 0.056182, 0.20 batches/sec.[2K|################----| 82.00%, 4134/906 sec. train epoch 12, iter 820/1000, loss 0.053025, 0.20 batches/sec.[32m[2019-03-18 04:03:32 @logger.py:146][0m [2K|####################| 100.00%, 5041/0 sec. train epoch 12, iter 1000/1000, loss 0.053597, 0.20 batches/sec.
[32m[2019-03-18 04:03:36 @logger.py:43][0m [32;1mTrigger callback: [0mTrigger ModelSaver: Save model to model_logs/20190317111349169013_10-255-0-254_mine_NORMAL_wgan_gp_full_model_celeba_hq_256/snap-12000.
[2K|#################---| 83.00%, 4184/855 sec. train epoch 12, iter 830/1000, loss 0.056604, 0.20 batches/sec.[2K|#################---| 84.00%, 4235/805 sec. train epoch 12, iter 840/1000, loss 0.056146, 0.20 batches/sec.[2K|#################---| 85.00%, 4285/756 sec. train epoch 12, iter 850/1000, loss 0.055408, 0.20 batches/sec.[2K|#################---| 86.00%, 4335/705 sec. train epoch 12, iter 860/1000, loss 0.053787, 0.20 batches/sec.[2K|#################---| 87.00%, 4386/655 sec. train epoch 12, iter 870/1000, loss 0.056296, 0.20 batches/sec.[2K|##################--| 88.00%, 4436/604 sec. train epoch 12, iter 880/1000, loss 0.058015, 0.20 batches/sec.[2K|##################--| 89.00%, 4487/554 sec. train epoch 12, iter 890/1000, loss 0.054442, 0.20 batches/sec.[2K|##################--| 90.00%, 4537/504 sec. train epoch 12, iter 900/1000, loss 0.055817, 0.20 batches/sec.[2K|##################--| 91.00%, 4587/453 sec. train epoch 12, iter 910/1000, loss 0.055238, 0.20 batches/sec.[2K|##################--| 92.00%, 4638/404 sec. train epoch 12, iter 920/1000, loss 0.055536, 0.20 batches/sec.[2K|###################-| 93.00%, 4688/353 sec. train epoch 12, iter 930/1000, loss 0.056535, 0.20 batches/sec.[2K|###################-| 94.00%, 4739/303 sec. train epoch 12, iter 940/1000, loss 0.054678, 0.20 batches/sec.[2K|###################-| 95.00%, 4789/252 sec. train epoch 12, iter 950/1000, loss 0.054746, 0.20 batches/sec.[2K|###################-| 96.00%, 4840/201 sec. train epoch 12, iter 960/1000, loss 0.056131, 0.20 batches/sec.[2K|###################-| 97.00%, 4890/151 sec. train epoch 12, iter 970/1000, loss 0.055193, 0.20 batches/sec.[2K|####################| 98.00%, 4940/101 sec. train epoch 12, iter 980/1000, loss 0.052107, 0.20 batches/sec.[2K|####################| 99.00%, 4991/50 sec. train epoch 12, iter 990/1000, loss 0.053824, 0.20 batches/sec.[2K|--------------------| 1.00%, 55/5446 sec. train epoch 13, iter 10/1000, loss 0.106678, 0.21 batches/sec.[2K|--------------------| 2.00%, 105/4947 sec. train epoch 13, iter 20/1000, loss -0.008524, 0.20 batches/sec.[2K|#-------------------| 3.00%, 156/4881 sec. train epoch 13, iter 30/1000, loss -0.070351, 0.20 batches/sec.[2K|#-------------------| 4.00%, 206/4841 sec. train epoch 13, iter 40/1000, loss -0.040650, 0.20 batches/sec.[2K|#-------------------| 5.00%, 257/4781 sec. train epoch 13, iter 50/1000, loss -0.085992, 0.20 batches/sec.[2K|#-------------------| 6.00%, 307/4736 sec. train epoch 13, iter 60/1000, loss -0.097977, 0.20 batches/sec.[2K|#-------------------| 7.00%, 357/4683 sec. train epoch 13, iter 70/1000, loss -0.096857, 0.20 batches/sec.[2K|##------------------| 8.00%, 408/4630 sec. train epoch 13, iter 80/1000, loss -0.131722, 0.20 batches/sec.[2K|##------------------| 9.00%, 458/4591 sec. train epoch 13, iter 90/1000, loss -0.120332, 0.20 batches/sec.[2K|##------------------| 10.00%, 508/4525 sec. train epoch 13, iter 100/1000, loss -0.153746, 0.20 batches/sec.[2K|##------------------| 11.00%, 559/4484 sec. train epoch 13, iter 110/1000, loss -0.171659, 0.20 batches/sec.[2K|##------------------| 12.00%, 609/4433 sec. train epoch 13, iter 120/1000, loss -0.188247, 0.20 batches/sec.[2K|###-----------------| 13.00%, 659/4376 sec. train epoch 13, iter 130/1000, loss -0.166896, 0.20 batches/sec.[2K|###-----------------| 14.00%, 710/4344 sec. train epoch 13, iter 140/1000, loss -0.150330, 0.20 batches/sec.[2K|###-----------------| 15.00%, 760/4275 sec. train epoch 13, iter 150/1000, loss -0.144724, 0.20 batches/sec.[2K|###-----------------| 16.00%, 810/4220 sec. train epoch 13, iter 160/1000, loss -0.142561, 0.20 batches/sec.[2K|###-----------------| 17.00%, 861/4187 sec. train epoch 13, iter 170/1000, loss -0.141728, 0.20 batches/sec.[2K|####----------------| 18.00%, 911/4125 sec. train epoch 13, iter 180/1000, loss -0.111658, 0.20 batches/sec.[2K|####----------------| 19.00%, 962/4083 sec. train epoch 13, iter 190/1000, loss -0.111266, 0.20 batches/sec.[2K|####----------------| 20.00%, 1012/4021 sec. train epoch 13, iter 200/1000, loss -0.098162, 0.20 batches/sec.[2K|####----------------| 21.00%, 1062/3985 sec. train epoch 13, iter 210/1000, loss -0.093423, 0.20 batches/sec.[2K|####----------------| 22.00%, 1113/3925 sec. train epoch 13, iter 220/1000, loss -0.084007, 0.20 batches/sec.[2K|#####---------------| 23.00%, 1163/3879 sec. train epoch 13, iter 230/1000, loss -0.083719, 0.20 batches/sec.[2K|#####---------------| 24.00%, 1213/3828 sec. train epoch 13, iter 240/1000, loss -0.065170, 0.20 batches/sec.[2K|#####---------------| 25.00%, 1264/3772 sec. train epoch 13, iter 250/1000, loss -0.071087, 0.20 batches/sec.[2K|#####---------------| 26.00%, 1314/3734 sec. train epoch 13, iter 260/1000, loss -0.069632, 0.20 batches/sec.[2K|#####---------------| 27.00%, 1364/3672 sec. train epoch 13, iter 270/1000, loss -0.065287, 0.20 batches/sec.[2K|######--------------| 28.00%, 1415/3630 sec. train epoch 13, iter 280/1000, loss -0.047208, 0.20 batches/sec.[2K|######--------------| 29.00%, 1465/3572 sec. train epoch 13, iter 290/1000, loss -0.020930, 0.20 batches/sec.[2K|######--------------| 30.00%, 1516/3526 sec. train epoch 13, iter 300/1000, loss -0.014266, 0.20 batches/sec.[2K|######--------------| 31.00%, 1566/3477 sec. train epoch 13, iter 310/1000, loss -0.006817, 0.20 batches/sec.[2K|######--------------| 32.00%, 1616/3422 sec. train epoch 13, iter 320/1000, loss -0.009155, 0.20 batches/sec.[2K|#######-------------| 33.00%, 1667/3378 sec. train epoch 13, iter 330/1000, loss 0.004673, 0.20 batches/sec.[2K|#######-------------| 34.00%, 1717/3322 sec. train epoch 13, iter 340/1000, loss -0.008305, 0.20 batches/sec.[2K|#######-------------| 35.00%, 1767/3278 sec. train epoch 13, iter 350/1000, loss -0.015471, 0.20 batches/sec.[2K|#######-------------| 36.00%, 1818/3225 sec. train epoch 13, iter 360/1000, loss -0.015888, 0.20 batches/sec.[2K|#######-------------| 37.00%, 1868/3173 sec. train epoch 13, iter 370/1000, loss -0.010419, 0.20 batches/sec.[2K|########------------| 38.00%, 1919/3128 sec. train epoch 13, iter 380/1000, loss 0.001786, 0.20 batches/sec.[2K|########------------| 39.00%, 1969/3067 sec. train epoch 13, iter 390/1000, loss 0.011320, 0.20 batches/sec.[2K|########------------| 40.00%, 2019/3026 sec. train epoch 13, iter 400/1000, loss 0.018232, 0.20 batches/sec.[2K|########------------| 41.00%, 2070/2969 sec. train epoch 13, iter 410/1000, loss 0.013276, 0.20 batches/sec.[2K|########------------| 42.00%, 2120/2918 sec. train epoch 13, iter 420/1000, loss 0.020050, 0.20 batches/sec.[2K|#########-----------| 43.00%, 2170/2877 sec. train epoch 13, iter 430/1000, loss 0.026321, 0.20 batches/sec.[2K|#########-----------| 44.00%, 2221/2814 sec. train epoch 13, iter 440/1000, loss 0.022812, 0.20 batches/sec.[2K|#########-----------| 45.00%, 2271/2779 sec. train epoch 13, iter 450/1000, loss 0.040229, 0.20 batches/sec.[2K|#########-----------| 46.00%, 2322/2717 sec. train epoch 13, iter 460/1000, loss 0.047506, 0.20 batches/sec.[2K|#########-----------| 47.00%, 2372/2667 sec. train epoch 13, iter 470/1000, loss 0.051793, 0.20 batches/sec.[2K|##########----------| 48.00%, 2422/2619 sec. train epoch 13, iter 480/1000, loss 0.058268, 0.20 batches/sec.[2K|##########----------| 49.00%, 2473/2567 sec. train epoch 13, iter 490/1000, loss 0.059698, 0.20 batches/sec.[2K|##########----------| 50.00%, 2523/2527 sec. train epoch 13, iter 500/1000, loss 0.060557, 0.20 batches/sec.[2K|##########----------| 51.00%, 2573/2468 sec. train epoch 13, iter 510/1000, loss 0.065024, 0.20 batches/sec.[2K|##########----------| 52.00%, 2624/2421 sec. train epoch 13, iter 520/1000, loss 0.072149, 0.20 batches/sec.[2K|###########---------| 53.00%, 2674/2365 sec. train epoch 13, iter 530/1000, loss 0.076843, 0.20 batches/sec.[2K|###########---------| 54.00%, 2725/2315 sec. train epoch 13, iter 540/1000, loss 0.080000, 0.20 batches/sec.[2K|###########---------| 55.00%, 2775/2270 sec. train epoch 13, iter 550/1000, loss 0.080093, 0.20 batches/sec.[2K|###########---------| 56.00%, 2825/2212 sec. train epoch 13, iter 560/1000, loss 0.082083, 0.20 batches/sec.[32m[2019-03-18 05:27:34 @logger.py:146][0m [2K|####################| 100.00%, 5041/0 sec. train epoch 13, iter 1000/1000, loss 0.090647, 0.20 batches/sec.
[32m[2019-03-18 05:27:38 @logger.py:43][0m [32;1mTrigger callback: [0mTrigger ModelSaver: Save model to model_logs/20190317111349169013_10-255-0-254_mine_NORMAL_wgan_gp_full_model_celeba_hq_256/snap-13000.
[2K|###########---------| 57.00%, 2876/2170 sec. train epoch 13, iter 570/1000, loss 0.088162, 0.20 batches/sec.[2K|############--------| 58.00%, 2926/2116 sec. train epoch 13, iter 580/1000, loss 0.085723, 0.20 batches/sec.[2K|############--------| 59.00%, 2976/2064 sec. train epoch 13, iter 590/1000, loss 0.082802, 0.20 batches/sec.[2K|############--------| 60.00%, 3027/2010 sec. train epoch 13, iter 600/1000, loss 0.082766, 0.20 batches/sec.[2K|############--------| 61.00%, 3077/1962 sec. train epoch 13, iter 610/1000, loss 0.082564, 0.20 batches/sec.[2K|############--------| 62.00%, 3127/1916 sec. train epoch 13, iter 620/1000, loss 0.090286, 0.20 batches/sec.[2K|#############-------| 63.00%, 3178/1859 sec. train epoch 13, iter 630/1000, loss 0.089880, 0.20 batches/sec.[2K|#############-------| 64.00%, 3228/1810 sec. train epoch 13, iter 640/1000, loss 0.091870, 0.20 batches/sec.[2K|#############-------| 65.00%, 3278/1764 sec. train epoch 13, iter 650/1000, loss 0.092253, 0.20 batches/sec.[2K|#############-------| 66.00%, 3329/1712 sec. train epoch 13, iter 660/1000, loss 0.091872, 0.20 batches/sec.[2K|#############-------| 67.00%, 3379/1660 sec. train epoch 13, iter 670/1000, loss 0.091180, 0.20 batches/sec.[2K|##############------| 68.00%, 3429/1608 sec. train epoch 13, iter 680/1000, loss 0.095534, 0.20 batches/sec.[2K|##############------| 69.00%, 3480/1561 sec. train epoch 13, iter 690/1000, loss 0.096736, 0.20 batches/sec.[2K|##############------| 70.00%, 3530/1512 sec. train epoch 13, iter 700/1000, loss 0.093617, 0.20 batches/sec.[2K|##############------| 71.00%, 3580/1461 sec. train epoch 13, iter 710/1000, loss 0.091890, 0.20 batches/sec.[2K|##############------| 72.00%, 3631/1409 sec. train epoch 13, iter 720/1000, loss 0.092521, 0.20 batches/sec.[2K|###############-----| 73.00%, 3681/1359 sec. train epoch 13, iter 730/1000, loss 0.092173, 0.20 batches/sec.[2K|###############-----| 74.00%, 3731/1310 sec. train epoch 13, iter 740/1000, loss 0.090337, 0.20 batches/sec.[2K|###############-----| 75.00%, 3782/1260 sec. train epoch 13, iter 750/1000, loss 0.090781, 0.20 batches/sec.[2K|###############-----| 76.00%, 3832/1206 sec. train epoch 13, iter 760/1000, loss 0.093959, 0.20 batches/sec.[2K|###############-----| 77.00%, 3883/1161 sec. train epoch 13, iter 770/1000, loss 0.091299, 0.20 batches/sec.[2K|################----| 78.00%, 3933/1107 sec. train epoch 13, iter 780/1000, loss 0.086839, 0.20 batches/sec.[2K|################----| 79.00%, 3983/1059 sec. train epoch 13, iter 790/1000, loss 0.087532, 0.20 batches/sec.[2K|################----| 80.00%, 4034/1008 sec. train epoch 13, iter 800/1000, loss 0.088705, 0.20 batches/sec.[2K|################----| 81.00%, 4084/957 sec. train epoch 13, iter 810/1000, loss 0.090210, 0.20 batches/sec.[2K|################----| 82.00%, 4135/907 sec. train epoch 13, iter 820/1000, loss 0.087615, 0.20 batches/sec.[2K|#################---| 83.00%, 4185/855 sec. train epoch 13, iter 830/1000, loss 0.087023, 0.20 batches/sec.[2K|#################---| 84.00%, 4235/808 sec. train epoch 13, iter 840/1000, loss 0.085507, 0.20 batches/sec.[2K|#################---| 85.00%, 4286/756 sec. train epoch 13, iter 850/1000, loss 0.087791, 0.20 batches/sec.[2K|#################---| 86.00%, 4336/707 sec. train epoch 13, iter 860/1000, loss 0.088981, 0.20 batches/sec.[2K|#################---| 87.00%, 4387/655 sec. train epoch 13, iter 870/1000, loss 0.087676, 0.20 batches/sec.[2K|##################--| 88.00%, 4437/605 sec. train epoch 13, iter 880/1000, loss 0.085638, 0.20 batches/sec.[2K|##################--| 89.00%, 4487/555 sec. train epoch 13, iter 890/1000, loss 0.083722, 0.20 batches/sec.[2K|##################--| 90.00%, 4538/503 sec. train epoch 13, iter 900/1000, loss 0.084307, 0.20 batches/sec.[2K|##################--| 91.00%, 4588/454 sec. train epoch 13, iter 910/1000, loss 0.082999, 0.20 batches/sec.[2K|##################--| 92.00%, 4639/403 sec. train epoch 13, iter 920/1000, loss 0.087225, 0.20 batches/sec.[2K|###################-| 93.00%, 4689/352 sec. train epoch 13, iter 930/1000, loss 0.086997, 0.20 batches/sec.[2K|###################-| 94.00%, 4739/303 sec. train epoch 13, iter 940/1000, loss 0.082582, 0.20 batches/sec.[2K|###################-| 95.00%, 4790/251 sec. train epoch 13, iter 950/1000, loss 0.082325, 0.20 batches/sec.[2K|###################-| 96.00%, 4840/202 sec. train epoch 13, iter 960/1000, loss 0.081530, 0.20 batches/sec.[2K|###################-| 97.00%, 4890/151 sec. train epoch 13, iter 970/1000, loss 0.085182, 0.20 batches/sec.[2K|####################| 98.00%, 4941/101 sec. train epoch 13, iter 980/1000, loss 0.087842, 0.20 batches/sec.[2K|####################| 99.00%, 4991/50 sec. train epoch 13, iter 990/1000, loss 0.089614, 0.20 batches/sec.[2K|--------------------| 1.00%, 55/5456 sec. train epoch 14, iter 10/1000, loss 0.038695, 0.21 batches/sec.[2K|--------------------| 2.00%, 105/4927 sec. train epoch 14, iter 20/1000, loss 0.085902, 0.20 batches/sec.[2K|#-------------------| 3.00%, 156/4875 sec. train epoch 14, iter 30/1000, loss 0.032341, 0.20 batches/sec.[2K|#-------------------| 4.00%, 206/4834 sec. train epoch 14, iter 40/1000, loss 0.029593, 0.20 batches/sec.[2K|#-------------------| 5.00%, 256/4783 sec. train epoch 14, iter 50/1000, loss 0.061736, 0.20 batches/sec.[2K|#-------------------| 6.00%, 307/4733 sec. train epoch 14, iter 60/1000, loss 0.064581, 0.20 batches/sec.[2K|#-------------------| 7.00%, 357/4681 sec. train epoch 14, iter 70/1000, loss 0.070747, 0.20 batches/sec.[2K|##------------------| 8.00%, 407/4632 sec. train epoch 14, iter 80/1000, loss 0.088933, 0.20 batches/sec.[2K|##------------------| 9.00%, 458/4581 sec. train epoch 14, iter 90/1000, loss 0.073308, 0.20 batches/sec.[2K|##------------------| 10.00%, 508/4526 sec. train epoch 14, iter 100/1000, loss 0.080084, 0.20 batches/sec.[2K|##------------------| 11.00%, 558/4481 sec. train epoch 14, iter 110/1000, loss 0.092688, 0.20 batches/sec.[2K|##------------------| 12.00%, 609/4430 sec. train epoch 14, iter 120/1000, loss 0.079153, 0.20 batches/sec.[2K|###-----------------| 13.00%, 659/4388 sec. train epoch 14, iter 130/1000, loss 0.071774, 0.20 batches/sec.[2K|###-----------------| 14.00%, 709/4329 sec. train epoch 14, iter 140/1000, loss 0.059919, 0.20 batches/sec.[2K|###-----------------| 15.00%, 760/4280 sec. train epoch 14, iter 150/1000, loss 0.066816, 0.20 batches/sec.[2K|###-----------------| 16.00%, 810/4231 sec. train epoch 14, iter 160/1000, loss 0.060024, 0.20 batches/sec.[2K|###-----------------| 17.00%, 860/4173 sec. train epoch 14, iter 170/1000, loss 0.044149, 0.20 batches/sec.[2K|####----------------| 18.00%, 911/4135 sec. train epoch 14, iter 180/1000, loss 0.045700, 0.20 batches/sec.[2K|####----------------| 19.00%, 961/4074 sec. train epoch 14, iter 190/1000, loss 0.030480, 0.20 batches/sec.[2K|####----------------| 20.00%, 1012/4029 sec. train epoch 14, iter 200/1000, loss 0.033682, 0.20 batches/sec.[2K|####----------------| 21.00%, 1062/3978 sec. train epoch 14, iter 210/1000, loss 0.055004, 0.20 batches/sec.[2K|####----------------| 22.00%, 1112/3922 sec. train epoch 14, iter 220/1000, loss 0.054066, 0.20 batches/sec.[2K|#####---------------| 23.00%, 1163/3876 sec. train epoch 14, iter 230/1000, loss 0.055042, 0.20 batches/sec.[2K|#####---------------| 24.00%, 1213/3825 sec. train epoch 14, iter 240/1000, loss 0.044038, 0.20 batches/sec.[2K|#####---------------| 25.00%, 1263/3779 sec. train epoch 14, iter 250/1000, loss 0.045029, 0.20 batches/sec.[2K|#####---------------| 26.00%, 1314/3721 sec. train epoch 14, iter 260/1000, loss 0.051935, 0.20 batches/sec.[2K|#####---------------| 27.00%, 1364/3671 sec. train epoch 14, iter 270/1000, loss 0.046334, 0.20 batches/sec.[2K|######--------------| 28.00%, 1414/3627 sec. train epoch 14, iter 280/1000, loss 0.037494, 0.20 batches/sec.[2K|######--------------| 29.00%, 1465/3573 sec. train epoch 14, iter 290/1000, loss 0.032370, 0.20 batches/sec.[2K|######--------------| 30.00%, 1515/3528 sec. train epoch 14, iter 300/1000, loss 0.030147, 0.20 batches/sec.[32m[2019-03-18 06:51:35 @logger.py:146][0m [2K|####################| 100.00%, 5041/0 sec. train epoch 14, iter 1000/1000, loss 0.081584, 0.20 batches/sec.
[32m[2019-03-18 06:51:39 @logger.py:43][0m [32;1mTrigger callback: [0mTrigger ModelSaver: Save model to model_logs/20190317111349169013_10-255-0-254_mine_NORMAL_wgan_gp_full_model_celeba_hq_256/snap-14000.
[2K|######--------------| 31.00%, 1565/3475 sec. train epoch 14, iter 310/1000, loss 0.034093, 0.20 batches/sec.[2K|######--------------| 32.00%, 1616/3423 sec. train epoch 14, iter 320/1000, loss 0.029247, 0.20 batches/sec.[2K|#######-------------| 33.00%, 1666/3376 sec. train epoch 14, iter 330/1000, loss 0.025501, 0.20 batches/sec.[2K|#######-------------| 34.00%, 1716/3318 sec. train epoch 14, iter 340/1000, loss 0.023968, 0.20 batches/sec.[2K|#######-------------| 35.00%, 1767/3278 sec. train epoch 14, iter 350/1000, loss 0.028963, 0.20 batches/sec.[2K|#######-------------| 36.00%, 1817/3219 sec. train epoch 14, iter 360/1000, loss 0.026446, 0.20 batches/sec.[2K|#######-------------| 37.00%, 1867/3174 sec. train epoch 14, iter 370/1000, loss 0.026190, 0.20 batches/sec.[2K|########------------| 38.00%, 1918/3128 sec. train epoch 14, iter 380/1000, loss 0.028219, 0.20 batches/sec.[2K|########------------| 39.00%, 1968/3070 sec. train epoch 14, iter 390/1000, loss 0.026907, 0.20 batches/sec.[2K|########------------| 40.00%, 2019/3029 sec. train epoch 14, iter 400/1000, loss 0.039140, 0.20 batches/sec.[2K|########------------| 41.00%, 2069/2974 sec. train epoch 14, iter 410/1000, loss 0.048840, 0.20 batches/sec.[2K|########------------| 42.00%, 2119/2925 sec. train epoch 14, iter 420/1000, loss 0.047880, 0.20 batches/sec.[2K|#########-----------| 43.00%, 2170/2876 sec. train epoch 14, iter 430/1000, loss 0.050140, 0.20 batches/sec.[2K|#########-----------| 44.00%, 2220/2816 sec. train epoch 14, iter 440/1000, loss 0.053215, 0.20 batches/sec.[2K|#########-----------| 45.00%, 2271/2774 sec. train epoch 14, iter 450/1000, loss 0.052746, 0.20 batches/sec.[2K|#########-----------| 46.00%, 2321/2714 sec. train epoch 14, iter 460/1000, loss 0.053013, 0.20 batches/sec.[2K|#########-----------| 47.00%, 2371/2673 sec. train epoch 14, iter 470/1000, loss 0.060758, 0.20 batches/sec.[2K|##########----------| 48.00%, 2422/2615 sec. train epoch 14, iter 480/1000, loss 0.060910, 0.20 batches/sec.[2K|##########----------| 49.00%, 2472/2562 sec. train epoch 14, iter 490/1000, loss 0.053976, 0.20 batches/sec.[2K|##########----------| 50.00%, 2522/2522 sec. train epoch 14, iter 500/1000, loss 0.056151, 0.20 batches/sec.[2K|##########----------| 51.00%, 2573/2463 sec. train epoch 14, iter 510/1000, loss 0.053849, 0.20 batches/sec.[2K|##########----------| 52.00%, 2623/2426 sec. train epoch 14, iter 520/1000, loss 0.055692, 0.20 batches/sec.[2K|###########---------| 53.00%, 2673/2369 sec. train epoch 14, iter 530/1000, loss 0.054639, 0.20 batches/sec.[2K|###########---------| 54.00%, 2724/2316 sec. train epoch 14, iter 540/1000, loss 0.057145, 0.20 batches/sec.[2K|###########---------| 55.00%, 2774/2264 sec. train epoch 14, iter 550/1000, loss 0.057579, 0.20 batches/sec.[2K|###########---------| 56.00%, 2825/2216 sec. train epoch 14, iter 560/1000, loss 0.065305, 0.20 batches/sec.[2K|###########---------| 57.00%, 2875/2164 sec. train epoch 14, iter 570/1000, loss 0.073198, 0.20 batches/sec.[2K|############--------| 58.00%, 2925/2115 sec. train epoch 14, iter 580/1000, loss 0.068950, 0.20 batches/sec.[2K|############--------| 59.00%, 2976/2065 sec. train epoch 14, iter 590/1000, loss 0.070259, 0.20 batches/sec.[2K|############--------| 60.00%, 3026/2011 sec. train epoch 14, iter 600/1000, loss 0.071948, 0.20 batches/sec.[2K|############--------| 61.00%, 3076/1965 sec. train epoch 14, iter 610/1000, loss 0.071345, 0.20 batches/sec.[2K|############--------| 62.00%, 3127/1911 sec. train epoch 14, iter 620/1000, loss 0.074114, 0.20 batches/sec.[2K|#############-------| 63.00%, 3177/1860 sec. train epoch 14, iter 630/1000, loss 0.077630, 0.20 batches/sec.[2K|#############-------| 64.00%, 3227/1815 sec. train epoch 14, iter 640/1000, loss 0.083632, 0.20 batches/sec.[2K|#############-------| 65.00%, 3278/1762 sec. train epoch 14, iter 650/1000, loss 0.085155, 0.20 batches/sec.[2K|#############-------| 66.00%, 3328/1713 sec. train epoch 14, iter 660/1000, loss 0.083857, 0.20 batches/sec.[2K|#############-------| 67.00%, 3378/1662 sec. train epoch 14, iter 670/1000, loss 0.083855, 0.20 batches/sec.[2K|##############------| 68.00%, 3429/1610 sec. train epoch 14, iter 680/1000, loss 0.083496, 0.20 batches/sec.[2K|##############------| 69.00%, 3479/1563 sec. train epoch 14, iter 690/1000, loss 0.080461, 0.20 batches/sec.[2K|##############------| 70.00%, 3529/1510 sec. train epoch 14, iter 700/1000, loss 0.081358, 0.20 batches/sec.[2K|##############------| 71.00%, 3580/1461 sec. train epoch 14, iter 710/1000, loss 0.083317, 0.20 batches/sec.[2K|##############------| 72.00%, 3630/1411 sec. train epoch 14, iter 720/1000, loss 0.080799, 0.20 batches/sec.[2K|###############-----| 73.00%, 3680/1359 sec. train epoch 14, iter 730/1000, loss 0.079049, 0.20 batches/sec.[2K|###############-----| 74.00%, 3731/1311 sec. train epoch 14, iter 740/1000, loss 0.078760, 0.20 batches/sec.[2K|###############-----| 75.00%, 3781/1256 sec. train epoch 14, iter 750/1000, loss 0.076169, 0.20 batches/sec.[2K|###############-----| 76.00%, 3832/1210 sec. train epoch 14, iter 760/1000, loss 0.075994, 0.20 batches/sec.[2K|###############-----| 77.00%, 3882/1160 sec. train epoch 14, iter 770/1000, loss 0.077126, 0.20 batches/sec.[2K|################----| 78.00%, 3932/1109 sec. train epoch 14, iter 780/1000, loss 0.074474, 0.20 batches/sec.[2K|################----| 79.00%, 3983/1060 sec. train epoch 14, iter 790/1000, loss 0.073573, 0.20 batches/sec.[2K|################----| 80.00%, 4033/1007 sec. train epoch 14, iter 800/1000, loss 0.074774, 0.20 batches/sec.[2K|################----| 81.00%, 4084/957 sec. train epoch 14, iter 810/1000, loss 0.078578, 0.20 batches/sec.[2K|################----| 82.00%, 4134/906 sec. train epoch 14, iter 820/1000, loss 0.076645, 0.20 batches/sec.[2K|#################---| 83.00%, 4184/856 sec. train epoch 14, iter 830/1000, loss 0.082152, 0.20 batches/sec.[2K|#################---| 84.00%, 4235/808 sec. train epoch 14, iter 840/1000, loss 0.084065, 0.20 batches/sec.[2K|#################---| 85.00%, 4285/754 sec. train epoch 14, iter 850/1000, loss 0.084260, 0.20 batches/sec.[2K|#################---| 86.00%, 4335/706 sec. train epoch 14, iter 860/1000, loss 0.085434, 0.20 batches/sec.[2K|#################---| 87.00%, 4386/653 sec. train epoch 14, iter 870/1000, loss 0.086395, 0.20 batches/sec.[2K|##################--| 88.00%, 4436/605 sec. train epoch 14, iter 880/1000, loss 0.087165, 0.20 batches/sec.[2K|##################--| 89.00%, 4487/555 sec. train epoch 14, iter 890/1000, loss 0.085010, 0.20 batches/sec.[2K|##################--| 90.00%, 4537/503 sec. train epoch 14, iter 900/1000, loss 0.083655, 0.20 batches/sec.[2K|##################--| 91.00%, 4587/455 sec. train epoch 14, iter 910/1000, loss 0.085489, 0.20 batches/sec.[2K|##################--| 92.00%, 4638/403 sec. train epoch 14, iter 920/1000, loss 0.086701, 0.20 batches/sec.[2K|###################-| 93.00%, 4688/352 sec. train epoch 14, iter 930/1000, loss 0.082643, 0.20 batches/sec.[2K|###################-| 94.00%, 4739/303 sec. train epoch 14, iter 940/1000, loss 0.082635, 0.20 batches/sec.[2K|###################-| 95.00%, 4789/252 sec. train epoch 14, iter 950/1000, loss 0.080003, 0.20 batches/sec.[2K|###################-| 96.00%, 4839/202 sec. train epoch 14, iter 960/1000, loss 0.081949, 0.20 batches/sec.[2K|###################-| 97.00%, 4890/151 sec. train epoch 14, iter 970/1000, loss 0.082922, 0.20 batches/sec.[2K|####################| 98.00%, 4940/101 sec. train epoch 14, iter 980/1000, loss 0.083008, 0.20 batches/sec.[2K|####################| 99.00%, 4991/50 sec. train epoch 14, iter 990/1000, loss 0.083873, 0.20 batches/sec.[2K|--------------------| 1.00%, 55/5460 sec. train epoch 15, iter 10/1000, loss 0.202044, 0.21 batches/sec.[2K|--------------------| 2.00%, 106/4936 sec. train epoch 15, iter 20/1000, loss 0.288772, 0.20 batches/sec.[2K|#-------------------| 3.00%, 156/4891 sec. train epoch 15, iter 30/1000, loss 0.245264, 0.20 batches/sec.[2K|#-------------------| 4.00%, 206/4839 sec. train epoch 15, iter 40/1000, loss 0.214941, 0.20 batches/sec.[2K|#-------------------| 5.00%, 257/4779 sec. train epoch 15, iter 50/1000, loss 0.163118, 0.20 batches/sec.[2K|#-------------------| 6.00%, 307/4739 sec. train epoch 15, iter 60/1000, loss 0.111849, 0.20 batches/sec.[2K|#-------------------| 7.00%, 357/4674 sec. train epoch 15, iter 70/1000, loss 0.127858, 0.20 batches/sec.[2K|##------------------| 8.00%, 408/4624 sec. train epoch 15, iter 80/1000, loss 0.096953, 0.20 batches/sec.[2K|##------------------| 9.00%, 458/4576 sec. train epoch 15, iter 90/1000, loss 0.096242, 0.20 batches/sec.[2K|##------------------| 10.00%, 508/4533 sec. train epoch 15, iter 100/1000, loss 0.108060, 0.20 batches/sec.[2K|##------------------| 11.00%, 559/4487 sec. train epoch 15, iter 110/1000, loss 0.105103, 0.20 batches/sec.[2K|##------------------| 12.00%, 609/4429 sec. train epoch 15, iter 120/1000, loss 0.087825, 0.20 batches/sec.[2K|###-----------------| 13.00%, 659/4384 sec. train epoch 15, iter 130/1000, loss 0.087504, 0.20 batches/sec.[2K|###-----------------| 14.00%, 710/4329 sec. train epoch 15, iter 140/1000, loss 0.112600, 0.20 batches/sec.[2K|###-----------------| 15.00%, 760/4282 sec. train epoch 15, iter 150/1000, loss 0.095863, 0.20 batches/sec.[2K|###-----------------| 16.00%, 811/4235 sec. train epoch 15, iter 160/1000, loss 0.067904, 0.20 batches/sec.[2K|###-----------------| 17.00%, 861/4175 sec. train epoch 15, iter 170/1000, loss 0.066160, 0.20 batches/sec.[2K|####----------------| 18.00%, 911/4136 sec. train epoch 15, iter 180/1000, loss 0.085131, 0.20 batches/sec.[2K|####----------------| 19.00%, 962/4072 sec. train epoch 15, iter 190/1000, loss 0.074341, 0.20 batches/sec.[2K|####----------------| 20.00%, 1012/4028 sec. train epoch 15, iter 200/1000, loss 0.060665, 0.20 batches/sec.[2K|####----------------| 21.00%, 1062/3978 sec. train epoch 15, iter 210/1000, loss 0.065414, 0.20 batches/sec.[2K|####----------------| 22.00%, 1113/3924 sec. train epoch 15, iter 220/1000, loss 0.065171, 0.20 batches/sec.[2K|#####---------------| 23.00%, 1163/3885 sec. train epoch 15, iter 230/1000, loss 0.062882, 0.20 batches/sec.[2K|#####---------------| 24.00%, 1213/3819 sec. train epoch 15, iter 240/1000, loss 0.069497, 0.20 batches/sec.[2K|#####---------------| 25.00%, 1264/3781 sec. train epoch 15, iter 250/1000, loss 0.081254, 0.20 batches/sec.[2K|#####---------------| 26.00%, 1314/3721 sec. train epoch 15, iter 260/1000, loss 0.087051, 0.20 batches/sec.[2K|#####---------------| 27.00%, 1364/3679 sec. train epoch 15, iter 270/1000, loss 0.091231, 0.20 batches/sec.[2K|######--------------| 28.00%, 1415/3629 sec. train epoch 15, iter 280/1000, loss 0.088159, 0.20 batches/sec.[2K|######--------------| 29.00%, 1465/3572 sec. train epoch 15, iter 290/1000, loss 0.087091, 0.20 batches/sec.[2K|######--------------| 30.00%, 1516/3529 sec. train epoch 15, iter 300/1000, loss 0.094056, 0.20 batches/sec.[2K|######--------------| 31.00%, 1566/3473 sec. train epoch 15, iter 310/1000, loss 0.087251, 0.20 batches/sec.[2K|######--------------| 32.00%, 1616/3426 sec. train epoch 15, iter 320/1000, loss 0.087350, 0.20 batches/sec.[2K|#######-------------| 33.00%, 1667/3381 sec. train epoch 15, iter 330/1000, loss 0.084994, 0.20 batches/sec.[2K|#######-------------| 34.00%, 1717/3319 sec. train epoch 15, iter 340/1000, loss 0.074608, 0.20 batches/sec.[2K|#######-------------| 35.00%, 1767/3273 sec. train epoch 15, iter 350/1000, loss 0.064698, 0.20 batches/sec.[2K|#######-------------| 36.00%, 1818/3220 sec. train epoch 15, iter 360/1000, loss 0.055507, 0.20 batches/sec.[2K|#######-------------| 37.00%, 1868/3173 sec. train epoch 15, iter 370/1000, loss 0.050794, 0.20 batches/sec.[2K|########------------| 38.00%, 1918/3120 sec. train epoch 15, iter 380/1000, loss 0.047177, 0.20 batches/sec.[2K|########------------| 39.00%, 1969/3077 sec. train epoch 15, iter 390/1000, loss 0.053526, 0.20 batches/sec.[2K|########------------| 40.00%, 2019/3027 sec. train epoch 15, iter 400/1000, loss 0.054825, 0.20 batches/sec.[2K|########------------| 41.00%, 2069/2966 sec. train epoch 15, iter 410/1000, loss 0.057792, 0.20 batches/sec.[2K|########------------| 42.00%, 2120/2924 sec. train epoch 15, iter 420/1000, loss 0.060163, 0.20 batches/sec.[2K|#########-----------| 43.00%, 2170/2869 sec. train epoch 15, iter 430/1000, loss 0.068840, 0.20 batches/sec.[2K|#########-----------| 44.00%, 2221/2822 sec. train epoch 15, iter 440/1000, loss 0.074250, 0.20 batches/sec.[2K|#########-----------| 45.00%, 2271/2769 sec. train epoch 15, iter 450/1000, loss 0.083281, 0.20 batches/sec.[2K|#########-----------| 46.00%, 2321/2717 sec. train epoch 15, iter 460/1000, loss 0.086399, 0.20 batches/sec.[2K|#########-----------| 47.00%, 2372/2671 sec. train epoch 15, iter 470/1000, loss 0.092875, 0.20 batches/sec.[2K|##########----------| 48.00%, 2422/2615 sec. train epoch 15, iter 480/1000, loss 0.088757, 0.20 batches/sec.[2K|##########----------| 49.00%, 2472/2568 sec. train epoch 15, iter 490/1000, loss 0.094346, 0.20 batches/sec.[2K|##########----------| 50.00%, 2523/2521 sec. train epoch 15, iter 500/1000, loss 0.093213, 0.20 batches/sec.[2K|##########----------| 51.00%, 2573/2464 sec. train epoch 15, iter 510/1000, loss 0.092086, 0.20 batches/sec.[2K|##########----------| 52.00%, 2623/2418 sec. train epoch 15, iter 520/1000, loss 0.090862, 0.20 batches/sec.[2K|###########---------| 53.00%, 2674/2364 sec. train epoch 15, iter 530/1000, loss 0.085354, 0.20 batches/sec.[2K|###########---------| 54.00%, 2724/2318 sec. train epoch 15, iter 540/1000, loss 0.079088, 0.20 batches/sec.[2K|###########---------| 55.00%, 2774/2266 sec. train epoch 15, iter 550/1000, loss 0.075285, 0.20 batches/sec.[2K|###########---------| 56.00%, 2825/2220 sec. train epoch 15, iter 560/1000, loss 0.075625, 0.20 batches/sec.[2K|###########---------| 57.00%, 2875/2170 sec. train epoch 15, iter 570/1000, loss 0.074964, 0.20 batches/sec.[2K|############--------| 58.00%, 2926/2114 sec. train epoch 15, iter 580/1000, loss 0.072584, 0.20 batches/sec.[2K|############--------| 59.00%, 2976/2066 sec. train epoch 15, iter 590/1000, loss 0.076075, 0.20 batches/sec.[2K|############--------| 60.00%, 3026/2013 sec. train epoch 15, iter 600/1000, loss 0.075235, 0.20 batches/sec.[2K|############--------| 61.00%, 3077/1967 sec. train epoch 15, iter 610/1000, loss 0.074300, 0.20 batches/sec.[2K|############--------| 62.00%, 3127/1919 sec. train epoch 15, iter 620/1000, loss 0.076598, 0.20 batches/sec.[2K|#############-------| 63.00%, 3178/1861 sec. train epoch 15, iter 630/1000, loss 0.071952, 0.20 batches/sec.[2K|#############-------| 64.00%, 3228/1814 sec. train epoch 15, iter 640/1000, loss 0.070115, 0.20 batches/sec.[2K|#############-------| 65.00%, 3278/1762 sec. train epoch 15, iter 650/1000, loss 0.067382, 0.20 batches/sec.[2K|#############-------| 66.00%, 3329/1715 sec. train epoch 15, iter 660/1000, loss 0.063295, 0.20 batches/sec.[2K|#############-------| 67.00%, 3379/1661 sec. train epoch 15, iter 670/1000, loss 0.069400, 0.20 batches/sec.[2K|##############------| 68.00%, 3429/1609 sec. train epoch 15, iter 680/1000, loss 0.069595, 0.20 batches/sec.[2K|##############------| 69.00%, 3480/1562 sec. train epoch 15, iter 690/1000, loss 0.072502, 0.20 batches/sec.[2K|##############------| 70.00%, 3530/1510 sec. train epoch 15, iter 700/1000, loss 0.073349, 0.20 batches/sec.[2K|##############------| 71.00%, 3581/1462 sec. train epoch 15, iter 710/1000, loss 0.073744, 0.20 batches/sec.[2K|##############------| 72.00%, 3631/1409 sec. train epoch 15, iter 720/1000, loss 0.075121, 0.20 batches/sec.[2K|###############-----| 73.00%, 3681/1361 sec. train epoch 15, iter 730/1000, loss 0.074039, 0.20 batches/sec.[2K|###############-----| 74.00%, 3732/1310 sec. train epoch 15, iter 740/1000, loss 0.073332, 0.20 batches/sec.[2K|###############-----| 75.00%, 3782/1258 sec. train epoch 15, iter 750/1000, loss 0.072810, 0.20 batches/sec.[2K|###############-----| 76.00%, 3832/1210 sec. train epoch 15, iter 760/1000, loss 0.074231, 0.20 batches/sec.[2K|###############-----| 77.00%, 3883/1156 sec. train epoch 15, iter 770/1000, loss 0.074497, 0.20 batches/sec.[32m[2019-03-18 08:15:36 @logger.py:146][0m [2K|####################| 100.00%, 5041/0 sec. train epoch 15, iter 1000/1000, loss 0.064709, 0.20 batches/sec.
[32m[2019-03-18 08:15:40 @logger.py:43][0m [32;1mTrigger callback: [0mTrigger ModelSaver: Save model to model_logs/20190317111349169013_10-255-0-254_mine_NORMAL_wgan_gp_full_model_celeba_hq_256/snap-15000.
[2K|################----| 78.00%, 3933/1108 sec. train epoch 15, iter 780/1000, loss 0.074235, 0.20 batches/sec.[2K|################----| 79.00%, 3983/1059 sec. train epoch 15, iter 790/1000, loss 0.072289, 0.20 batches/sec.[2K|################----| 80.00%, 4034/1005 sec. train epoch 15, iter 800/1000, loss 0.072210, 0.20 batches/sec.[2K|################----| 81.00%, 4084/958 sec. train epoch 15, iter 810/1000, loss 0.069690, 0.20 batches/sec.[2K|################----| 82.00%, 4134/906 sec. train epoch 15, iter 820/1000, loss 0.066668, 0.20 batches/sec.[2K|#################---| 83.00%, 4185/856 sec. train epoch 15, iter 830/1000, loss 0.068948, 0.20 batches/sec.[2K|#################---| 84.00%, 4235/806 sec. train epoch 15, iter 840/1000, loss 0.068838, 0.20 batches/sec.[2K|#################---| 85.00%, 4286/754 sec. train epoch 15, iter 850/1000, loss 0.068020, 0.20 batches/sec.[2K|#################---| 86.00%, 4336/705 sec. train epoch 15, iter 860/1000, loss 0.066123, 0.20 batches/sec.[2K|#################---| 87.00%, 4386/655 sec. train epoch 15, iter 870/1000, loss 0.062252, 0.20 batches/sec.[2K|##################--| 88.00%, 4437/605 sec. train epoch 15, iter 880/1000, loss 0.061535, 0.20 batches/sec.[2K|##################--| 89.00%, 4487/554 sec. train epoch 15, iter 890/1000, loss 0.061164, 0.20 batches/sec.[2K|##################--| 90.00%, 4537/504 sec. train epoch 15, iter 900/1000, loss 0.063608, 0.20 batches/sec.[2K|##################--| 91.00%, 4588/454 sec. train epoch 15, iter 910/1000, loss 0.065351, 0.20 batches/sec.[2K|##################--| 92.00%, 4638/402 sec. train epoch 15, iter 920/1000, loss 0.066880, 0.20 batches/sec.[2K|###################-| 93.00%, 4688/353 sec. train epoch 15, iter 930/1000, loss 0.070691, 0.20 batches/sec.[2K|###################-| 94.00%, 4739/302 sec. train epoch 15, iter 940/1000, loss 0.068201, 0.20 batches/sec.[2K|###################-| 95.00%, 4789/252 sec. train epoch 15, iter 950/1000, loss 0.068839, 0.20 batches/sec.[2K|###################-| 96.00%, 4840/202 sec. train epoch 15, iter 960/1000, loss 0.063891, 0.20 batches/sec.[2K|###################-| 97.00%, 4890/151 sec. train epoch 15, iter 970/1000, loss 0.062818, 0.20 batches/sec.[2K|####################| 98.00%, 4940/101 sec. train epoch 15, iter 980/1000, loss 0.064367, 0.20 batches/sec.[2K|####################| 99.00%, 4991/50 sec. train epoch 15, iter 990/1000, loss 0.065076, 0.20 batches/sec.[2K|--------------------| 1.00%, 55/5466 sec. train epoch 16, iter 10/1000, loss -0.063267, 0.21 batches/sec.[2K|--------------------| 2.00%, 106/4928 sec. train epoch 16, iter 20/1000, loss -0.006832, 0.20 batches/sec.[2K|#-------------------| 3.00%, 156/4893 sec. train epoch 16, iter 30/1000, loss 0.062655, 0.20 batches/sec.[2K|#-------------------| 4.00%, 206/4834 sec. train epoch 16, iter 40/1000, loss 0.157419, 0.20 batches/sec.[2K|#-------------------| 5.00%, 257/4784 sec. train epoch 16, iter 50/1000, loss 0.177628, 0.20 batches/sec.[2K|#-------------------| 6.00%, 307/4736 sec. train epoch 16, iter 60/1000, loss 0.157528, 0.20 batches/sec.[2K|#-------------------| 7.00%, 357/4676 sec. train epoch 16, iter 70/1000, loss 0.165155, 0.20 batches/sec.[2K|##------------------| 8.00%, 408/4645 sec. train epoch 16, iter 80/1000, loss 0.167289, 0.20 batches/sec.[2K|##------------------| 9.00%, 458/4578 sec. train epoch 16, iter 90/1000, loss 0.164422, 0.20 batches/sec.[2K|##------------------| 10.00%, 508/4533 sec. train epoch 16, iter 100/1000, loss 0.150095, 0.20 batches/sec.[2K|##------------------| 11.00%, 559/4491 sec. train epoch 16, iter 110/1000, loss 0.142178, 0.20 batches/sec.[2K|##------------------| 12.00%, 609/4429 sec. train epoch 16, iter 120/1000, loss 0.116445, 0.20 batches/sec.[2K|###-----------------| 13.00%, 660/4382 sec. train epoch 16, iter 130/1000, loss 0.139506, 0.20 batches/sec.[2K|###-----------------| 14.00%, 710/4331 sec. train epoch 16, iter 140/1000, loss 0.154095, 0.20 batches/sec.[2K|###-----------------| 15.00%, 760/4286 sec. train epoch 16, iter 150/1000, loss 0.159093, 0.20 batches/sec.[2K|###-----------------| 16.00%, 811/4233 sec. train epoch 16, iter 160/1000, loss 0.170204, 0.20 batches/sec.[2K|###-----------------| 17.00%, 861/4177 sec. train epoch 16, iter 170/1000, loss 0.181570, 0.20 batches/sec.[2K|####----------------| 18.00%, 912/4130 sec. train epoch 16, iter 180/1000, loss 0.173155, 0.20 batches/sec.[2K|####----------------| 19.00%, 962/4075 sec. train epoch 16, iter 190/1000, loss 0.158173, 0.20 batches/sec.[2K|####----------------| 20.00%, 1012/4035 sec. train epoch 16, iter 200/1000, loss 0.140089, 0.20 batches/sec.[2K|####----------------| 21.00%, 1063/3977 sec. train epoch 16, iter 210/1000, loss 0.136251, 0.20 batches/sec.[2K|####----------------| 22.00%, 1113/3927 sec. train epoch 16, iter 220/1000, loss 0.134177, 0.20 batches/sec.[2K|#####---------------| 23.00%, 1163/3883 sec. train epoch 16, iter 230/1000, loss 0.121494, 0.20 batches/sec.[2K|#####---------------| 24.00%, 1214/3820 sec. train epoch 16, iter 240/1000, loss 0.117711, 0.20 batches/sec.[2K|#####---------------| 25.00%, 1264/3779 sec. train epoch 16, iter 250/1000, loss 0.121641, 0.20 batches/sec.[2K|#####---------------| 26.00%, 1314/3721 sec. train epoch 16, iter 260/1000, loss 0.098875, 0.20 batches/sec.[2K|#####---------------| 27.00%, 1365/3672 sec. train epoch 16, iter 270/1000, loss 0.078092, 0.20 batches/sec.[2K|######--------------| 28.00%, 1415/3623 sec. train epoch 16, iter 280/1000, loss 0.069135, 0.20 batches/sec.[2K|######--------------| 29.00%, 1465/3576 sec. train epoch 16, iter 290/1000, loss 0.071555, 0.20 batches/sec.[2K|######--------------| 30.00%, 1516/3533 sec. train epoch 16, iter 300/1000, loss 0.065127, 0.20 batches/sec.[2K|######--------------| 31.00%, 1566/3471 sec. train epoch 16, iter 310/1000, loss 0.084688, 0.20 batches/sec.[2K|######--------------| 32.00%, 1617/3431 sec. train epoch 16, iter 320/1000, loss 0.082624, 0.20 batches/sec.[2K|#######-------------| 33.00%, 1667/3380 sec. train epoch 16, iter 330/1000, loss 0.080467, 0.20 batches/sec.[2K|#######-------------| 34.00%, 1717/3322 sec. train epoch 16, iter 340/1000, loss 0.085792, 0.20 batches/sec.[2K|#######-------------| 35.00%, 1768/3285 sec. train epoch 16, iter 350/1000, loss 0.089936, 0.20 batches/sec.[2K|#######-------------| 36.00%, 1818/3227 sec. train epoch 16, iter 360/1000, loss 0.096699, 0.20 batches/sec.[2K|#######-------------| 37.00%, 1869/3179 sec. train epoch 16, iter 370/1000, loss 0.095979, 0.20 batches/sec.[2K|########------------| 38.00%, 1919/3122 sec. train epoch 16, iter 380/1000, loss 0.106256, 0.20 batches/sec.[2K|########------------| 39.00%, 1969/3073 sec. train epoch 16, iter 390/1000, loss 0.110741, 0.20 batches/sec.[2K|########------------| 40.00%, 2020/3024 sec. train epoch 16, iter 400/1000, loss 0.112352, 0.20 batches/sec.[2K|########------------| 41.00%, 2070/2972 sec. train epoch 16, iter 410/1000, loss 0.115290, 0.20 batches/sec.[2K|########------------| 42.00%, 2121/2928 sec. train epoch 16, iter 420/1000, loss 0.113154, 0.20 batches/sec.[2K|#########-----------| 43.00%, 2171/2864 sec. train epoch 16, iter 430/1000, loss 0.103168, 0.20 batches/sec.[2K|#########-----------| 44.00%, 2221/2823 sec. train epoch 16, iter 440/1000, loss 0.101206, 0.20 batches/sec.[2K|#########-----------| 45.00%, 2272/2773 sec. train epoch 16, iter 450/1000, loss 0.093304, 0.20 batches/sec.[2K|#########-----------| 46.00%, 2322/2718 sec. train epoch 16, iter 460/1000, loss 0.091400, 0.20 batches/sec.[2K|#########-----------| 47.00%, 2373/2675 sec. train epoch 16, iter 470/1000, loss 0.086909, 0.20 batches/sec.[2K|##########----------| 48.00%, 2423/2615 sec. train epoch 16, iter 480/1000, loss 0.086806, 0.20 batches/sec.[2K|##########----------| 49.00%, 2473/2564 sec. train epoch 16, iter 490/1000, loss 0.089777, 0.20 batches/sec.[2K|##########----------| 50.00%, 2524/2522 sec. train epoch 16, iter 500/1000, loss 0.076541, 0.20 batches/sec.[2K|##########----------| 51.00%, 2574/2471 sec. train epoch 16, iter 510/1000, loss 0.069727, 0.20 batches/sec.[32m[2019-03-18 09:39:41 @logger.py:146][0m [2K|####################| 100.00%, 5045/0 sec. train epoch 16, iter 1000/1000, loss -0.004968, 0.20 batches/sec.
[32m[2019-03-18 09:39:45 @logger.py:43][0m [32;1mTrigger callback: [0mTrigger ModelSaver: Save model to model_logs/20190317111349169013_10-255-0-254_mine_NORMAL_wgan_gp_full_model_celeba_hq_256/snap-16000.
[2K|##########----------| 52.00%, 2625/2423 sec. train epoch 16, iter 520/1000, loss 0.067034, 0.20 batches/sec.[2K|###########---------| 53.00%, 2675/2368 sec. train epoch 16, iter 530/1000, loss 0.063355, 0.20 batches/sec.[2K|###########---------| 54.00%, 2725/2325 sec. train epoch 16, iter 540/1000, loss 0.059382, 0.20 batches/sec.[2K|###########---------| 55.00%, 2776/2267 sec. train epoch 16, iter 550/1000, loss 0.058456, 0.20 batches/sec.[2K|###########---------| 56.00%, 2826/2219 sec. train epoch 16, iter 560/1000, loss 0.056272, 0.20 batches/sec.[2K|###########---------| 57.00%, 2877/2172 sec. train epoch 16, iter 570/1000, loss 0.053540, 0.20 batches/sec.[2K|############--------| 58.00%, 2927/2116 sec. train epoch 16, iter 580/1000, loss 0.048305, 0.20 batches/sec.[2K|############--------| 59.00%, 2978/2069 sec. train epoch 16, iter 590/1000, loss 0.047449, 0.20 batches/sec.[2K|############--------| 60.00%, 3028/2016 sec. train epoch 16, iter 600/1000, loss 0.044760, 0.20 batches/sec.[2K|############--------| 61.00%, 3078/1967 sec. train epoch 16, iter 610/1000, loss 0.045090, 0.20 batches/sec.[2K|############--------| 62.00%, 3129/1916 sec. train epoch 16, iter 620/1000, loss 0.045627, 0.20 batches/sec.[2K|#############-------| 63.00%, 3179/1866 sec. train epoch 16, iter 630/1000, loss 0.042180, 0.20 batches/sec.[2K|#############-------| 64.00%, 3230/1818 sec. train epoch 16, iter 640/1000, loss 0.039781, 0.20 batches/sec.[2K|#############-------| 65.00%, 3280/1761 sec. train epoch 16, iter 650/1000, loss 0.035179, 0.20 batches/sec.[2K|#############-------| 66.00%, 3330/1713 sec. train epoch 16, iter 660/1000, loss 0.034067, 0.20 batches/sec.[2K|#############-------| 67.00%, 3381/1663 sec. train epoch 16, iter 670/1000, loss 0.027250, 0.20 batches/sec.[2K|##############------| 68.00%, 3431/1613 sec. train epoch 16, iter 680/1000, loss 0.025708, 0.20 batches/sec.[2K|##############------| 69.00%, 3482/1567 sec. train epoch 16, iter 690/1000, loss 0.024421, 0.20 batches/sec.[2K|##############------| 70.00%, 3532/1508 sec. train epoch 16, iter 700/1000, loss 0.020184, 0.20 batches/sec.[2K|##############------| 71.00%, 3583/1464 sec. train epoch 16, iter 710/1000, loss 0.016636, 0.20 batches/sec.[2K|##############------| 72.00%, 3633/1413 sec. train epoch 16, iter 720/1000, loss 0.018338, 0.20 batches/sec.[2K|###############-----| 73.00%, 3683/1360 sec. train epoch 16, iter 730/1000, loss 0.016076, 0.20 batches/sec.[2K|###############-----| 74.00%, 3734/1313 sec. train epoch 16, iter 740/1000, loss 0.014179, 0.20 batches/sec.[2K|###############-----| 75.00%, 3784/1260 sec. train epoch 16, iter 750/1000, loss 0.014273, 0.20 batches/sec.[2K|###############-----| 76.00%, 3835/1211 sec. train epoch 16, iter 760/1000, loss 0.016546, 0.20 batches/sec.[2K|###############-----| 77.00%, 3885/1160 sec. train epoch 16, iter 770/1000, loss 0.016880, 0.20 batches/sec.[2K|################----| 78.00%, 3936/1109 sec. train epoch 16, iter 780/1000, loss 0.015190, 0.20 batches/sec.[2K|################----| 79.00%, 3986/1059 sec. train epoch 16, iter 790/1000, loss 0.014089, 0.20 batches/sec.[2K|################----| 80.00%, 4036/1007 sec. train epoch 16, iter 800/1000, loss 0.011390, 0.20 batches/sec.[2K|################----| 81.00%, 4087/960 sec. train epoch 16, iter 810/1000, loss 0.010867, 0.20 batches/sec.[2K|################----| 82.00%, 4137/909 sec. train epoch 16, iter 820/1000, loss 0.009699, 0.20 batches/sec.[2K|#################---| 83.00%, 4188/858 sec. train epoch 16, iter 830/1000, loss 0.009574, 0.20 batches/sec.[2K|#################---| 84.00%, 4238/806 sec. train epoch 16, iter 840/1000, loss 0.008647, 0.20 batches/sec.[2K|#################---| 85.00%, 4289/756 sec. train epoch 16, iter 850/1000, loss 0.009411, 0.20 batches/sec.[2K|#################---| 86.00%, 4339/707 sec. train epoch 16, iter 860/1000, loss 0.007281, 0.20 batches/sec.[2K|#################---| 87.00%, 4389/654 sec. train epoch 16, iter 870/1000, loss 0.008732, 0.20 batches/sec.[2K|##################--| 88.00%, 4440/605 sec. train epoch 16, iter 880/1000, loss 0.009673, 0.20 batches/sec.[2K|##################--| 89.00%, 4490/554 sec. train epoch 16, iter 890/1000, loss 0.008721, 0.20 batches/sec.[2K|##################--| 90.00%, 4541/503 sec. train epoch 16, iter 900/1000, loss 0.005715, 0.20 batches/sec.[2K|##################--| 91.00%, 4591/454 sec. train epoch 16, iter 910/1000, loss 0.004286, 0.20 batches/sec.[2K|##################--| 92.00%, 4641/403 sec. train epoch 16, iter 920/1000, loss -0.001518, 0.20 batches/sec.[2K|###################-| 93.00%, 4692/354 sec. train epoch 16, iter 930/1000, loss -0.001447, 0.20 batches/sec.[2K|###################-| 94.00%, 4742/303 sec. train epoch 16, iter 940/1000, loss -0.004534, 0.20 batches/sec.[2K|###################-| 95.00%, 4793/253 sec. train epoch 16, iter 950/1000, loss -0.005921, 0.20 batches/sec.[2K|###################-| 96.00%, 4843/202 sec. train epoch 16, iter 960/1000, loss -0.005289, 0.20 batches/sec.[2K|###################-| 97.00%, 4893/151 sec. train epoch 16, iter 970/1000, loss -0.006225, 0.20 batches/sec.[2K|####################| 98.00%, 4944/101 sec. train epoch 16, iter 980/1000, loss -0.004277, 0.20 batches/sec.[2K|####################| 99.00%, 4994/50 sec. train epoch 16, iter 990/1000, loss -0.003565, 0.20 batches/sec.[2K|--------------------| 1.00%, 55/5474 sec. train epoch 17, iter 10/1000, loss -0.129298, 0.21 batches/sec.[2K|--------------------| 2.00%, 106/4923 sec. train epoch 17, iter 20/1000, loss -0.132264, 0.20 batches/sec.[2K|#-------------------| 3.00%, 156/4894 sec. train epoch 17, iter 30/1000, loss -0.080047, 0.20 batches/sec.[2K|#-------------------| 4.00%, 206/4833 sec. train epoch 17, iter 40/1000, loss -0.095504, 0.20 batches/sec.[2K|#-------------------| 5.00%, 257/4789 sec. train epoch 17, iter 50/1000, loss -0.097633, 0.20 batches/sec.[2K|#-------------------| 6.00%, 307/4746 sec. train epoch 17, iter 60/1000, loss -0.096553, 0.20 batches/sec.[2K|#-------------------| 7.00%, 358/4683 sec. train epoch 17, iter 70/1000, loss -0.043626, 0.20 batches/sec.[2K|##------------------| 8.00%, 408/4640 sec. train epoch 17, iter 80/1000, loss -0.036743, 0.20 batches/sec.[2K|##------------------| 9.00%, 458/4575 sec. train epoch 17, iter 90/1000, loss -0.050526, 0.20 batches/sec.[2K|##------------------| 10.00%, 509/4546 sec. train epoch 17, iter 100/1000, loss -0.062942, 0.20 batches/sec.[2K|##------------------| 11.00%, 559/4479 sec. train epoch 17, iter 110/1000, loss -0.082607, 0.20 batches/sec.[2K|##------------------| 12.00%, 609/4433 sec. train epoch 17, iter 120/1000, loss -0.095514, 0.20 batches/sec.[2K|###-----------------| 13.00%, 660/4394 sec. train epoch 17, iter 130/1000, loss -0.104266, 0.20 batches/sec.[2K|###-----------------| 14.00%, 710/4329 sec. train epoch 17, iter 140/1000, loss -0.102880, 0.20 batches/sec.[2K|###-----------------| 15.00%, 761/4292 sec. train epoch 17, iter 150/1000, loss -0.093319, 0.20 batches/sec.[2K|###-----------------| 16.00%, 811/4233 sec. train epoch 17, iter 160/1000, loss -0.095395, 0.20 batches/sec.[2K|###-----------------| 17.00%, 862/4182 sec. train epoch 17, iter 170/1000, loss -0.083870, 0.20 batches/sec.[2K|####----------------| 18.00%, 912/4134 sec. train epoch 17, iter 180/1000, loss -0.069199, 0.20 batches/sec.[2K|####----------------| 19.00%, 962/4078 sec. train epoch 17, iter 190/1000, loss -0.067655, 0.20 batches/sec.[2K|####----------------| 20.00%, 1013/4031 sec. train epoch 17, iter 200/1000, loss -0.062311, 0.20 batches/sec.[2K|####----------------| 21.00%, 1063/3978 sec. train epoch 17, iter 210/1000, loss -0.069477, 0.20 batches/sec.[2K|####----------------| 22.00%, 1113/3931 sec. train epoch 17, iter 220/1000, loss -0.062842, 0.20 batches/sec.[2K|#####---------------| 23.00%, 1164/3879 sec. train epoch 17, iter 230/1000, loss -0.061268, 0.20 batches/sec.[2K|#####---------------| 24.00%, 1214/3828 sec. train epoch 17, iter 240/1000, loss -0.055850, 0.20 batches/sec.[2K|#####---------------| 25.00%, 1265/3782 sec. train epoch 17, iter 250/1000, loss -0.057790, 0.20 batches/sec.[2K|#####---------------| 26.00%, 1315/3719 sec. train epoch 17, iter 260/1000, loss -0.047035, 0.20 batches/sec.[2K|#####---------------| 27.00%, 1365/3684 sec. train epoch 17, iter 270/1000, loss -0.042100, 0.20 batches/sec.[2K|######--------------| 28.00%, 1416/3627 sec. train epoch 17, iter 280/1000, loss -0.033659, 0.20 batches/sec.[2K|######--------------| 29.00%, 1466/3577 sec. train epoch 17, iter 290/1000, loss -0.027670, 0.20 batches/sec.[2K|######--------------| 30.00%, 1517/3527 sec. train epoch 17, iter 300/1000, loss -0.022654, 0.20 batches/sec.[2K|######--------------| 31.00%, 1567/3469 sec. train epoch 17, iter 310/1000, loss -0.024362, 0.20 batches/sec.[2K|######--------------| 32.00%, 1618/3457 sec. train epoch 17, iter 320/1000, loss -0.026646, 0.20 batches/sec.[2K|#######-------------| 33.00%, 1668/3393 sec. train epoch 17, iter 330/1000, loss -0.025093, 0.20 batches/sec.[2K|#######-------------| 34.00%, 1719/3335 sec. train epoch 17, iter 340/1000, loss -0.021131, 0.20 batches/sec.[2K|#######-------------| 35.00%, 1769/3284 sec. train epoch 17, iter 350/1000, loss -0.018734, 0.20 batches/sec.[2K|#######-------------| 36.00%, 1820/3229 sec. train epoch 17, iter 360/1000, loss -0.015590, 0.20 batches/sec.[2K|#######-------------| 37.00%, 1870/3181 sec. train epoch 17, iter 370/1000, loss -0.017751, 0.20 batches/sec.[2K|########------------| 38.00%, 1921/3119 sec. train epoch 17, iter 380/1000, loss -0.016690, 0.20 batches/sec.[2K|########------------| 39.00%, 1971/3076 sec. train epoch 17, iter 390/1000, loss -0.017705, 0.20 batches/sec.[2K|########------------| 40.00%, 2021/3028 sec. train epoch 17, iter 400/1000, loss -0.020137, 0.20 batches/sec.[2K|########------------| 41.00%, 2072/2969 sec. train epoch 17, iter 410/1000, loss -0.020169, 0.20 batches/sec.[2K|########------------| 42.00%, 2122/2927 sec. train epoch 17, iter 420/1000, loss -0.020977, 0.20 batches/sec.[2K|#########-----------| 43.00%, 2173/2867 sec. train epoch 17, iter 430/1000, loss -0.028221, 0.20 batches/sec.[2K|#########-----------| 44.00%, 2223/2819 sec. train epoch 17, iter 440/1000, loss -0.030878, 0.20 batches/sec.[2K|#########-----------| 45.00%, 2273/2773 sec. train epoch 17, iter 450/1000, loss -0.029815, 0.20 batches/sec.[2K|#########-----------| 46.00%, 2324/2716 sec. train epoch 17, iter 460/1000, loss -0.033478, 0.20 batches/sec.[2K|#########-----------| 47.00%, 2374/2672 sec. train epoch 17, iter 470/1000, loss -0.032418, 0.20 batches/sec.[2K|##########----------| 48.00%, 2424/2614 sec. train epoch 17, iter 480/1000, loss -0.028037, 0.20 batches/sec.[2K|##########----------| 49.00%, 2475/2569 sec. train epoch 17, iter 490/1000, loss -0.028837, 0.20 batches/sec.[2K|##########----------| 50.00%, 2525/2521 sec. train epoch 17, iter 500/1000, loss -0.030560, 0.20 batches/sec.[2K|##########----------| 51.00%, 2576/2469 sec. train epoch 17, iter 510/1000, loss -0.023040, 0.20 batches/sec.[2K|##########----------| 52.00%, 2626/2422 sec. train epoch 17, iter 520/1000, loss -0.026539, 0.20 batches/sec.[2K|###########---------| 53.00%, 2676/2365 sec. train epoch 17, iter 530/1000, loss -0.024271, 0.20 batches/sec.[2K|###########---------| 54.00%, 2727/2325 sec. train epoch 17, iter 540/1000, loss -0.020324, 0.20 batches/sec.[2K|###########---------| 55.00%, 2777/2266 sec. train epoch 17, iter 550/1000, loss -0.024778, 0.20 batches/sec.[2K|###########---------| 56.00%, 2828/2222 sec. train epoch 17, iter 560/1000, loss -0.023352, 0.20 batches/sec.[2K|###########---------| 57.00%, 2878/2166 sec. train epoch 17, iter 570/1000, loss -0.024149, 0.20 batches/sec.[2K|############--------| 58.00%, 2928/2113 sec. train epoch 17, iter 580/1000, loss -0.030958, 0.20 batches/sec.[2K|############--------| 59.00%, 2979/2076 sec. train epoch 17, iter 590/1000, loss -0.035120, 0.20 batches/sec.[2K|############--------| 60.00%, 3029/2012 sec. train epoch 17, iter 600/1000, loss -0.039718, 0.20 batches/sec.[2K|############--------| 61.00%, 3080/1965 sec. train epoch 17, iter 610/1000, loss -0.041291, 0.20 batches/sec.[2K|############--------| 62.00%, 3130/1914 sec. train epoch 17, iter 620/1000, loss -0.044216, 0.20 batches/sec.[2K|#############-------| 63.00%, 3180/1862 sec. train epoch 17, iter 630/1000, loss -0.044592, 0.20 batches/sec.[2K|#############-------| 64.00%, 3231/1816 sec. train epoch 17, iter 640/1000, loss -0.044317, 0.20 batches/sec.[2K|#############-------| 65.00%, 3281/1759 sec. train epoch 17, iter 650/1000, loss -0.044116, 0.20 batches/sec.[2K|#############-------| 66.00%, 3332/1714 sec. train epoch 17, iter 660/1000, loss -0.046253, 0.20 batches/sec.[2K|#############-------| 67.00%, 3382/1663 sec. train epoch 17, iter 670/1000, loss -0.044211, 0.20 batches/sec.[2K|##############------| 68.00%, 3432/1614 sec. train epoch 17, iter 680/1000, loss -0.039769, 0.20 batches/sec.[2K|##############------| 69.00%, 3483/1564 sec. train epoch 17, iter 690/1000, loss -0.040052, 0.20 batches/sec.[2K|##############------| 70.00%, 3533/1510 sec. train epoch 17, iter 700/1000, loss -0.038725, 0.20 batches/sec.[2K|##############------| 71.00%, 3584/1463 sec. train epoch 17, iter 710/1000, loss -0.039737, 0.20 batches/sec.[2K|##############------| 72.00%, 3634/1408 sec. train epoch 17, iter 720/1000, loss -0.039840, 0.20 batches/sec.[2K|###############-----| 73.00%, 3684/1361 sec. train epoch 17, iter 730/1000, loss -0.041733, 0.20 batches/sec.[2K|###############-----| 74.00%, 3735/1311 sec. train epoch 17, iter 740/1000, loss -0.040033, 0.20 batches/sec.[2K|###############-----| 75.00%, 3785/1257 sec. train epoch 17, iter 750/1000, loss -0.048254, 0.20 batches/sec.[2K|###############-----| 76.00%, 3835/1210 sec. train epoch 17, iter 760/1000, loss -0.048253, 0.20 batches/sec.[2K|###############-----| 77.00%, 3886/1157 sec. train epoch 17, iter 770/1000, loss -0.049297, 0.20 batches/sec.[2K|################----| 78.00%, 3936/1111 sec. train epoch 17, iter 780/1000, loss -0.049422, 0.20 batches/sec.[2K|################----| 79.00%, 3987/1058 sec. train epoch 17, iter 790/1000, loss -0.044041, 0.20 batches/sec.[2K|################----| 80.00%, 4037/1006 sec. train epoch 17, iter 800/1000, loss -0.047333, 0.20 batches/sec.[2K|################----| 81.00%, 4087/959 sec. train epoch 17, iter 810/1000, loss -0.048233, 0.20 batches/sec.[2K|################----| 82.00%, 4138/906 sec. train epoch 17, iter 820/1000, loss -0.047382, 0.20 batches/sec.[2K|#################---| 83.00%, 4188/858 sec. train epoch 17, iter 830/1000, loss -0.047694, 0.20 batches/sec.[2K|#################---| 84.00%, 4238/805 sec. train epoch 17, iter 840/1000, loss -0.048082, 0.20 batches/sec.[2K|#################---| 85.00%, 4289/756 sec. train epoch 17, iter 850/1000, loss -0.049489, 0.20 batches/sec.[2K|#################---| 86.00%, 4339/705 sec. train epoch 17, iter 860/1000, loss -0.048355, 0.20 batches/sec.[2K|#################---| 87.00%, 4390/654 sec. train epoch 17, iter 870/1000, loss -0.049023, 0.20 batches/sec.[2K|##################--| 88.00%, 4440/606 sec. train epoch 17, iter 880/1000, loss -0.050758, 0.20 batches/sec.[2K|##################--| 89.00%, 4490/555 sec. train epoch 17, iter 890/1000, loss -0.048765, 0.20 batches/sec.[2K|##################--| 90.00%, 4541/505 sec. train epoch 17, iter 900/1000, loss -0.046128, 0.20 batches/sec.[2K|##################--| 91.00%, 4591/454 sec. train epoch 17, iter 910/1000, loss -0.047676, 0.20 batches/sec.[2K|##################--| 92.00%, 4642/402 sec. train epoch 17, iter 920/1000, loss -0.045281, 0.20 batches/sec.[2K|###################-| 93.00%, 4692/353 sec. train epoch 17, iter 930/1000, loss -0.043015, 0.20 batches/sec.[2K|###################-| 94.00%, 4742/302 sec. train epoch 17, iter 940/1000, loss -0.039182, 0.20 batches/sec.[2K|###################-| 95.00%, 4793/252 sec. train epoch 17, iter 950/1000, loss -0.037021, 0.20 batches/sec.[2K|###################-| 96.00%, 4843/201 sec. train epoch 17, iter 960/1000, loss -0.034198, 0.20 batches/sec.[2K|###################-| 97.00%, 4894/151 sec. train epoch 17, iter 970/1000, loss -0.031905, 0.20 batches/sec.[32m[2019-03-18 11:03:46 @logger.py:146][0m [2K|####################| 100.00%, 5045/0 sec. train epoch 17, iter 1000/1000, loss -0.030989, 0.20 batches/sec.
[32m[2019-03-18 11:03:49 @logger.py:43][0m [32;1mTrigger callback: [0mTrigger ModelSaver: Save model to model_logs/20190317111349169013_10-255-0-254_mine_NORMAL_wgan_gp_full_model_celeba_hq_256/snap-17000.
[2K|####################| 98.00%, 4944/101 sec. train epoch 17, iter 980/1000, loss -0.030166, 0.20 batches/sec.[2K|####################| 99.00%, 4994/50 sec. train epoch 17, iter 990/1000, loss -0.029839, 0.20 batches/sec.[2K|--------------------| 1.00%, 55/5453 sec. train epoch 18, iter 10/1000, loss 0.428714, 0.21 batches/sec.[2K|--------------------| 2.00%, 106/4941 sec. train epoch 18, iter 20/1000, loss 0.295948, 0.20 batches/sec.[2K|#-------------------| 3.00%, 156/4885 sec. train epoch 18, iter 30/1000, loss 0.281902, 0.20 batches/sec.[2K|#-------------------| 4.00%, 206/4837 sec. train epoch 18, iter 40/1000, loss 0.196277, 0.20 batches/sec.[2K|#-------------------| 5.00%, 257/4797 sec. train epoch 18, iter 50/1000, loss 0.121010, 0.20 batches/sec.[2K|#-------------------| 6.00%, 307/4725 sec. train epoch 18, iter 60/1000, loss 0.065292, 0.20 batches/sec.[2K|#-------------------| 7.00%, 357/4685 sec. train epoch 18, iter 70/1000, loss 0.041399, 0.20 batches/sec.[2K|##------------------| 8.00%, 408/4631 sec. train epoch 18, iter 80/1000, loss 0.050122, 0.20 batches/sec.[2K|##------------------| 9.00%, 458/4584 sec. train epoch 18, iter 90/1000, loss 0.052644, 0.20 batches/sec.[2K|##------------------| 10.00%, 509/4541 sec. train epoch 18, iter 100/1000, loss 0.044250, 0.20 batches/sec.[2K|##------------------| 11.00%, 559/4477 sec. train epoch 18, iter 110/1000, loss 0.075594, 0.20 batches/sec.[2K|##------------------| 12.00%, 609/4439 sec. train epoch 18, iter 120/1000, loss 0.058369, 0.20 batches/sec.[2K|###-----------------| 13.00%, 660/4380 sec. train epoch 18, iter 130/1000, loss 0.068128, 0.20 batches/sec.[2K|###-----------------| 14.00%, 710/4332 sec. train epoch 18, iter 140/1000, loss 0.064390, 0.20 batches/sec.[2K|###-----------------| 15.00%, 760/4285 sec. train epoch 18, iter 150/1000, loss 0.057098, 0.20 batches/sec.[2K|###-----------------| 16.00%, 811/4233 sec. train epoch 18, iter 160/1000, loss 0.031268, 0.20 batches/sec.[2K|###-----------------| 17.00%, 861/4186 sec. train epoch 18, iter 170/1000, loss 0.025522, 0.20 batches/sec.[2K|####----------------| 18.00%, 912/4125 sec. train epoch 18, iter 180/1000, loss 0.019235, 0.20 batches/sec.[2K|####----------------| 19.00%, 962/4083 sec. train epoch 18, iter 190/1000, loss 0.023433, 0.20 batches/sec.[2K|####----------------| 20.00%, 1012/4029 sec. train epoch 18, iter 200/1000, loss 0.027033, 0.20 batches/sec.[2K|####----------------| 21.00%, 1063/3979 sec. train epoch 18, iter 210/1000, loss 0.027171, 0.20 batches/sec.[2K|####----------------| 22.00%, 1113/3932 sec. train epoch 18, iter 220/1000, loss 0.015154, 0.20 batches/sec.[2K|#####---------------| 23.00%, 1163/3871 sec. train epoch 18, iter 230/1000, loss 0.022907, 0.20 batches/sec.[2K|#####---------------| 24.00%, 1214/3834 sec. train epoch 18, iter 240/1000, loss 0.027926, 0.20 batches/sec.[2K|#####---------------| 25.00%, 1264/3769 sec. train epoch 18, iter 250/1000, loss 0.025888, 0.20 batches/sec.[2K|#####---------------| 26.00%, 1315/3729 sec. train epoch 18, iter 260/1000, loss 0.025467, 0.20 batches/sec.[2K|#####---------------| 27.00%, 1365/3678 sec. train epoch 18, iter 270/1000, loss 0.030303, 0.20 batches/sec.[2K|######--------------| 28.00%, 1415/3622 sec. train epoch 18, iter 280/1000, loss 0.028392, 0.20 batches/sec.[2K|######--------------| 29.00%, 1466/3583 sec. train epoch 18, iter 290/1000, loss 0.028607, 0.20 batches/sec.[2K|######--------------| 30.00%, 1516/3520 sec. train epoch 18, iter 300/1000, loss 0.034600, 0.20 batches/sec.[2K|######--------------| 31.00%, 1566/3476 sec. train epoch 18, iter 310/1000, loss 0.036238, 0.20 batches/sec.[2K|######--------------| 32.00%, 1617/3424 sec. train epoch 18, iter 320/1000, loss 0.041830, 0.20 batches/sec.[2K|#######-------------| 33.00%, 1667/3373 sec. train epoch 18, iter 330/1000, loss 0.044766, 0.20 batches/sec.[2K|#######-------------| 34.00%, 1717/3326 sec. train epoch 18, iter 340/1000, loss 0.045830, 0.20 batches/sec.[2K|#######-------------| 35.00%, 1768/3269 sec. train epoch 18, iter 350/1000, loss 0.046980, 0.20 batches/sec.[2K|#######-------------| 36.00%, 1818/3229 sec. train epoch 18, iter 360/1000, loss 0.041220, 0.20 batches/sec.[2K|#######-------------| 37.00%, 1869/3173 sec. train epoch 18, iter 370/1000, loss 0.038130, 0.20 batches/sec.[2K|########------------| 38.00%, 1919/3125 sec. train epoch 18, iter 380/1000, loss 0.034780, 0.20 batches/sec.[2K|########------------| 39.00%, 1969/3076 sec. train epoch 18, iter 390/1000, loss 0.035330, 0.20 batches/sec.[2K|########------------| 40.00%, 2020/3020 sec. train epoch 18, iter 400/1000, loss 0.035030, 0.20 batches/sec.[2K|########------------| 41.00%, 2070/2972 sec. train epoch 18, iter 410/1000, loss 0.043720, 0.20 batches/sec.[2K|########------------| 42.00%, 2120/2921 sec. train epoch 18, iter 420/1000, loss 0.043277, 0.20 batches/sec.[2K|#########-----------| 43.00%, 2171/2873 sec. train epoch 18, iter 430/1000, loss 0.041648, 0.20 batches/sec.[2K|#########-----------| 44.00%, 2221/2826 sec. train epoch 18, iter 440/1000, loss 0.038458, 0.20 batches/sec.[2K|#########-----------| 45.00%, 2272/2771 sec. train epoch 18, iter 450/1000, loss 0.037598, 0.20 batches/sec.[2K|#########-----------| 46.00%, 2322/2724 sec. train epoch 18, iter 460/1000, loss 0.042886, 0.20 batches/sec.[2K|#########-----------| 47.00%, 2372/2661 sec. train epoch 18, iter 470/1000, loss 0.049608, 0.20 batches/sec.[2K|##########----------| 48.00%, 2423/2620 sec. train epoch 18, iter 480/1000, loss 0.049147, 0.20 batches/sec.[2K|##########----------| 49.00%, 2473/2573 sec. train epoch 18, iter 490/1000, loss 0.053019, 0.20 batches/sec.[2K|##########----------| 50.00%, 2524/2515 sec. train epoch 18, iter 500/1000, loss 0.053543, 0.20 batches/sec.[2K|##########----------| 51.00%, 2574/2473 sec. train epoch 18, iter 510/1000, loss 0.054749, 0.20 batches/sec.[2K|##########----------| 52.00%, 2624/2418 sec. train epoch 18, iter 520/1000, loss 0.055401, 0.20 batches/sec.[2K|###########---------| 53.00%, 2675/2370 sec. train epoch 18, iter 530/1000, loss 0.059587, 0.20 batches/sec.[2K|###########---------| 54.00%, 2725/2317 sec. train epoch 18, iter 540/1000, loss 0.062044, 0.20 batches/sec.[2K|###########---------| 55.00%, 2776/2265 sec. train epoch 18, iter 550/1000, loss 0.061543, 0.20 batches/sec.[2K|###########---------| 56.00%, 2826/2220 sec. train epoch 18, iter 560/1000, loss 0.059491, 0.20 batches/sec.[2K|###########---------| 57.00%, 2876/2168 sec. train epoch 18, iter 570/1000, loss 0.052587, 0.20 batches/sec.[2K|############--------| 58.00%, 2927/2119 sec. train epoch 18, iter 580/1000, loss 0.053358, 0.20 batches/sec.[2K|############--------| 59.00%, 2977/2062 sec. train epoch 18, iter 590/1000, loss 0.052036, 0.20 batches/sec.[2K|############--------| 60.00%, 3028/2016 sec. train epoch 18, iter 600/1000, loss 0.043048, 0.20 batches/sec.[2K|############--------| 61.00%, 3078/1964 sec. train epoch 18, iter 610/1000, loss 0.041075, 0.20 batches/sec.[2K|############--------| 62.00%, 3128/1911 sec. train epoch 18, iter 620/1000, loss 0.037782, 0.20 batches/sec.[2K|#############-------| 63.00%, 3179/1865 sec. train epoch 18, iter 630/1000, loss 0.035185, 0.20 batches/sec.[2K|#############-------| 64.00%, 3229/1811 sec. train epoch 18, iter 640/1000, loss 0.037500, 0.20 batches/sec.[2K|#############-------| 65.00%, 3279/1763 sec. train epoch 18, iter 650/1000, loss 0.038319, 0.20 batches/sec.[2K|#############-------| 66.00%, 3330/1713 sec. train epoch 18, iter 660/1000, loss 0.036971, 0.20 batches/sec.[2K|#############-------| 67.00%, 3380/1659 sec. train epoch 18, iter 670/1000, loss 0.033975, 0.20 batches/sec.[2K|##############------| 68.00%, 3430/1612 sec. train epoch 18, iter 680/1000, loss 0.029460, 0.20 batches/sec.[2K|##############------| 69.00%, 3481/1560 sec. train epoch 18, iter 690/1000, loss 0.027819, 0.20 batches/sec.[2K|##############------| 70.00%, 3531/1513 sec. train epoch 18, iter 700/1000, loss 0.027393, 0.20 batches/sec.[2K|##############------| 71.00%, 3581/1459 sec. train epoch 18, iter 710/1000, loss 0.026942, 0.20 batches/sec.[32m[2019-03-18 12:27:48 @logger.py:146][0m [2K|####################| 100.00%, 5042/0 sec. train epoch 18, iter 1000/1000, loss 0.022334, 0.20 batches/sec.
[32m[2019-03-18 12:27:52 @logger.py:43][0m [32;1mTrigger callback: [0mTrigger ModelSaver: Save model to model_logs/20190317111349169013_10-255-0-254_mine_NORMAL_wgan_gp_full_model_celeba_hq_256/snap-18000.
[2K|##############------| 72.00%, 3632/1412 sec. train epoch 18, iter 720/1000, loss 0.021412, 0.20 batches/sec.[2K|###############-----| 73.00%, 3682/1358 sec. train epoch 18, iter 730/1000, loss 0.022951, 0.20 batches/sec.[2K|###############-----| 74.00%, 3733/1311 sec. train epoch 18, iter 740/1000, loss 0.021466, 0.20 batches/sec.[2K|###############-----| 75.00%, 3783/1262 sec. train epoch 18, iter 750/1000, loss 0.018748, 0.20 batches/sec.[2K|###############-----| 76.00%, 3833/1207 sec. train epoch 18, iter 760/1000, loss 0.020034, 0.20 batches/sec.[2K|###############-----| 77.00%, 3884/1160 sec. train epoch 18, iter 770/1000, loss 0.019302, 0.20 batches/sec.[2K|################----| 78.00%, 3934/1105 sec. train epoch 18, iter 780/1000, loss 0.022482, 0.20 batches/sec.[2K|################----| 79.00%, 3984/1060 sec. train epoch 18, iter 790/1000, loss 0.021610, 0.20 batches/sec.[2K|################----| 80.00%, 4035/1008 sec. train epoch 18, iter 800/1000, loss 0.015556, 0.20 batches/sec.[2K|################----| 81.00%, 4085/958 sec. train epoch 18, iter 810/1000, loss 0.022972, 0.20 batches/sec.[2K|################----| 82.00%, 4136/906 sec. train epoch 18, iter 820/1000, loss 0.024135, 0.20 batches/sec.[2K|#################---| 83.00%, 4186/855 sec. train epoch 18, iter 830/1000, loss 0.025961, 0.20 batches/sec.[2K|#################---| 84.00%, 4236/807 sec. train epoch 18, iter 840/1000, loss 0.021162, 0.20 batches/sec.[2K|#################---| 85.00%, 4287/755 sec. train epoch 18, iter 850/1000, loss 0.019715, 0.20 batches/sec.[2K|#################---| 86.00%, 4337/704 sec. train epoch 18, iter 860/1000, loss 0.019505, 0.20 batches/sec.[2K|#################---| 87.00%, 4387/656 sec. train epoch 18, iter 870/1000, loss 0.022764, 0.20 batches/sec.[2K|##################--| 88.00%, 4438/604 sec. train epoch 18, iter 880/1000, loss 0.028764, 0.20 batches/sec.[2K|##################--| 89.00%, 4488/553 sec. train epoch 18, iter 890/1000, loss 0.028396, 0.20 batches/sec.[2K|##################--| 90.00%, 4538/503 sec. train epoch 18, iter 900/1000, loss 0.026294, 0.20 batches/sec.[2K|##################--| 91.00%, 4589/454 sec. train epoch 18, iter 910/1000, loss 0.021006, 0.20 batches/sec.[2K|##################--| 92.00%, 4639/404 sec. train epoch 18, iter 920/1000, loss 0.019656, 0.20 batches/sec.[2K|###################-| 93.00%, 4690/353 sec. train epoch 18, iter 930/1000, loss 0.016025, 0.20 batches/sec.[2K|###################-| 94.00%, 4740/303 sec. train epoch 18, iter 940/1000, loss 0.015327, 0.20 batches/sec.[2K|###################-| 95.00%, 4790/252 sec. train epoch 18, iter 950/1000, loss 0.016687, 0.20 batches/sec.[2K|###################-| 96.00%, 4841/202 sec. train epoch 18, iter 960/1000, loss 0.016586, 0.20 batches/sec.[2K|###################-| 97.00%, 4891/151 sec. train epoch 18, iter 970/1000, loss 0.016467, 0.20 batches/sec.[2K|####################| 98.00%, 4942/101 sec. train epoch 18, iter 980/1000, loss 0.017730, 0.20 batches/sec.[2K|####################| 99.00%, 4992/50 sec. train epoch 18, iter 990/1000, loss 0.017993, 0.20 batches/sec.[2K|--------------------| 1.00%, 55/5449 sec. train epoch 19, iter 10/1000, loss 0.022581, 0.21 batches/sec.[2K|--------------------| 2.00%, 105/4936 sec. train epoch 19, iter 20/1000, loss -0.117710, 0.20 batches/sec.[2K|#-------------------| 3.00%, 156/4882 sec. train epoch 19, iter 30/1000, loss -0.103210, 0.20 batches/sec.[2K|#-------------------| 4.00%, 206/4845 sec. train epoch 19, iter 40/1000, loss -0.087463, 0.20 batches/sec.[2K|#-------------------| 5.00%, 256/4778 sec. train epoch 19, iter 50/1000, loss -0.080111, 0.20 batches/sec.[2K|#-------------------| 6.00%, 307/4746 sec. train epoch 19, iter 60/1000, loss -0.098607, 0.20 batches/sec.[2K|#-------------------| 7.00%, 357/4687 sec. train epoch 19, iter 70/1000, loss -0.061179, 0.20 batches/sec.[2K|##------------------| 8.00%, 408/4630 sec. train epoch 19, iter 80/1000, loss -0.040849, 0.20 batches/sec.[2K|##------------------| 9.00%, 458/4589 sec. train epoch 19, iter 90/1000, loss -0.054367, 0.20 batches/sec.[2K|##------------------| 10.00%, 508/4523 sec. train epoch 19, iter 100/1000, loss -0.023933, 0.20 batches/sec.[2K|##------------------| 11.00%, 559/4488 sec. train epoch 19, iter 110/1000, loss 0.031286, 0.20 batches/sec.[2K|##------------------| 12.00%, 609/4436 sec. train epoch 19, iter 120/1000, loss 0.027758, 0.20 batches/sec.[2K|###-----------------| 13.00%, 660/4386 sec. train epoch 19, iter 130/1000, loss 0.058959, 0.20 batches/sec.[2K|###-----------------| 14.00%, 710/4337 sec. train epoch 19, iter 140/1000, loss 0.039567, 0.20 batches/sec.[2K|###-----------------| 15.00%, 760/4281 sec. train epoch 19, iter 150/1000, loss 0.023902, 0.20 batches/sec.[2K|###-----------------| 16.00%, 811/4233 sec. train epoch 19, iter 160/1000, loss 0.021428, 0.20 batches/sec.[2K|###-----------------| 17.00%, 861/4182 sec. train epoch 19, iter 170/1000, loss 0.026656, 0.20 batches/sec.[2K|####----------------| 18.00%, 912/4135 sec. train epoch 19, iter 180/1000, loss 0.023540, 0.20 batches/sec.[2K|####----------------| 19.00%, 962/4086 sec. train epoch 19, iter 190/1000, loss 0.020077, 0.20 batches/sec.[2K|####----------------| 20.00%, 1012/4029 sec. train epoch 19, iter 200/1000, loss -0.004456, 0.20 batches/sec.[2K|####----------------| 21.00%, 1063/3987 sec. train epoch 19, iter 210/1000, loss -0.010576, 0.20 batches/sec.[2K|####----------------| 22.00%, 1113/3928 sec. train epoch 19, iter 220/1000, loss -0.017034, 0.20 batches/sec.[2K|#####---------------| 23.00%, 1164/3886 sec. train epoch 19, iter 230/1000, loss -0.013629, 0.20 batches/sec.[2K|#####---------------| 24.00%, 1214/3836 sec. train epoch 19, iter 240/1000, loss -0.011174, 0.20 batches/sec.[2K|#####---------------| 25.00%, 1264/3771 sec. train epoch 19, iter 250/1000, loss -0.015109, 0.20 batches/sec.[2K|#####---------------| 26.00%, 1315/3727 sec. train epoch 19, iter 260/1000, loss -0.022229, 0.20 batches/sec.[2K|#####---------------| 27.00%, 1365/3676 sec. train epoch 19, iter 270/1000, loss -0.010504, 0.20 batches/sec.[2K|######--------------| 28.00%, 1416/3630 sec. train epoch 19, iter 280/1000, loss -0.008966, 0.20 batches/sec.[2K|######--------------| 29.00%, 1466/3570 sec. train epoch 19, iter 290/1000, loss -0.014196, 0.20 batches/sec.[2K|######--------------| 30.00%, 1516/3526 sec. train epoch 19, iter 300/1000, loss -0.012715, 0.20 batches/sec.[2K|######--------------| 31.00%, 1567/3480 sec. train epoch 19, iter 310/1000, loss -0.020397, 0.20 batches/sec.[2K|######--------------| 32.00%, 1617/3423 sec. train epoch 19, iter 320/1000, loss -0.018837, 0.20 batches/sec.[2K|#######-------------| 33.00%, 1667/3378 sec. train epoch 19, iter 330/1000, loss -0.026559, 0.20 batches/sec.[2K|#######-------------| 34.00%, 1718/3320 sec. train epoch 19, iter 340/1000, loss -0.024516, 0.20 batches/sec.[2K|#######-------------| 35.00%, 1768/3270 sec. train epoch 19, iter 350/1000, loss -0.033228, 0.20 batches/sec.[2K|#######-------------| 36.00%, 1818/3218 sec. train epoch 19, iter 360/1000, loss -0.027622, 0.20 batches/sec.[2K|#######-------------| 37.00%, 1869/3173 sec. train epoch 19, iter 370/1000, loss -0.036725, 0.20 batches/sec.[2K|########------------| 38.00%, 1919/3131 sec. train epoch 19, iter 380/1000, loss -0.040561, 0.20 batches/sec.[2K|########------------| 39.00%, 1969/3066 sec. train epoch 19, iter 390/1000, loss -0.045883, 0.20 batches/sec.[2K|########------------| 40.00%, 2020/3029 sec. train epoch 19, iter 400/1000, loss -0.041022, 0.20 batches/sec.[2K|########------------| 41.00%, 2070/2964 sec. train epoch 19, iter 410/1000, loss -0.035751, 0.20 batches/sec.[2K|########------------| 42.00%, 2121/2926 sec. train epoch 19, iter 420/1000, loss -0.030345, 0.20 batches/sec.[2K|#########-----------| 43.00%, 2171/2872 sec. train epoch 19, iter 430/1000, loss -0.025707, 0.20 batches/sec.[2K|#########-----------| 44.00%, 2221/2820 sec. train epoch 19, iter 440/1000, loss -0.024502, 0.20 batches/sec.[2K|#########-----------| 45.00%, 2272/2762 sec. train epoch 19, iter 450/1000, loss -0.023448, 0.20 batches/sec.[32m[2019-03-18 13:51:49 @logger.py:146][0m [2K|####################| 100.00%, 5042/0 sec. train epoch 19, iter 1000/1000, loss -0.040931, 0.20 batches/sec.
[32m[2019-03-18 13:51:53 @logger.py:43][0m [32;1mTrigger callback: [0mTrigger ModelSaver: Save model to model_logs/20190317111349169013_10-255-0-254_mine_NORMAL_wgan_gp_full_model_celeba_hq_256/snap-19000.
[2K|#########-----------| 46.00%, 2322/2714 sec. train epoch 19, iter 460/1000, loss -0.024865, 0.20 batches/sec.[2K|#########-----------| 47.00%, 2372/2672 sec. train epoch 19, iter 470/1000, loss -0.023219, 0.20 batches/sec.[2K|##########----------| 48.00%, 2423/2616 sec. train epoch 19, iter 480/1000, loss -0.019417, 0.20 batches/sec.[2K|##########----------| 49.00%, 2473/2572 sec. train epoch 19, iter 490/1000, loss -0.012062, 0.20 batches/sec.[2K|##########----------| 50.00%, 2523/2526 sec. train epoch 19, iter 500/1000, loss -0.012921, 0.20 batches/sec.[2K|##########----------| 51.00%, 2574/2467 sec. train epoch 19, iter 510/1000, loss -0.006955, 0.20 batches/sec.[2K|##########----------| 52.00%, 2624/2420 sec. train epoch 19, iter 520/1000, loss -0.004030, 0.20 batches/sec.[2K|###########---------| 53.00%, 2674/2362 sec. train epoch 19, iter 530/1000, loss -0.010294, 0.20 batches/sec.[2K|###########---------| 54.00%, 2725/2319 sec. train epoch 19, iter 540/1000, loss -0.010360, 0.20 batches/sec.[2K|###########---------| 55.00%, 2775/2265 sec. train epoch 19, iter 550/1000, loss -0.007543, 0.20 batches/sec.[2K|###########---------| 56.00%, 2826/2213 sec. train epoch 19, iter 560/1000, loss -0.010440, 0.20 batches/sec.[2K|###########---------| 57.00%, 2876/2172 sec. train epoch 19, iter 570/1000, loss -0.015973, 0.20 batches/sec.[2K|############--------| 58.00%, 2926/2115 sec. train epoch 19, iter 580/1000, loss -0.016182, 0.20 batches/sec.[2K|############--------| 59.00%, 2977/2067 sec. train epoch 19, iter 590/1000, loss -0.015303, 0.20 batches/sec.[2K|############--------| 60.00%, 3027/2013 sec. train epoch 19, iter 600/1000, loss -0.022318, 0.20 batches/sec.[2K|############--------| 61.00%, 3078/1966 sec. train epoch 19, iter 610/1000, loss -0.022738, 0.20 batches/sec.[2K|############--------| 62.00%, 3128/1917 sec. train epoch 19, iter 620/1000, loss -0.023284, 0.20 batches/sec.[2K|#############-------| 63.00%, 3178/1859 sec. train epoch 19, iter 630/1000, loss -0.022223, 0.20 batches/sec.[2K|#############-------| 64.00%, 3229/1815 sec. train epoch 19, iter 640/1000, loss -0.025111, 0.20 batches/sec.[2K|#############-------| 65.00%, 3279/1760 sec. train epoch 19, iter 650/1000, loss -0.027559, 0.20 batches/sec.[2K|#############-------| 66.00%, 3329/1714 sec. train epoch 19, iter 660/1000, loss -0.023275, 0.20 batches/sec.[2K|#############-------| 67.00%, 3380/1663 sec. train epoch 19, iter 670/1000, loss -0.019585, 0.20 batches/sec.[2K|##############------| 68.00%, 3430/1612 sec. train epoch 19, iter 680/1000, loss -0.014539, 0.20 batches/sec.[2K|##############------| 69.00%, 3481/1565 sec. train epoch 19, iter 690/1000, loss -0.016156, 0.20 batches/sec.[2K|##############------| 70.00%, 3531/1510 sec. train epoch 19, iter 700/1000, loss -0.018969, 0.20 batches/sec.[2K|##############------| 71.00%, 3581/1461 sec. train epoch 19, iter 710/1000, loss -0.020718, 0.20 batches/sec.[2K|##############------| 72.00%, 3632/1410 sec. train epoch 19, iter 720/1000, loss -0.019118, 0.20 batches/sec.[2K|###############-----| 73.00%, 3682/1358 sec. train epoch 19, iter 730/1000, loss -0.022781, 0.20 batches/sec.[2K|###############-----| 74.00%, 3732/1312 sec. train epoch 19, iter 740/1000, loss -0.024490, 0.20 batches/sec.[2K|###############-----| 75.00%, 3783/1257 sec. train epoch 19, iter 750/1000, loss -0.025938, 0.20 batches/sec.[2K|###############-----| 76.00%, 3833/1209 sec. train epoch 19, iter 760/1000, loss -0.026603, 0.20 batches/sec.[2K|###############-----| 77.00%, 3883/1159 sec. train epoch 19, iter 770/1000, loss -0.025987, 0.20 batches/sec.[2K|################----| 78.00%, 3934/1108 sec. train epoch 19, iter 780/1000, loss -0.025750, 0.20 batches/sec.[2K|################----| 79.00%, 3984/1058 sec. train epoch 19, iter 790/1000, loss -0.023930, 0.20 batches/sec.[2K|################----| 80.00%, 4035/1007 sec. train epoch 19, iter 800/1000, loss -0.024630, 0.20 batches/sec.[2K|################----| 81.00%, 4085/959 sec. train epoch 19, iter 810/1000, loss -0.025837, 0.20 batches/sec.[2K|################----| 82.00%, 4135/907 sec. train epoch 19, iter 820/1000, loss -0.026554, 0.20 batches/sec.[2K|#################---| 83.00%, 4186/857 sec. train epoch 19, iter 830/1000, loss -0.030195, 0.20 batches/sec.[2K|#################---| 84.00%, 4236/806 sec. train epoch 19, iter 840/1000, loss -0.032373, 0.20 batches/sec.[2K|#################---| 85.00%, 4286/754 sec. train epoch 19, iter 850/1000, loss -0.032358, 0.20 batches/sec.[2K|#################---| 86.00%, 4337/706 sec. train epoch 19, iter 860/1000, loss -0.036531, 0.20 batches/sec.[2K|#################---| 87.00%, 4387/653 sec. train epoch 19, iter 870/1000, loss -0.038613, 0.20 batches/sec.[2K|##################--| 88.00%, 4438/605 sec. train epoch 19, iter 880/1000, loss -0.040593, 0.20 batches/sec.[2K|##################--| 89.00%, 4488/553 sec. train epoch 19, iter 890/1000, loss -0.041684, 0.20 batches/sec.[2K|##################--| 90.00%, 4538/502 sec. train epoch 19, iter 900/1000, loss -0.042231, 0.20 batches/sec.[2K|##################--| 91.00%, 4588/453 sec. train epoch 19, iter 910/1000, loss -0.040016, 0.20 batches/sec.[2K|##################--| 92.00%, 4639/402 sec. train epoch 19, iter 920/1000, loss -0.038504, 0.20 batches/sec.[2K|###################-| 93.00%, 4689/353 sec. train epoch 19, iter 930/1000, loss -0.039245, 0.20 batches/sec.[2K|###################-| 94.00%, 4739/302 sec. train epoch 19, iter 940/1000, loss -0.037635, 0.20 batches/sec.[2K|###################-| 95.00%, 4790/252 sec. train epoch 19, iter 950/1000, loss -0.038926, 0.20 batches/sec.[2K|###################-| 96.00%, 4840/202 sec. train epoch 19, iter 960/1000, loss -0.037479, 0.20 batches/sec.[2K|###################-| 97.00%, 4890/151 sec. train epoch 19, iter 970/1000, loss -0.037268, 0.20 batches/sec.[2K|####################| 98.00%, 4941/101 sec. train epoch 19, iter 980/1000, loss -0.039375, 0.20 batches/sec.[2K|####################| 99.00%, 4991/50 sec. train epoch 19, iter 990/1000, loss -0.039988, 0.20 batches/sec.[2K|--------------------| 1.00%, 55/5459 sec. train epoch 20, iter 10/1000, loss 0.077604, 0.21 batches/sec.[2K|--------------------| 2.00%, 105/4925 sec. train epoch 20, iter 20/1000, loss 0.067884, 0.20 batches/sec.[2K|#-------------------| 3.00%, 156/4892 sec. train epoch 20, iter 30/1000, loss 0.080022, 0.20 batches/sec.[2K|#-------------------| 4.00%, 206/4830 sec. train epoch 20, iter 40/1000, loss -0.029401, 0.20 batches/sec.[2K|#-------------------| 5.00%, 257/4784 sec. train epoch 20, iter 50/1000, loss -0.011736, 0.20 batches/sec.[2K|#-------------------| 6.00%, 307/4737 sec. train epoch 20, iter 60/1000, loss -0.033853, 0.20 batches/sec.[2K|#-------------------| 7.00%, 357/4677 sec. train epoch 20, iter 70/1000, loss -0.025070, 0.20 batches/sec.[2K|##------------------| 8.00%, 408/4642 sec. train epoch 20, iter 80/1000, loss -0.003045, 0.20 batches/sec.[2K|##------------------| 9.00%, 458/4579 sec. train epoch 20, iter 90/1000, loss -0.008867, 0.20 batches/sec.[2K|##------------------| 10.00%, 508/4537 sec. train epoch 20, iter 100/1000, loss -0.016346, 0.20 batches/sec.[2K|##------------------| 11.00%, 559/4474 sec. train epoch 20, iter 110/1000, loss -0.010663, 0.20 batches/sec.[2K|##------------------| 12.00%, 609/4438 sec. train epoch 20, iter 120/1000, loss -0.005089, 0.20 batches/sec.[2K|###-----------------| 13.00%, 660/4389 sec. train epoch 20, iter 130/1000, loss -0.000759, 0.20 batches/sec.[2K|###-----------------| 14.00%, 710/4320 sec. train epoch 20, iter 140/1000, loss -0.016361, 0.20 batches/sec.[2K|###-----------------| 15.00%, 760/4289 sec. train epoch 20, iter 150/1000, loss -0.024561, 0.20 batches/sec.[2K|###-----------------| 16.00%, 811/4228 sec. train epoch 20, iter 160/1000, loss -0.045915, 0.20 batches/sec.[2K|###-----------------| 17.00%, 861/4182 sec. train epoch 20, iter 170/1000, loss -0.053436, 0.20 batches/sec.[2K|####----------------| 18.00%, 911/4125 sec. train epoch 20, iter 180/1000, loss -0.053741, 0.20 batches/sec.[2K|####----------------| 19.00%, 962/4079 sec. train epoch 20, iter 190/1000, loss -0.055108, 0.20 batches/sec.[2K|####----------------| 20.00%, 1012/4038 sec. train epoch 20, iter 200/1000, loss -0.060986, 0.20 batches/sec.[2K|####----------------| 21.00%, 1062/3977 sec. train epoch 20, iter 210/1000, loss -0.059207, 0.20 batches/sec.[2K|####----------------| 22.00%, 1113/3930 sec. train epoch 20, iter 220/1000, loss -0.069748, 0.20 batches/sec.[2K|#####---------------| 23.00%, 1163/3879 sec. train epoch 20, iter 230/1000, loss -0.074674, 0.20 batches/sec.[2K|#####---------------| 24.00%, 1213/3825 sec. train epoch 20, iter 240/1000, loss -0.069433, 0.20 batches/sec.[2K|#####---------------| 25.00%, 1264/3785 sec. train epoch 20, iter 250/1000, loss -0.069562, 0.20 batches/sec.[2K|#####---------------| 26.00%, 1314/3720 sec. train epoch 20, iter 260/1000, loss -0.048935, 0.20 batches/sec.[2K|#####---------------| 27.00%, 1365/3675 sec. train epoch 20, iter 270/1000, loss -0.042676, 0.20 batches/sec.[2K|######--------------| 28.00%, 1415/3627 sec. train epoch 20, iter 280/1000, loss -0.032910, 0.20 batches/sec.[2K|######--------------| 29.00%, 1465/3577 sec. train epoch 20, iter 290/1000, loss -0.028214, 0.20 batches/sec.[2K|######--------------| 30.00%, 1516/3528 sec. train epoch 20, iter 300/1000, loss -0.025497, 0.20 batches/sec.[2K|######--------------| 31.00%, 1566/3472 sec. train epoch 20, iter 310/1000, loss -0.021226, 0.20 batches/sec.[2K|######--------------| 32.00%, 1616/3430 sec. train epoch 20, iter 320/1000, loss -0.028533, 0.20 batches/sec.[2K|#######-------------| 33.00%, 1667/3378 sec. train epoch 20, iter 330/1000, loss -0.029419, 0.20 batches/sec.[2K|#######-------------| 34.00%, 1717/3332 sec. train epoch 20, iter 340/1000, loss -0.027007, 0.20 batches/sec.[2K|#######-------------| 35.00%, 1768/3273 sec. train epoch 20, iter 350/1000, loss -0.029531, 0.20 batches/sec.[2K|#######-------------| 36.00%, 1818/3212 sec. train epoch 20, iter 360/1000, loss -0.025075, 0.20 batches/sec.[2K|#######-------------| 37.00%, 1868/3177 sec. train epoch 20, iter 370/1000, loss -0.014059, 0.20 batches/sec.[2K|########------------| 38.00%, 1919/3124 sec. train epoch 20, iter 380/1000, loss -0.014636, 0.20 batches/sec.[2K|########------------| 39.00%, 1969/3082 sec. train epoch 20, iter 390/1000, loss -0.014982, 0.20 batches/sec.[2K|########------------| 40.00%, 2020/3025 sec. train epoch 20, iter 400/1000, loss -0.002273, 0.20 batches/sec.[2K|########------------| 41.00%, 2070/2969 sec. train epoch 20, iter 410/1000, loss -0.004719, 0.20 batches/sec.[2K|########------------| 42.00%, 2120/2926 sec. train epoch 20, iter 420/1000, loss -0.004844, 0.20 batches/sec.[2K|#########-----------| 43.00%, 2171/2866 sec. train epoch 20, iter 430/1000, loss -0.012764, 0.20 batches/sec.[2K|#########-----------| 44.00%, 2221/2829 sec. train epoch 20, iter 440/1000, loss -0.015337, 0.20 batches/sec.[2K|#########-----------| 45.00%, 2272/2771 sec. train epoch 20, iter 450/1000, loss -0.011175, 0.20 batches/sec.[2K|#########-----------| 46.00%, 2322/2716 sec. train epoch 20, iter 460/1000, loss -0.018196, 0.20 batches/sec.[2K|#########-----------| 47.00%, 2372/2673 sec. train epoch 20, iter 470/1000, loss -0.025023, 0.20 batches/sec.[2K|##########----------| 48.00%, 2423/2613 sec. train epoch 20, iter 480/1000, loss -0.022262, 0.20 batches/sec.[2K|##########----------| 49.00%, 2473/2571 sec. train epoch 20, iter 490/1000, loss -0.023404, 0.20 batches/sec.[2K|##########----------| 50.00%, 2523/2518 sec. train epoch 20, iter 500/1000, loss -0.020189, 0.20 batches/sec.[2K|##########----------| 51.00%, 2574/2468 sec. train epoch 20, iter 510/1000, loss -0.022466, 0.20 batches/sec.[2K|##########----------| 52.00%, 2624/2419 sec. train epoch 20, iter 520/1000, loss -0.019460, 0.20 batches/sec.[2K|###########---------| 53.00%, 2674/2367 sec. train epoch 20, iter 530/1000, loss -0.017134, 0.20 batches/sec.[2K|###########---------| 54.00%, 2725/2319 sec. train epoch 20, iter 540/1000, loss -0.020051, 0.20 batches/sec.[2K|###########---------| 55.00%, 2775/2266 sec. train epoch 20, iter 550/1000, loss -0.017553, 0.20 batches/sec.[2K|###########---------| 56.00%, 2826/2214 sec. train epoch 20, iter 560/1000, loss -0.013794, 0.20 batches/sec.[2K|###########---------| 57.00%, 2876/2162 sec. train epoch 20, iter 570/1000, loss -0.009222, 0.20 batches/sec.[2K|############--------| 58.00%, 2926/2117 sec. train epoch 20, iter 580/1000, loss -0.000477, 0.20 batches/sec.[2K|############--------| 59.00%, 2977/2064 sec. train epoch 20, iter 590/1000, loss 0.002865, 0.20 batches/sec.[2K|############--------| 60.00%, 3027/2013 sec. train epoch 20, iter 600/1000, loss -0.002168, 0.20 batches/sec.[2K|############--------| 61.00%, 3077/1968 sec. train epoch 20, iter 610/1000, loss -0.003676, 0.20 batches/sec.[2K|############--------| 62.00%, 3128/1912 sec. train epoch 20, iter 620/1000, loss -0.004279, 0.20 batches/sec.[2K|#############-------| 63.00%, 3178/1866 sec. train epoch 20, iter 630/1000, loss -0.001119, 0.20 batches/sec.[2K|#############-------| 64.00%, 3229/1815 sec. train epoch 20, iter 640/1000, loss 0.000527, 0.20 batches/sec.[2K|#############-------| 65.00%, 3279/1761 sec. train epoch 20, iter 650/1000, loss 0.005287, 0.20 batches/sec.[2K|#############-------| 66.00%, 3329/1710 sec. train epoch 20, iter 660/1000, loss 0.006659, 0.20 batches/sec.[2K|#############-------| 67.00%, 3379/1659 sec. train epoch 20, iter 670/1000, loss 0.011081, 0.20 batches/sec.[2K|##############------| 68.00%, 3430/1612 sec. train epoch 20, iter 680/1000, loss 0.012145, 0.20 batches/sec.[2K|##############------| 69.00%, 3480/1564 sec. train epoch 20, iter 690/1000, loss 0.018093, 0.20 batches/sec.[2K|##############------| 70.00%, 3531/1511 sec. train epoch 20, iter 700/1000, loss 0.019392, 0.20 batches/sec.[2K|##############------| 71.00%, 3581/1462 sec. train epoch 20, iter 710/1000, loss 0.022842, 0.20 batches/sec.[2K|##############------| 72.00%, 3631/1411 sec. train epoch 20, iter 720/1000, loss 0.023098, 0.20 batches/sec.[2K|###############-----| 73.00%, 3682/1363 sec. train epoch 20, iter 730/1000, loss 0.022095, 0.20 batches/sec.[2K|###############-----| 74.00%, 3732/1312 sec. train epoch 20, iter 740/1000, loss 0.021051, 0.20 batches/sec.[2K|###############-----| 75.00%, 3783/1259 sec. train epoch 20, iter 750/1000, loss 0.019935, 0.20 batches/sec.[2K|###############-----| 76.00%, 3833/1211 sec. train epoch 20, iter 760/1000, loss 0.021689, 0.20 batches/sec.[2K|###############-----| 77.00%, 3883/1157 sec. train epoch 20, iter 770/1000, loss 0.025455, 0.20 batches/sec.[2K|################----| 78.00%, 3934/1110 sec. train epoch 20, iter 780/1000, loss 0.029399, 0.20 batches/sec.[2K|################----| 79.00%, 3984/1060 sec. train epoch 20, iter 790/1000, loss 0.030353, 0.20 batches/sec.[2K|################----| 80.00%, 4035/1008 sec. train epoch 20, iter 800/1000, loss 0.031693, 0.20 batches/sec.[2K|################----| 81.00%, 4085/956 sec. train epoch 20, iter 810/1000, loss 0.033441, 0.20 batches/sec.[2K|################----| 82.00%, 4135/905 sec. train epoch 20, iter 820/1000, loss 0.034900, 0.20 batches/sec.[2K|#################---| 83.00%, 4186/856 sec. train epoch 20, iter 830/1000, loss 0.032928, 0.20 batches/sec.[2K|#################---| 84.00%, 4236/806 sec. train epoch 20, iter 840/1000, loss 0.033049, 0.20 batches/sec.[2K|#################---| 85.00%, 4286/755 sec. train epoch 20, iter 850/1000, loss 0.034309, 0.20 batches/sec.[2K|#################---| 86.00%, 4337/707 sec. train epoch 20, iter 860/1000, loss 0.035149, 0.20 batches/sec.[2K|#################---| 87.00%, 4387/654 sec. train epoch 20, iter 870/1000, loss 0.037011, 0.20 batches/sec.[2K|##################--| 88.00%, 4438/605 sec. train epoch 20, iter 880/1000, loss 0.037764, 0.20 batches/sec.[2K|##################--| 89.00%, 4488/554 sec. train epoch 20, iter 890/1000, loss 0.038784, 0.20 batches/sec.[2K|##################--| 90.00%, 4538/505 sec. train epoch 20, iter 900/1000, loss 0.042068, 0.20 batches/sec.[32m[2019-03-18 15:15:52 @logger.py:146][0m [2K|####################| 100.00%, 5042/0 sec. train epoch 20, iter 1000/1000, loss 0.046750, 0.20 batches/sec.
[32m[2019-03-18 15:15:55 @logger.py:43][0m [32;1mTrigger callback: [0mTrigger ModelSaver: Save model to model_logs/20190317111349169013_10-255-0-254_mine_NORMAL_wgan_gp_full_model_celeba_hq_256/snap-20000.
[2K|##################--| 91.00%, 4589/454 sec. train epoch 20, iter 910/1000, loss 0.042188, 0.20 batches/sec.[2K|##################--| 92.00%, 4639/403 sec. train epoch 20, iter 920/1000, loss 0.039459, 0.20 batches/sec.[2K|###################-| 93.00%, 4690/353 sec. train epoch 20, iter 930/1000, loss 0.039631, 0.20 batches/sec.[2K|###################-| 94.00%, 4740/302 sec. train epoch 20, iter 940/1000, loss 0.038658, 0.20 batches/sec.[2K|###################-| 95.00%, 4790/252 sec. train epoch 20, iter 950/1000, loss 0.040681, 0.20 batches/sec.[2K|###################-| 96.00%, 4841/202 sec. train epoch 20, iter 960/1000, loss 0.042206, 0.20 batches/sec.[2K|###################-| 97.00%, 4891/151 sec. train epoch 20, iter 970/1000, loss 0.043080, 0.20 batches/sec.[2K|####################| 98.00%, 4942/101 sec. train epoch 20, iter 980/1000, loss 0.041229, 0.20 batches/sec.[2K|####################| 99.00%, 4992/50 sec. train epoch 20, iter 990/1000, loss 0.044001, 0.20 batches/sec.[2K|--------------------| 1.00%, 55/5454 sec. train epoch 21, iter 10/1000, loss 0.368519, 0.21 batches/sec.[2K|--------------------| 2.00%, 105/4933 sec. train epoch 21, iter 20/1000, loss 0.447921, 0.20 batches/sec.[2K|#-------------------| 3.00%, 156/4897 sec. train epoch 21, iter 30/1000, loss 0.392267, 0.20 batches/sec.[2K|#-------------------| 4.00%, 206/4829 sec. train epoch 21, iter 40/1000, loss 0.388500, 0.20 batches/sec.[2K|#-------------------| 5.00%, 257/4792 sec. train epoch 21, iter 50/1000, loss 0.343907, 0.20 batches/sec.[2K|#-------------------| 6.00%, 307/4728 sec. train epoch 21, iter 60/1000, loss 0.347192, 0.20 batches/sec.[2K|#-------------------| 7.00%, 357/4685 sec. train epoch 21, iter 70/1000, loss 0.259851, 0.20 batches/sec.[2K|##------------------| 8.00%, 408/4638 sec. train epoch 21, iter 80/1000, loss 0.279417, 0.20 batches/sec.[2K|##------------------| 9.00%, 458/4580 sec. train epoch 21, iter 90/1000, loss 0.287094, 0.20 batches/sec.[2K|##------------------| 10.00%, 508/4535 sec. train epoch 21, iter 100/1000, loss 0.262724, 0.20 batches/sec.[2K|##------------------| 11.00%, 559/4482 sec. train epoch 21, iter 110/1000, loss 0.230071, 0.20 batches/sec.[2K|##------------------| 12.00%, 609/4436 sec. train epoch 21, iter 120/1000, loss 0.224743, 0.20 batches/sec.[2K|###-----------------| 13.00%, 660/4385 sec. train epoch 21, iter 130/1000, loss 0.203856, 0.20 batches/sec.[2K|###-----------------| 14.00%, 710/4328 sec. train epoch 21, iter 140/1000, loss 0.188929, 0.20 batches/sec.[2K|###-----------------| 15.00%, 760/4284 sec. train epoch 21, iter 150/1000, loss 0.169847, 0.20 batches/sec.[2K|###-----------------| 16.00%, 811/4223 sec. train epoch 21, iter 160/1000, loss 0.161493, 0.20 batches/sec.[2K|###-----------------| 17.00%, 861/4180 sec. train epoch 21, iter 170/1000, loss 0.147590, 0.20 batches/sec.[2K|####----------------| 18.00%, 911/4128 sec. train epoch 21, iter 180/1000, loss 0.156484, 0.20 batches/sec.[2K|####----------------| 19.00%, 962/4071 sec. train epoch 21, iter 190/1000, loss 0.144042, 0.20 batches/sec.[2K|####----------------| 20.00%, 1012/4032 sec. train epoch 21, iter 200/1000, loss 0.141676, 0.20 batches/sec.[2K|####----------------| 21.00%, 1062/3981 sec. train epoch 21, iter 210/1000, loss 0.130325, 0.20 batches/sec.[2K|####----------------| 22.00%, 1113/3934 sec. train epoch 21, iter 220/1000, loss 0.117480, 0.20 batches/sec.[2K|#####---------------| 23.00%, 1163/3879 sec. train epoch 21, iter 230/1000, loss 0.121676, 0.20 batches/sec.[2K|#####---------------| 24.00%, 1214/3836 sec. train epoch 21, iter 240/1000, loss 0.113537, 0.20 batches/sec.[2K|#####---------------| 25.00%, 1264/3780 sec. train epoch 21, iter 250/1000, loss 0.093095, 0.20 batches/sec.[2K|#####---------------| 26.00%, 1314/3726 sec. train epoch 21, iter 260/1000, loss 0.095846, 0.20 batches/sec.[2K|#####---------------| 27.00%, 1365/3681 sec. train epoch 21, iter 270/1000, loss 0.088332, 0.20 batches/sec.[2K|######--------------| 28.00%, 1415/3619 sec. train epoch 21, iter 280/1000, loss 0.084062, 0.20 batches/sec.[2K|######--------------| 29.00%, 1465/3574 sec. train epoch 21, iter 290/1000, loss 0.085235, 0.20 batches/sec.[2K|######--------------| 30.00%, 1516/3528 sec. train epoch 21, iter 300/1000, loss 0.080310, 0.20 batches/sec.[2K|######--------------| 31.00%, 1566/3475 sec. train epoch 21, iter 310/1000, loss 0.084167, 0.20 batches/sec.[2K|######--------------| 32.00%, 1617/3429 sec. train epoch 21, iter 320/1000, loss 0.083984, 0.20 batches/sec.[2K|#######-------------| 33.00%, 1667/3374 sec. train epoch 21, iter 330/1000, loss 0.083141, 0.20 batches/sec.[2K|#######-------------| 34.00%, 1717/3325 sec. train epoch 21, iter 340/1000, loss 0.082840, 0.20 batches/sec.[2K|#######-------------| 35.00%, 1768/3276 sec. train epoch 21, iter 350/1000, loss 0.087854, 0.20 batches/sec.[2K|#######-------------| 36.00%, 1818/3221 sec. train epoch 21, iter 360/1000, loss 0.095970, 0.20 batches/sec.[2K|#######-------------| 37.00%, 1869/3176 sec. train epoch 21, iter 370/1000, loss 0.096798, 0.20 batches/sec.[2K|########------------| 38.00%, 1919/3118 sec. train epoch 21, iter 380/1000, loss 0.095374, 0.20 batches/sec.[2K|########------------| 39.00%, 1969/3075 sec. train epoch 21, iter 390/1000, loss 0.097349, 0.20 batches/sec.[2K|########------------| 40.00%, 2020/3022 sec. train epoch 21, iter 400/1000, loss 0.105924, 0.20 batches/sec.[2K|########------------| 41.00%, 2070/2971 sec. train epoch 21, iter 410/1000, loss 0.111073, 0.20 batches/sec.[2K|########------------| 42.00%, 2120/2922 sec. train epoch 21, iter 420/1000, loss 0.114602, 0.20 batches/sec.[2K|#########-----------| 43.00%, 2171/2870 sec. train epoch 21, iter 430/1000, loss 0.117494, 0.20 batches/sec.[2K|#########-----------| 44.00%, 2221/2815 sec. train epoch 21, iter 440/1000, loss 0.117376, 0.20 batches/sec.[2K|#########-----------| 45.00%, 2271/2764 sec. train epoch 21, iter 450/1000, loss 0.113658, 0.20 batches/sec.[2K|#########-----------| 46.00%, 2321/2715 sec. train epoch 21, iter 460/1000, loss 0.114402, 0.20 batches/sec.[2K|#########-----------| 47.00%, 2372/2670 sec. train epoch 21, iter 470/1000, loss 0.114050, 0.20 batches/sec.[2K|##########----------| 48.00%, 2422/2618 sec. train epoch 21, iter 480/1000, loss 0.110554, 0.20 batches/sec.[2K|##########----------| 49.00%, 2473/2575 sec. train epoch 21, iter 490/1000, loss 0.110124, 0.20 batches/sec.[2K|##########----------| 50.00%, 2523/2514 sec. train epoch 21, iter 500/1000, loss 0.106760, 0.20 batches/sec.[2K|##########----------| 51.00%, 2573/2468 sec. train epoch 21, iter 510/1000, loss 0.105391, 0.20 batches/sec.[2K|##########----------| 52.00%, 2624/2419 sec. train epoch 21, iter 520/1000, loss 0.106796, 0.20 batches/sec.[2K|###########---------| 53.00%, 2674/2367 sec. train epoch 21, iter 530/1000, loss 0.107395, 0.20 batches/sec.[2K|###########---------| 54.00%, 2724/2317 sec. train epoch 21, iter 540/1000, loss 0.111083, 0.20 batches/sec.[2K|###########---------| 55.00%, 2775/2264 sec. train epoch 21, iter 550/1000, loss 0.105628, 0.20 batches/sec.[2K|###########---------| 56.00%, 2825/2216 sec. train epoch 21, iter 560/1000, loss 0.107009, 0.20 batches/sec.[2K|###########---------| 57.00%, 2876/2167 sec. train epoch 21, iter 570/1000, loss 0.108356, 0.20 batches/sec.[2K|############--------| 58.00%, 2926/2117 sec. train epoch 21, iter 580/1000, loss 0.109573, 0.20 batches/sec.[2K|############--------| 59.00%, 2976/2070 sec. train epoch 21, iter 590/1000, loss 0.112201, 0.20 batches/sec.[2K|############--------| 60.00%, 3027/2011 sec. train epoch 21, iter 600/1000, loss 0.115544, 0.20 batches/sec.[2K|############--------| 61.00%, 3077/1966 sec. train epoch 21, iter 610/1000, loss 0.110879, 0.20 batches/sec.[2K|############--------| 62.00%, 3127/1912 sec. train epoch 21, iter 620/1000, loss 0.106489, 0.20 batches/sec.[2K|#############-------| 63.00%, 3178/1867 sec. train epoch 21, iter 630/1000, loss 0.105837, 0.20 batches/sec.[2K|#############-------| 64.00%, 3228/1813 sec. train epoch 21, iter 640/1000, loss 0.105151, 0.20 batches/sec.[32m[2019-03-18 16:39:53 @logger.py:146][0m [2K|####################| 100.00%, 5041/0 sec. train epoch 21, iter 1000/1000, loss 0.121353, 0.20 batches/sec.
[32m[2019-03-18 16:39:57 @logger.py:43][0m [32;1mTrigger callback: [0mTrigger ModelSaver: Save model to model_logs/20190317111349169013_10-255-0-254_mine_NORMAL_wgan_gp_full_model_celeba_hq_256/snap-21000.
[2K|#############-------| 65.00%, 3279/1760 sec. train epoch 21, iter 650/1000, loss 0.104999, 0.20 batches/sec.[2K|#############-------| 66.00%, 3329/1717 sec. train epoch 21, iter 660/1000, loss 0.105660, 0.20 batches/sec.[2K|#############-------| 67.00%, 3379/1660 sec. train epoch 21, iter 670/1000, loss 0.103761, 0.20 batches/sec.[2K|##############------| 68.00%, 3430/1611 sec. train epoch 21, iter 680/1000, loss 0.104531, 0.20 batches/sec.[2K|##############------| 69.00%, 3480/1560 sec. train epoch 21, iter 690/1000, loss 0.102962, 0.20 batches/sec.[2K|##############------| 70.00%, 3530/1508 sec. train epoch 21, iter 700/1000, loss 0.106271, 0.20 batches/sec.[2K|##############------| 71.00%, 3581/1462 sec. train epoch 21, iter 710/1000, loss 0.111106, 0.20 batches/sec.[2K|##############------| 72.00%, 3631/1407 sec. train epoch 21, iter 720/1000, loss 0.113279, 0.20 batches/sec.[2K|###############-----| 73.00%, 3681/1362 sec. train epoch 21, iter 730/1000, loss 0.113956, 0.20 batches/sec.[2K|###############-----| 74.00%, 3732/1310 sec. train epoch 21, iter 740/1000, loss 0.114395, 0.20 batches/sec.[2K|###############-----| 75.00%, 3782/1259 sec. train epoch 21, iter 750/1000, loss 0.112804, 0.20 batches/sec.[2K|###############-----| 76.00%, 3832/1208 sec. train epoch 21, iter 760/1000, loss 0.112600, 0.20 batches/sec.[2K|###############-----| 77.00%, 3883/1159 sec. train epoch 21, iter 770/1000, loss 0.110264, 0.20 batches/sec.[2K|################----| 78.00%, 3933/1109 sec. train epoch 21, iter 780/1000, loss 0.110923, 0.20 batches/sec.[2K|################----| 79.00%, 3984/1057 sec. train epoch 21, iter 790/1000, loss 0.110617, 0.20 batches/sec.[2K|################----| 80.00%, 4034/1008 sec. train epoch 21, iter 800/1000, loss 0.108853, 0.20 batches/sec.[2K|################----| 81.00%, 4084/959 sec. train epoch 21, iter 810/1000, loss 0.108043, 0.20 batches/sec.[2K|################----| 82.00%, 4135/905 sec. train epoch 21, iter 820/1000, loss 0.107153, 0.20 batches/sec.[2K|#################---| 83.00%, 4185/857 sec. train epoch 21, iter 830/1000, loss 0.105185, 0.20 batches/sec.[2K|#################---| 84.00%, 4235/805 sec. train epoch 21, iter 840/1000, loss 0.103998, 0.20 batches/sec.[2K|#################---| 85.00%, 4286/756 sec. train epoch 21, iter 850/1000, loss 0.105465, 0.20 batches/sec.[2K|#################---| 86.00%, 4336/705 sec. train epoch 21, iter 860/1000, loss 0.103971, 0.20 batches/sec.[2K|#################---| 87.00%, 4387/655 sec. train epoch 21, iter 870/1000, loss 0.105237, 0.20 batches/sec.[2K|##################--| 88.00%, 4437/605 sec. train epoch 21, iter 880/1000, loss 0.103740, 0.20 batches/sec.[2K|##################--| 89.00%, 4487/554 sec. train epoch 21, iter 890/1000, loss 0.106217, 0.20 batches/sec.[2K|##################--| 90.00%, 4538/504 sec. train epoch 21, iter 900/1000, loss 0.108644, 0.20 batches/sec.[2K|##################--| 91.00%, 4588/453 sec. train epoch 21, iter 910/1000, loss 0.113043, 0.20 batches/sec.[2K|##################--| 92.00%, 4638/403 sec. train epoch 21, iter 920/1000, loss 0.113318, 0.20 batches/sec.[2K|###################-| 93.00%, 4689/354 sec. train epoch 21, iter 930/1000, loss 0.114255, 0.20 batches/sec.[2K|###################-| 94.00%, 4739/302 sec. train epoch 21, iter 940/1000, loss 0.113641, 0.20 batches/sec.[2K|###################-| 95.00%, 4790/252 sec. train epoch 21, iter 950/1000, loss 0.111258, 0.20 batches/sec.[2K|###################-| 96.00%, 4840/201 sec. train epoch 21, iter 960/1000, loss 0.112327, 0.20 batches/sec.[2K|###################-| 97.00%, 4890/151 sec. train epoch 21, iter 970/1000, loss 0.114742, 0.20 batches/sec.[2K|####################| 98.00%, 4941/101 sec. train epoch 21, iter 980/1000, loss 0.116004, 0.20 batches/sec.[2K|####################| 99.00%, 4991/50 sec. train epoch 21, iter 990/1000, loss 0.118805, 0.20 batches/sec.[2K|--------------------| 1.00%, 55/5449 sec. train epoch 22, iter 10/1000, loss 0.474762, 0.21 batches/sec.[2K|--------------------| 2.00%, 105/4932 sec. train epoch 22, iter 20/1000, loss 0.347707, 0.20 batches/sec.[2K|#-------------------| 3.00%, 156/4881 sec. train epoch 22, iter 30/1000, loss 0.290750, 0.20 batches/sec.[2K|#-------------------| 4.00%, 206/4829 sec. train epoch 22, iter 40/1000, loss 0.216364, 0.20 batches/sec.[2K|#-------------------| 5.00%, 256/4787 sec. train epoch 22, iter 50/1000, loss 0.156680, 0.20 batches/sec.[2K|#-------------------| 6.00%, 307/4730 sec. train epoch 22, iter 60/1000, loss 0.132990, 0.20 batches/sec.[2K|#-------------------| 7.00%, 357/4683 sec. train epoch 22, iter 70/1000, loss 0.102815, 0.20 batches/sec.[2K|##------------------| 8.00%, 407/4630 sec. train epoch 22, iter 80/1000, loss 0.060459, 0.20 batches/sec.[2K|##------------------| 9.00%, 458/4577 sec. train epoch 22, iter 90/1000, loss 0.077621, 0.20 batches/sec.[2K|##------------------| 10.00%, 508/4532 sec. train epoch 22, iter 100/1000, loss 0.105254, 0.20 batches/sec.[2K|##------------------| 11.00%, 558/4470 sec. train epoch 22, iter 110/1000, loss 0.107541, 0.20 batches/sec.[2K|##------------------| 12.00%, 609/4435 sec. train epoch 22, iter 120/1000, loss 0.097937, 0.20 batches/sec.[2K|###-----------------| 13.00%, 659/4379 sec. train epoch 22, iter 130/1000, loss 0.093470, 0.20 batches/sec.[2K|###-----------------| 14.00%, 709/4336 sec. train epoch 22, iter 140/1000, loss 0.090400, 0.20 batches/sec.[2K|###-----------------| 15.00%, 760/4283 sec. train epoch 22, iter 150/1000, loss 0.109486, 0.20 batches/sec.[2K|###-----------------| 16.00%, 810/4227 sec. train epoch 22, iter 160/1000, loss 0.109881, 0.20 batches/sec.[2K|###-----------------| 17.00%, 861/4183 sec. train epoch 22, iter 170/1000, loss 0.120693, 0.20 batches/sec.[2K|####----------------| 18.00%, 911/4128 sec. train epoch 22, iter 180/1000, loss 0.123595, 0.20 batches/sec.[2K|####----------------| 19.00%, 961/4082 sec. train epoch 22, iter 190/1000, loss 0.128479, 0.20 batches/sec.[2K|####----------------| 20.00%, 1012/4038 sec. train epoch 22, iter 200/1000, loss 0.135516, 0.20 batches/sec.[2K|####----------------| 21.00%, 1062/3970 sec. train epoch 22, iter 210/1000, loss 0.138428, 0.20 batches/sec.[2K|####----------------| 22.00%, 1112/3932 sec. train epoch 22, iter 220/1000, loss 0.151739, 0.20 batches/sec.[2K|#####---------------| 23.00%, 1163/3877 sec. train epoch 22, iter 230/1000, loss 0.154881, 0.20 batches/sec.[2K|#####---------------| 24.00%, 1213/3830 sec. train epoch 22, iter 240/1000, loss 0.157092, 0.20 batches/sec.[2K|#####---------------| 25.00%, 1263/3774 sec. train epoch 22, iter 250/1000, loss 0.164862, 0.20 batches/sec.[2K|#####---------------| 26.00%, 1314/3718 sec. train epoch 22, iter 260/1000, loss 0.159859, 0.20 batches/sec.[2K|#####---------------| 27.00%, 1364/3682 sec. train epoch 22, iter 270/1000, loss 0.146257, 0.20 batches/sec.[2K|######--------------| 28.00%, 1414/3617 sec. train epoch 22, iter 280/1000, loss 0.149266, 0.20 batches/sec.[2K|######--------------| 29.00%, 1465/3574 sec. train epoch 22, iter 290/1000, loss 0.142801, 0.20 batches/sec.[2K|######--------------| 30.00%, 1515/3524 sec. train epoch 22, iter 300/1000, loss 0.140304, 0.20 batches/sec.[2K|######--------------| 31.00%, 1565/3474 sec. train epoch 22, iter 310/1000, loss 0.134486, 0.20 batches/sec.[2K|######--------------| 32.00%, 1616/3420 sec. train epoch 22, iter 320/1000, loss 0.130868, 0.20 batches/sec.[2K|#######-------------| 33.00%, 1666/3368 sec. train epoch 22, iter 330/1000, loss 0.123931, 0.20 batches/sec.[2K|#######-------------| 34.00%, 1716/3325 sec. train epoch 22, iter 340/1000, loss 0.122905, 0.20 batches/sec.[2K|#######-------------| 35.00%, 1767/3272 sec. train epoch 22, iter 350/1000, loss 0.106329, 0.20 batches/sec.[2K|#######-------------| 36.00%, 1817/3224 sec. train epoch 22, iter 360/1000, loss 0.093050, 0.20 batches/sec.[2K|#######-------------| 37.00%, 1867/3175 sec. train epoch 22, iter 370/1000, loss 0.093206, 0.20 batches/sec.[2K|########------------| 38.00%, 1918/3120 sec. train epoch 22, iter 380/1000, loss 0.095488, 0.20 batches/sec.[32m[2019-03-18 18:03:52 @logger.py:146][0m [2K|####################| 100.00%, 5039/0 sec. train epoch 22, iter 1000/1000, loss 0.102283, 0.20 batches/sec.
[32m[2019-03-18 18:03:56 @logger.py:43][0m [32;1mTrigger callback: [0mTrigger ModelSaver: Save model to model_logs/20190317111349169013_10-255-0-254_mine_NORMAL_wgan_gp_full_model_celeba_hq_256/snap-22000.
[2K|########------------| 39.00%, 1968/3074 sec. train epoch 22, iter 390/1000, loss 0.101738, 0.20 batches/sec.[2K|########------------| 40.00%, 2019/3021 sec. train epoch 22, iter 400/1000, loss 0.106038, 0.20 batches/sec.[2K|########------------| 41.00%, 2069/2973 sec. train epoch 22, iter 410/1000, loss 0.109881, 0.20 batches/sec.[2K|########------------| 42.00%, 2119/2922 sec. train epoch 22, iter 420/1000, loss 0.109417, 0.20 batches/sec.[2K|#########-----------| 43.00%, 2170/2868 sec. train epoch 22, iter 430/1000, loss 0.107903, 0.20 batches/sec.[2K|#########-----------| 44.00%, 2220/2822 sec. train epoch 22, iter 440/1000, loss 0.111807, 0.20 batches/sec.[2K|#########-----------| 45.00%, 2270/2769 sec. train epoch 22, iter 450/1000, loss 0.115633, 0.20 batches/sec.[2K|#########-----------| 46.00%, 2321/2716 sec. train epoch 22, iter 460/1000, loss 0.117095, 0.20 batches/sec.[2K|#########-----------| 47.00%, 2371/2672 sec. train epoch 22, iter 470/1000, loss 0.114319, 0.20 batches/sec.[2K|##########----------| 48.00%, 2421/2615 sec. train epoch 22, iter 480/1000, loss 0.114018, 0.20 batches/sec.[2K|##########----------| 49.00%, 2472/2567 sec. train epoch 22, iter 490/1000, loss 0.117115, 0.20 batches/sec.[2K|##########----------| 50.00%, 2522/2519 sec. train epoch 22, iter 500/1000, loss 0.118568, 0.20 batches/sec.[2K|##########----------| 51.00%, 2572/2472 sec. train epoch 22, iter 510/1000, loss 0.123278, 0.20 batches/sec.[2K|##########----------| 52.00%, 2623/2415 sec. train epoch 22, iter 520/1000, loss 0.124594, 0.20 batches/sec.[2K|###########---------| 53.00%, 2673/2369 sec. train epoch 22, iter 530/1000, loss 0.130226, 0.20 batches/sec.[2K|###########---------| 54.00%, 2724/2317 sec. train epoch 22, iter 540/1000, loss 0.125053, 0.20 batches/sec.[2K|###########---------| 55.00%, 2774/2265 sec. train epoch 22, iter 550/1000, loss 0.122630, 0.20 batches/sec.[2K|###########---------| 56.00%, 2824/2220 sec. train epoch 22, iter 560/1000, loss 0.122119, 0.20 batches/sec.[2K|###########---------| 57.00%, 2875/2165 sec. train epoch 22, iter 570/1000, loss 0.114801, 0.20 batches/sec.[2K|############--------| 58.00%, 2925/2115 sec. train epoch 22, iter 580/1000, loss 0.116084, 0.20 batches/sec.[2K|############--------| 59.00%, 2975/2068 sec. train epoch 22, iter 590/1000, loss 0.119402, 0.20 batches/sec.[2K|############--------| 60.00%, 3026/2011 sec. train epoch 22, iter 600/1000, loss 0.124042, 0.20 batches/sec.[2K|############--------| 61.00%, 3076/1964 sec. train epoch 22, iter 610/1000, loss 0.127056, 0.20 batches/sec.[2K|############--------| 62.00%, 3126/1912 sec. train epoch 22, iter 620/1000, loss 0.127936, 0.20 batches/sec.[2K|#############-------| 63.00%, 3177/1863 sec. train epoch 22, iter 630/1000, loss 0.127411, 0.20 batches/sec.[2K|#############-------| 64.00%, 3227/1810 sec. train epoch 22, iter 640/1000, loss 0.127394, 0.20 batches/sec.[2K|#############-------| 65.00%, 3277/1761 sec. train epoch 22, iter 650/1000, loss 0.126739, 0.20 batches/sec.[2K|#############-------| 66.00%, 3328/1713 sec. train epoch 22, iter 660/1000, loss 0.126703, 0.20 batches/sec.[2K|#############-------| 67.00%, 3378/1660 sec. train epoch 22, iter 670/1000, loss 0.127197, 0.20 batches/sec.[2K|##############------| 68.00%, 3428/1614 sec. train epoch 22, iter 680/1000, loss 0.125056, 0.20 batches/sec.[2K|##############------| 69.00%, 3479/1559 sec. train epoch 22, iter 690/1000, loss 0.129128, 0.20 batches/sec.[2K|##############------| 70.00%, 3529/1511 sec. train epoch 22, iter 700/1000, loss 0.128151, 0.20 batches/sec.[2K|##############------| 71.00%, 3579/1459 sec. train epoch 22, iter 710/1000, loss 0.128200, 0.20 batches/sec.[2K|##############------| 72.00%, 3630/1407 sec. train epoch 22, iter 720/1000, loss 0.127266, 0.20 batches/sec.[2K|###############-----| 73.00%, 3680/1359 sec. train epoch 22, iter 730/1000, loss 0.128543, 0.20 batches/sec.[2K|###############-----| 74.00%, 3730/1308 sec. train epoch 22, iter 740/1000, loss 0.124974, 0.20 batches/sec.[2K|###############-----| 75.00%, 3781/1261 sec. train epoch 22, iter 750/1000, loss 0.125538, 0.20 batches/sec.[2K|###############-----| 76.00%, 3831/1209 sec. train epoch 22, iter 760/1000, loss 0.124005, 0.20 batches/sec.[2K|###############-----| 77.00%, 3881/1157 sec. train epoch 22, iter 770/1000, loss 0.125471, 0.20 batches/sec.[2K|################----| 78.00%, 3932/1110 sec. train epoch 22, iter 780/1000, loss 0.125988, 0.20 batches/sec.[2K|################----| 79.00%, 3982/1056 sec. train epoch 22, iter 790/1000, loss 0.124246, 0.20 batches/sec.[2K|################----| 80.00%, 4033/1007 sec. train epoch 22, iter 800/1000, loss 0.123618, 0.20 batches/sec.[2K|################----| 81.00%, 4083/957 sec. train epoch 22, iter 810/1000, loss 0.121724, 0.20 batches/sec.[2K|################----| 82.00%, 4133/906 sec. train epoch 22, iter 820/1000, loss 0.120033, 0.20 batches/sec.[2K|#################---| 83.00%, 4184/858 sec. train epoch 22, iter 830/1000, loss 0.118564, 0.20 batches/sec.[2K|#################---| 84.00%, 4234/805 sec. train epoch 22, iter 840/1000, loss 0.117618, 0.20 batches/sec.[2K|#################---| 85.00%, 4284/756 sec. train epoch 22, iter 850/1000, loss 0.115992, 0.20 batches/sec.[2K|#################---| 86.00%, 4335/704 sec. train epoch 22, iter 860/1000, loss 0.116098, 0.20 batches/sec.[2K|#################---| 87.00%, 4385/654 sec. train epoch 22, iter 870/1000, loss 0.115489, 0.20 batches/sec.[2K|##################--| 88.00%, 4435/604 sec. train epoch 22, iter 880/1000, loss 0.112601, 0.20 batches/sec.[2K|##################--| 89.00%, 4486/552 sec. train epoch 22, iter 890/1000, loss 0.107594, 0.20 batches/sec.[2K|##################--| 90.00%, 4536/504 sec. train epoch 22, iter 900/1000, loss 0.107225, 0.20 batches/sec.[2K|##################--| 91.00%, 4586/453 sec. train epoch 22, iter 910/1000, loss 0.105656, 0.20 batches/sec.[2K|##################--| 92.00%, 4637/403 sec. train epoch 22, iter 920/1000, loss 0.102161, 0.20 batches/sec.[2K|###################-| 93.00%, 4687/352 sec. train epoch 22, iter 930/1000, loss 0.102273, 0.20 batches/sec.[2K|###################-| 94.00%, 4737/302 sec. train epoch 22, iter 940/1000, loss 0.101434, 0.20 batches/sec.[2K|###################-| 95.00%, 4788/252 sec. train epoch 22, iter 950/1000, loss 0.103270, 0.20 batches/sec.[2K|###################-| 96.00%, 4838/201 sec. train epoch 22, iter 960/1000, loss 0.102414, 0.20 batches/sec.[2K|###################-| 97.00%, 4888/151 sec. train epoch 22, iter 970/1000, loss 0.102259, 0.20 batches/sec.[2K|####################| 98.00%, 4939/101 sec. train epoch 22, iter 980/1000, loss 0.103246, 0.20 batches/sec.[2K|####################| 99.00%, 4989/50 sec. train epoch 22, iter 990/1000, loss 0.103408, 0.20 batches/sec.[2K|--------------------| 1.00%, 55/5452 sec. train epoch 23, iter 10/1000, loss -0.210109, 0.21 batches/sec.[2K|--------------------| 2.00%, 105/4934 sec. train epoch 23, iter 20/1000, loss -0.157256, 0.20 batches/sec.[2K|#-------------------| 3.00%, 156/4888 sec. train epoch 23, iter 30/1000, loss -0.044625, 0.20 batches/sec.[2K|#-------------------| 4.00%, 206/4832 sec. train epoch 23, iter 40/1000, loss -0.055236, 0.20 batches/sec.[2K|#-------------------| 5.00%, 257/4792 sec. train epoch 23, iter 50/1000, loss 0.032214, 0.20 batches/sec.[2K|#-------------------| 6.00%, 307/4728 sec. train epoch 23, iter 60/1000, loss 0.068135, 0.20 batches/sec.[2K|#-------------------| 7.00%, 357/4686 sec. train epoch 23, iter 70/1000, loss 0.102824, 0.20 batches/sec.[2K|##------------------| 8.00%, 408/4624 sec. train epoch 23, iter 80/1000, loss 0.085201, 0.20 batches/sec.[2K|##------------------| 9.00%, 458/4579 sec. train epoch 23, iter 90/1000, loss 0.078989, 0.20 batches/sec.[2K|##------------------| 10.00%, 508/4541 sec. train epoch 23, iter 100/1000, loss 0.072790, 0.20 batches/sec.[2K|##------------------| 11.00%, 559/4475 sec. train epoch 23, iter 110/1000, loss 0.085957, 0.20 batches/sec.[2K|##------------------| 12.00%, 609/4427 sec. train epoch 23, iter 120/1000, loss 0.071238, 0.20 batches/sec.[2K|###-----------------| 13.00%, 659/4373 sec. train epoch 23, iter 130/1000, loss 0.067267, 0.20 batches/sec.[2K|###-----------------| 14.00%, 710/4336 sec. train epoch 23, iter 140/1000, loss 0.070099, 0.20 batches/sec.[2K|###-----------------| 15.00%, 760/4285 sec. train epoch 23, iter 150/1000, loss 0.077647, 0.20 batches/sec.[2K|###-----------------| 16.00%, 810/4225 sec. train epoch 23, iter 160/1000, loss 0.081097, 0.20 batches/sec.[2K|###-----------------| 17.00%, 861/4187 sec. train epoch 23, iter 170/1000, loss 0.081804, 0.20 batches/sec.[2K|####----------------| 18.00%, 911/4122 sec. train epoch 23, iter 180/1000, loss 0.086161, 0.20 batches/sec.[2K|####----------------| 19.00%, 961/4086 sec. train epoch 23, iter 190/1000, loss 0.095240, 0.20 batches/sec.[2K|####----------------| 20.00%, 1012/4031 sec. train epoch 23, iter 200/1000, loss 0.107960, 0.20 batches/sec.[2K|####----------------| 21.00%, 1062/3987 sec. train epoch 23, iter 210/1000, loss 0.118227, 0.20 batches/sec.[2K|####----------------| 22.00%, 1113/3925 sec. train epoch 23, iter 220/1000, loss 0.113340, 0.20 batches/sec.[2K|#####---------------| 23.00%, 1163/3879 sec. train epoch 23, iter 230/1000, loss 0.109156, 0.20 batches/sec.[2K|#####---------------| 24.00%, 1213/3833 sec. train epoch 23, iter 240/1000, loss 0.107953, 0.20 batches/sec.[2K|#####---------------| 25.00%, 1264/3777 sec. train epoch 23, iter 250/1000, loss 0.111978, 0.20 batches/sec.[2K|#####---------------| 26.00%, 1314/3729 sec. train epoch 23, iter 260/1000, loss 0.108933, 0.20 batches/sec.[2K|#####---------------| 27.00%, 1365/3680 sec. train epoch 23, iter 270/1000, loss 0.110649, 0.20 batches/sec.[2K|######--------------| 28.00%, 1415/3628 sec. train epoch 23, iter 280/1000, loss 0.105828, 0.20 batches/sec.[2K|######--------------| 29.00%, 1465/3583 sec. train epoch 23, iter 290/1000, loss 0.105686, 0.20 batches/sec.[2K|######--------------| 30.00%, 1516/3524 sec. train epoch 23, iter 300/1000, loss 0.101789, 0.20 batches/sec.[2K|######--------------| 31.00%, 1566/3477 sec. train epoch 23, iter 310/1000, loss 0.095760, 0.20 batches/sec.[2K|######--------------| 32.00%, 1617/3425 sec. train epoch 23, iter 320/1000, loss 0.101350, 0.20 batches/sec.[2K|#######-------------| 33.00%, 1667/3372 sec. train epoch 23, iter 330/1000, loss 0.102159, 0.20 batches/sec.[2K|#######-------------| 34.00%, 1717/3325 sec. train epoch 23, iter 340/1000, loss 0.116644, 0.20 batches/sec.[2K|#######-------------| 35.00%, 1768/3270 sec. train epoch 23, iter 350/1000, loss 0.114572, 0.20 batches/sec.[2K|#######-------------| 36.00%, 1818/3228 sec. train epoch 23, iter 360/1000, loss 0.123184, 0.20 batches/sec.[2K|#######-------------| 37.00%, 1868/3174 sec. train epoch 23, iter 370/1000, loss 0.123715, 0.20 batches/sec.[2K|########------------| 38.00%, 1919/3117 sec. train epoch 23, iter 380/1000, loss 0.126613, 0.20 batches/sec.[2K|########------------| 39.00%, 1969/3075 sec. train epoch 23, iter 390/1000, loss 0.133190, 0.20 batches/sec.[2K|########------------| 40.00%, 2019/3017 sec. train epoch 23, iter 400/1000, loss 0.136600, 0.20 batches/sec.[2K|########------------| 41.00%, 2070/2977 sec. train epoch 23, iter 410/1000, loss 0.141243, 0.20 batches/sec.[2K|########------------| 42.00%, 2120/2926 sec. train epoch 23, iter 420/1000, loss 0.146275, 0.20 batches/sec.[2K|#########-----------| 43.00%, 2171/2873 sec. train epoch 23, iter 430/1000, loss 0.146617, 0.20 batches/sec.[2K|#########-----------| 44.00%, 2221/2825 sec. train epoch 23, iter 440/1000, loss 0.151480, 0.20 batches/sec.[2K|#########-----------| 45.00%, 2271/2767 sec. train epoch 23, iter 450/1000, loss 0.153415, 0.20 batches/sec.[2K|#########-----------| 46.00%, 2322/2720 sec. train epoch 23, iter 460/1000, loss 0.153639, 0.20 batches/sec.[2K|#########-----------| 47.00%, 2372/2666 sec. train epoch 23, iter 470/1000, loss 0.151627, 0.20 batches/sec.[2K|##########----------| 48.00%, 2423/2623 sec. train epoch 23, iter 480/1000, loss 0.156332, 0.20 batches/sec.[2K|##########----------| 49.00%, 2473/2566 sec. train epoch 23, iter 490/1000, loss 0.159490, 0.20 batches/sec.[2K|##########----------| 50.00%, 2523/2517 sec. train epoch 23, iter 500/1000, loss 0.161580, 0.20 batches/sec.[2K|##########----------| 51.00%, 2574/2468 sec. train epoch 23, iter 510/1000, loss 0.162042, 0.20 batches/sec.[2K|##########----------| 52.00%, 2624/2414 sec. train epoch 23, iter 520/1000, loss 0.160282, 0.20 batches/sec.[2K|###########---------| 53.00%, 2674/2368 sec. train epoch 23, iter 530/1000, loss 0.163729, 0.20 batches/sec.[2K|###########---------| 54.00%, 2725/2317 sec. train epoch 23, iter 540/1000, loss 0.162859, 0.20 batches/sec.[2K|###########---------| 55.00%, 2775/2264 sec. train epoch 23, iter 550/1000, loss 0.168443, 0.20 batches/sec.[2K|###########---------| 56.00%, 2825/2218 sec. train epoch 23, iter 560/1000, loss 0.172528, 0.20 batches/sec.[2K|###########---------| 57.00%, 2876/2163 sec. train epoch 23, iter 570/1000, loss 0.173784, 0.20 batches/sec.[2K|############--------| 58.00%, 2926/2118 sec. train epoch 23, iter 580/1000, loss 0.173165, 0.20 batches/sec.[2K|############--------| 59.00%, 2976/2062 sec. train epoch 23, iter 590/1000, loss 0.173277, 0.20 batches/sec.[2K|############--------| 60.00%, 3027/2016 sec. train epoch 23, iter 600/1000, loss 0.175700, 0.20 batches/sec.[2K|############--------| 61.00%, 3077/1965 sec. train epoch 23, iter 610/1000, loss 0.179884, 0.20 batches/sec.[2K|############--------| 62.00%, 3128/1914 sec. train epoch 23, iter 620/1000, loss 0.183212, 0.20 batches/sec.[2K|#############-------| 63.00%, 3178/1866 sec. train epoch 23, iter 630/1000, loss 0.178986, 0.20 batches/sec.[2K|#############-------| 64.00%, 3228/1811 sec. train epoch 23, iter 640/1000, loss 0.177761, 0.20 batches/sec.[2K|#############-------| 65.00%, 3279/1764 sec. train epoch 23, iter 650/1000, loss 0.178551, 0.20 batches/sec.[2K|#############-------| 66.00%, 3329/1713 sec. train epoch 23, iter 660/1000, loss 0.176675, 0.20 batches/sec.[2K|#############-------| 67.00%, 3379/1663 sec. train epoch 23, iter 670/1000, loss 0.181902, 0.20 batches/sec.[2K|##############------| 68.00%, 3430/1614 sec. train epoch 23, iter 680/1000, loss 0.181368, 0.20 batches/sec.[2K|##############------| 69.00%, 3480/1561 sec. train epoch 23, iter 690/1000, loss 0.184519, 0.20 batches/sec.[2K|##############------| 70.00%, 3531/1516 sec. train epoch 23, iter 700/1000, loss 0.185630, 0.20 batches/sec.[2K|##############------| 71.00%, 3581/1463 sec. train epoch 23, iter 710/1000, loss 0.187942, 0.20 batches/sec.[2K|##############------| 72.00%, 3632/1410 sec. train epoch 23, iter 720/1000, loss 0.192374, 0.20 batches/sec.[2K|###############-----| 73.00%, 3682/1362 sec. train epoch 23, iter 730/1000, loss 0.191591, 0.20 batches/sec.[2K|###############-----| 74.00%, 3732/1308 sec. train epoch 23, iter 740/1000, loss 0.192546, 0.20 batches/sec.[2K|###############-----| 75.00%, 3783/1261 sec. train epoch 23, iter 750/1000, loss 0.195911, 0.20 batches/sec.[2K|###############-----| 76.00%, 3833/1210 sec. train epoch 23, iter 760/1000, loss 0.192322, 0.20 batches/sec.[2K|###############-----| 77.00%, 3883/1157 sec. train epoch 23, iter 770/1000, loss 0.192633, 0.20 batches/sec.[2K|################----| 78.00%, 3934/1109 sec. train epoch 23, iter 780/1000, loss 0.193412, 0.20 batches/sec.[2K|################----| 79.00%, 3984/1057 sec. train epoch 23, iter 790/1000, loss 0.196662, 0.20 batches/sec.[2K|################----| 80.00%, 4035/1008 sec. train epoch 23, iter 800/1000, loss 0.196625, 0.20 batches/sec.[2K|################----| 81.00%, 4085/955 sec. train epoch 23, iter 810/1000, loss 0.198168, 0.20 batches/sec.[2K|################----| 82.00%, 4135/908 sec. train epoch 23, iter 820/1000, loss 0.197942, 0.20 batches/sec.[2K|#################---| 83.00%, 4186/858 sec. train epoch 23, iter 830/1000, loss 0.196747, 0.20 batches/sec.[2K|#################---| 84.00%, 4236/807 sec. train epoch 23, iter 840/1000, loss 0.196846, 0.20 batches/sec.[32m[2019-03-18 19:27:55 @logger.py:146][0m [2K|####################| 100.00%, 5043/0 sec. train epoch 23, iter 1000/1000, loss 0.200231, 0.20 batches/sec.
[32m[2019-03-18 19:27:59 @logger.py:43][0m [32;1mTrigger callback: [0mTrigger ModelSaver: Save model to model_logs/20190317111349169013_10-255-0-254_mine_NORMAL_wgan_gp_full_model_celeba_hq_256/snap-23000.
